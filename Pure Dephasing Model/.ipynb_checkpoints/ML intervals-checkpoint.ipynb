{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a83048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split the data into training, validation and test sets, and calculate their Fourier coefficients along\n",
    "#with the corresponding labels. At t=0 all of the signals are equal, so we omit the first timestep. Ntrain is the \n",
    "#number of trajectories in the training set, Nval is the number in the validation set and Ntest is the number in \n",
    "#the test set\n",
    "def fouriertrainvaltest(X, Y, Ntrain, Nval, Ntest):\n",
    "    \n",
    "    #Generating a training set with Ntrain trajectories, a validation with Nval trajectories and a test set with\n",
    "    #Ntest trajectories. At t=0 all of the signals are equal, so we omit the first timestep.\n",
    "    Xtrain = X[0:Ntrain, 1:401]\n",
    "    Xval = X[Ntrain:Ntrain+Nval, 1:401]\n",
    "    Xtest = X[Ntrain+Nval:Ntrain+Nval+Ntest, 1:401]\n",
    "\n",
    "    #extract the corresponding labels for the training, validation and test sets.\n",
    "    Ytrain = Y[0:Ntrain, :]\n",
    "    Yval = Y[Ntrain:Ntrain+Nval, :]\n",
    "    Ytest = Y[Ntrain+Nval:Ntrain+Nval+Ntest, :]\n",
    "    \n",
    "    #calculating the Fourier coefficients for each subset.\n",
    "    XtrainF = np.fft.fft(Xtrain)\n",
    "    XvalF = np.fft.fft(Xval)\n",
    "    XtestF = np.fft.fft(Xtest)\n",
    "    \n",
    "    #Prepare to split the Fourier coefficients into their real and imaginary components. Each complex number will \n",
    "    #occupy two columns: one for the real part and one for the imaginary part. Therefore, we create new arrays that \n",
    "    #have twice the number of columns. \n",
    "    xtrain = np.zeros((XtrainF.shape[0], 2*XtrainF.shape[1]))\n",
    "    xval = np.zeros((XvalF.shape[0], 2*XvalF.shape[1]))\n",
    "    xtest = np.zeros((XtestF.shape[0], 2*XtestF.shape[1]))\n",
    "\n",
    "    #For each Fourier coefficient in the training set, split into real and imaginary parts. These parts are then\n",
    "    #stored alternately (even indices for real, odd indices for imaginary).\n",
    "    for i in range(XtrainF.shape[0]):\n",
    "        for j in range(XtrainF.shape[1]):\n",
    "            xtrain[i, 2*j] = XtrainF[i,j].real\n",
    "            xtrain[i, 2*j + 1] = XtrainF[i,j].imag\n",
    "        \n",
    "    #Do the same for the test set, splitting the Fourier coefficients into their real and imaginary parts.\n",
    "    for i in range(XtestF.shape[0]):\n",
    "        for j in range(XtestF.shape[1]):\n",
    "            xtest[i, 2*j] = XtestF[i,j].real\n",
    "            xtest[i, 2*j + 1] = XtestF[i,j].imag\n",
    "            \n",
    "    #Similarly, split the Fourier coefficients for the validation set.\n",
    "    for i in range(XvalF.shape[0]):\n",
    "        for j in range(XvalF.shape[1]):\n",
    "            xval[i, 2*j] = XvalF[i,j].real\n",
    "            xval[i, 2*j + 1] = XvalF[i,j].imag\n",
    "            \n",
    "    #Return the transformed training, validation and test sets along with their corresponding labels\n",
    "    return(xtrain, xval, xtest, Ytrain, Yval, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2779efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the R-squared metric. This function takes the true and predicted values, and calculates the \n",
    "#R-squared value\n",
    "def r_square(y, y_pred):\n",
    "    residual = tf.reduce_sum(tf.square(tf.subtract(y, y_pred)))\n",
    "    total = tf.reduce_sum(tf.square(tf.subtract(y, tf.reduce_mean(y))))\n",
    "    r2 = 1 - residual/total\n",
    "    return(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa014794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initalise arrays to store the loss values for each interval\n",
    "testloss = np.zeros(10)\n",
    "trainingloss = np.zeros(10)\n",
    "validationloss = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eebc965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise the upper bound for the interval\n",
    "upper_bound = 0.25\n",
    "\n",
    "#Loop over 10 different values, adjusting the upper bound during each iteration\n",
    "for i in tqdm(range(10)):\n",
    "    \n",
    "    #Load training data from csv files based on the current upper bound\n",
    "    X = np.loadtxt('Data/Xtrainx_varyηandω_0.25and{0}.csv'.format(np.round(upper_bound, 2)), delimiter=',')\n",
    "    Y = np.loadtxt('Data/Ytrain_varyηandω_0.25and{0}.csv'.format(np.round(upper_bound, 2)), delimiter=',')\n",
    "    \n",
    "    #Extract the values of $\\omega_c$, $s$ and $\\eta$ from Y for training\n",
    "    Y_params = Y[:,3:6]\n",
    "    \n",
    "    #Scale the extracted parameters to a [0,1] range using min-max scaling\n",
    "    scaler=MinMaxScaler()\n",
    "    Y_scaled = scaler.fit_transform(Y_params)\n",
    "\n",
    "    #Generating a training, validation and test set\n",
    "    xtrain, xval, xtest, Ytrain, Yval, Ytest = fouriertrainvaltest(X, Y_scaled, 4800, 2400, 2400)\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = tf.keras.Sequential()\n",
    "    #Add the hidden layers\n",
    "    model.add(tf.keras.layers.Dense(250, input_dim = (np.shape(xtrain)[1]), activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(250 , activation = 'sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(250 , activation = 'sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(250 , activation = 'sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(250 , activation = 'sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(80 , activation = 'sigmoid'))\n",
    "    #Add the output layer\n",
    "    model.add(tf.keras.layers.Dense(3, activation = 'linear'))\n",
    "\n",
    "    #Setting the optimiser equal to the Adam optimiser with learning rate = 0.0001\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "\n",
    "    #Compliling the model\n",
    "    model.compile(optimizer=opt, loss = 'mean_squared_error', metrics=[r_square])\n",
    "    \n",
    "    #Training the model\n",
    "    history = model.fit(xtrain, Ytrain, epochs = 100000, validation_data = (xval, Yval), batch_size = np.shape(xtrain)[0], verbose=0)\n",
    "    \n",
    "    #Save the trained model weights\n",
    "    model.save(\"Weights/training_regression_0.25and{0}.weights.h5\".format(np.round(upper_bound, 2)))\n",
    "               \n",
    "    #Evaluate the model on the training, validation and test sets and store the loss metric\n",
    "    trainingloss[i], trainingr2 = model.evaluate(xtrain, Ytrain)\n",
    "    validationloss[i], validationr2 = model.evaluate(xval, Yval)\n",
    "    testloss[i], testr2 = model.evaluate(xtest, Ytest)\n",
    "               \n",
    "    #Save the loss metrics to csv files\n",
    "    np.savetxt('traininglossvintervallength.csv', trainingloss, delimiter=',')\n",
    "    np.savetxt('validationlossvintervallength.csv', validationloss, delimiter=',')\n",
    "    np.savetxt('testlossvintervallength.csv', testloss, delimiter=',')\n",
    "               \n",
    "    #Make predictions for the training validation, and test sets and revert scaling\n",
    "    predictions_train = scaler.inverse_transform(model.predict(xtrain))\n",
    "    predictions_val = scaler.inverse_transform(model.predict(xval))\n",
    "    predictions_test = scaler.inverse_transform(model.predict(xtest))\n",
    "               \n",
    "    #Save predictions alongside the original index for training, validation and test sets to csv files\n",
    "    np.savetxt('Predictions/predictionstrain_0.25and{0}.csv'.format(np.round(upper_bound, 2)), predictions_train, delimiter=',')\n",
    "    np.savetxt('Predictions/predictionsval_0.25and{0}.csv'.format(np.round(upper_bound, 2)), predictions_val, delimiter=',')\n",
    "    np.savetxt('Predictions/predictionstest_0.25and{0}.csv'.format(np.round(upper_bound, 2)), predictions_test, delimiter=',')\n",
    "\n",
    "    #Increase the upper bound by 0.2 for the next iteration\n",
    "    upper_bound += 0.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
