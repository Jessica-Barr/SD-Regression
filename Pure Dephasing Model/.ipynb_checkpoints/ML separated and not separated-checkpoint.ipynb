{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0691f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d02eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split the data into training, validation and test sets, and calculate their Fourier coefficients along\n",
    "#with the corresponding labels. At t=0 all of the signals are equal, so we omit the first timestep. Ntrain is the \n",
    "#number of trajectories in the training set, Nval is the number in the validation set and Ntest is the number in \n",
    "#the test set\n",
    "def fouriertrainvaltest(X, Y, Ntrain, Nval, Ntest):\n",
    "    \n",
    "    #Generating a training set with Ntrain trajectories, a validation with Nval trajectories and a test set with\n",
    "    #Ntest trajectories. At t=0 all of the signals are equal, so we omit the first timestep.\n",
    "    Xtrain = X[0:Ntrain, 1:401]\n",
    "    Xval = X[Ntrain:Ntrain+Nval, 1:401]\n",
    "    Xtest = X[Ntrain+Nval:Ntrain+Nval+Ntest, 1:401]\n",
    "\n",
    "    #extract the corresponding labels for the training, validation and test sets.\n",
    "    Ytrain = Y[0:Ntrain, :]\n",
    "    Yval = Y[Ntrain:Ntrain+Nval, :]\n",
    "    Ytest = Y[Ntrain+Nval:Ntrain+Nval+Ntest, :]\n",
    "    \n",
    "    #calculating the Fourier coefficients for each subset.\n",
    "    XtrainF = np.fft.fft(Xtrain)\n",
    "    XvalF = np.fft.fft(Xval)\n",
    "    XtestF = np.fft.fft(Xtest)\n",
    "    \n",
    "    #Prepare to split the Fourier coefficients into their real and imaginary components. Each complex number will \n",
    "    #occupy two columns: one for the real part and one for the imaginary part. Therefore, we create new arrays that \n",
    "    #have twice the number of columns. \n",
    "    xtrain = np.zeros((XtrainF.shape[0], 2*XtrainF.shape[1]))\n",
    "    xval = np.zeros((XvalF.shape[0], 2*XvalF.shape[1]))\n",
    "    xtest = np.zeros((XtestF.shape[0], 2*XtestF.shape[1]))\n",
    "\n",
    "    #For each Fourier coefficient in the training set, split into real and imaginary parts. These parts are then\n",
    "    #stored alternately (even indices for real, odd indices for imaginary).\n",
    "    for i in range(XtrainF.shape[0]):\n",
    "        for j in range(XtrainF.shape[1]):\n",
    "            xtrain[i, 2*j] = XtrainF[i,j].real\n",
    "            xtrain[i, 2*j + 1] = XtrainF[i,j].imag\n",
    "        \n",
    "    #Do the same for the test set, splitting the Fourier coefficients into their real and imaginary parts.\n",
    "    for i in range(XtestF.shape[0]):\n",
    "        for j in range(XtestF.shape[1]):\n",
    "            xtest[i, 2*j] = XtestF[i,j].real\n",
    "            xtest[i, 2*j + 1] = XtestF[i,j].imag\n",
    "            \n",
    "    #Similarly, split the Fourier coefficients for the validation set.\n",
    "    for i in range(XvalF.shape[0]):\n",
    "        for j in range(XvalF.shape[1]):\n",
    "            xval[i, 2*j] = XvalF[i,j].real\n",
    "            xval[i, 2*j + 1] = XvalF[i,j].imag\n",
    "            \n",
    "    #Return the transformed training, validation and test sets along with their corresponding labels\n",
    "    return(xtrain, xval, xtest, Ytrain, Yval, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23dade39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the R-squared metric. This function takes the true and predicted values, and calculates the \n",
    "#R-squared value\n",
    "def r_square(y, y_pred):\n",
    "    residual = tf.reduce_sum(tf.square(tf.subtract(y, y_pred)))\n",
    "    total = tf.reduce_sum(tf.square(tf.subtract(y, tf.reduce_mean(y))))\n",
    "    r2 = 1 - residual/total\n",
    "    return(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f27f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data with $\\eta = 0.25$, $\\omega_c = 0.5$ with $s \\in (0, 0.5]$ if the spectral density is sub-Ohmic,\n",
    "#$s \\in [1.5, 4]$ is the spectral density is super-Ohmic and $s=1$ is the spectral density is Ohmic.\n",
    "X_separated = np.loadtxt('Data/Xtrainx_fixedηandω_separated.csv', delimiter=',')\n",
    "Y_separated = np.loadtxt('Data/Ytrain_fixedηandω_separated.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dee5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_separated[:,[4]] selects the column with the Ohmicity parameter, located at index 4\n",
    "Y_separateds = Y_separated[:,[4]]\n",
    "\n",
    "#Scale the labels using MinMaxScaler for normalisation\n",
    "scaler=MinMaxScaler()\n",
    "Y_separateds_scaled = scaler.fit_transform(Y_separateds)\n",
    "\n",
    "#Generating a training, validation and test set \n",
    "xtrain_separated, xval_separated, xtest_separated, Ytrain_separated, Yval_separated, Ytest_separated = fouriertrainvaltest(X_separated, Y_separateds_scaled, 4800, 2400, 2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad92570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the path where the model's weights will be saved\n",
    "checkpoint_path = \"training_regressions_separated.weights.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "#Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5e18c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3754 - r_square: -1.1854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 15:10:57.026383: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-10-17 15:10:57.189157: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.3754 - r_square: -1.1854 - val_loss: 0.3413 - val_r_square: -0.7474\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3401 - r_square: -0.7667\n",
      "Epoch 2: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3401 - r_square: -0.7667 - val_loss: 0.3111 - val_r_square: -0.4410\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3082 - r_square: -0.4495\n",
      "Epoch 3: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3082 - r_square: -0.4495 - val_loss: 0.2840 - val_r_square: -0.2269\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2796 - r_square: -0.2278\n",
      "Epoch 4: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2796 - r_square: -0.2278 - val_loss: 0.2578 - val_r_square: -0.0970\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2519 - r_square: -0.0932\n",
      "Epoch 5: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2519 - r_square: -0.0932 - val_loss: 0.2314 - val_r_square: -0.0450\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2241 - r_square: -0.0391\n",
      "Epoch 6: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2241 - r_square: -0.0391 - val_loss: 0.2304 - val_r_square: -0.0677\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2240 - r_square: -0.0622\n",
      "Epoch 7: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2240 - r_square: -0.0622 - val_loss: 0.2317 - val_r_square: -0.0716\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2268 - r_square: -0.0679\n",
      "Epoch 8: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2268 - r_square: -0.0679 - val_loss: 0.2267 - val_r_square: -0.0382\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2227 - r_square: -0.0360\n",
      "Epoch 9: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2227 - r_square: -0.0360 - val_loss: 0.2171 - val_r_square: 0.0327\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2137 - r_square: 0.0338\n",
      "Epoch 10: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2137 - r_square: 0.0338 - val_loss: 0.2040 - val_r_square: 0.1327\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2008 - r_square: 0.1335\n",
      "Epoch 11: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2008 - r_square: 0.1335 - val_loss: 0.1882 - val_r_square: 0.2506\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1849 - r_square: 0.2513\n",
      "Epoch 12: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1849 - r_square: 0.2513 - val_loss: 0.1700 - val_r_square: 0.3740\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1665 - r_square: 0.3746\n",
      "Epoch 13: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1665 - r_square: 0.3746 - val_loss: 0.1499 - val_r_square: 0.4906\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1460 - r_square: 0.4910\n",
      "Epoch 14: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1460 - r_square: 0.4910 - val_loss: 0.1344 - val_r_square: 0.5888\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1306 - r_square: 0.5886\n",
      "Epoch 15: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1306 - r_square: 0.5886 - val_loss: 0.1300 - val_r_square: 0.6555\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1271 - r_square: 0.6544\n",
      "Epoch 16: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1271 - r_square: 0.6544 - val_loss: 0.1227 - val_r_square: 0.7069\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1207 - r_square: 0.7050\n",
      "Epoch 17: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1207 - r_square: 0.7050 - val_loss: 0.1134 - val_r_square: 0.7510\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1119 - r_square: 0.7488\n",
      "Epoch 18: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1119 - r_square: 0.7488 - val_loss: 0.1015 - val_r_square: 0.7906\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1004 - r_square: 0.7883\n",
      "Epoch 19: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1004 - r_square: 0.7883 - val_loss: 0.0868 - val_r_square: 0.8240\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0857 - r_square: 0.8221\n",
      "Epoch 20: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0857 - r_square: 0.8221 - val_loss: 0.0694 - val_r_square: 0.8466\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0683 - r_square: 0.8451\n",
      "Epoch 21: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0683 - r_square: 0.8451 - val_loss: 0.0656 - val_r_square: 0.8521\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0646 - r_square: 0.8508\n",
      "Epoch 22: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0646 - r_square: 0.8508 - val_loss: 0.0653 - val_r_square: 0.8674\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0645 - r_square: 0.8662\n",
      "Epoch 23: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0645 - r_square: 0.8662 - val_loss: 0.0560 - val_r_square: 0.8983\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0551 - r_square: 0.8973\n",
      "Epoch 24: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0551 - r_square: 0.8973 - val_loss: 0.0428 - val_r_square: 0.9318\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0419 - r_square: 0.9310\n",
      "Epoch 25: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0419 - r_square: 0.9310 - val_loss: 0.0425 - val_r_square: 0.9508\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0422 - r_square: 0.9501\n",
      "Epoch 26: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0422 - r_square: 0.9501 - val_loss: 0.0419 - val_r_square: 0.9611\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0419 - r_square: 0.9606\n",
      "Epoch 27: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0419 - r_square: 0.9606 - val_loss: 0.0403 - val_r_square: 0.9676\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0400 - r_square: 0.9674\n",
      "Epoch 28: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0400 - r_square: 0.9674 - val_loss: 0.0374 - val_r_square: 0.9726\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0366 - r_square: 0.9728\n",
      "Epoch 29: saving model to training_regressions_separated.weights.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0366 - r_square: 0.9728 - val_loss: 0.0332 - val_r_square: 0.9757\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0318 - r_square: 0.9762\n",
      "Epoch 30: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0318 - r_square: 0.9762 - val_loss: 0.0376 - val_r_square: 0.9752\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0364 - r_square: 0.9758\n",
      "Epoch 31: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0364 - r_square: 0.9758 - val_loss: 0.0375 - val_r_square: 0.9762\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0362 - r_square: 0.9770\n",
      "Epoch 32: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0362 - r_square: 0.9770 - val_loss: 0.0339 - val_r_square: 0.9778\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0324 - r_square: 0.9787\n",
      "Epoch 33: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0324 - r_square: 0.9787 - val_loss: 0.0335 - val_r_square: 0.9750\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0318 - r_square: 0.9759\n",
      "Epoch 34: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0318 - r_square: 0.9759 - val_loss: 0.0415 - val_r_square: 0.9666\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0403 - r_square: 0.9674\n",
      "Epoch 35: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0403 - r_square: 0.9674 - val_loss: 0.0414 - val_r_square: 0.9671\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0402 - r_square: 0.9678\n",
      "Epoch 36: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0402 - r_square: 0.9678 - val_loss: 0.0333 - val_r_square: 0.9760\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0318 - r_square: 0.9767\n",
      "Epoch 37: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0318 - r_square: 0.9767 - val_loss: 0.0320 - val_r_square: 0.9818\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0307 - r_square: 0.9823\n",
      "Epoch 38: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0307 - r_square: 0.9823 - val_loss: 0.0294 - val_r_square: 0.9857\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0285 - r_square: 0.9861\n",
      "Epoch 39: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0285 - r_square: 0.9861 - val_loss: 0.0257 - val_r_square: 0.9886\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0250 - r_square: 0.9889\n",
      "Epoch 40: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0250 - r_square: 0.9889 - val_loss: 0.0219 - val_r_square: 0.9910\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0215 - r_square: 0.9912\n",
      "Epoch 41: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0215 - r_square: 0.9912 - val_loss: 0.0179 - val_r_square: 0.9926\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0174 - r_square: 0.9928\n",
      "Epoch 42: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0174 - r_square: 0.9928 - val_loss: 0.0192 - val_r_square: 0.9918\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0192 - r_square: 0.9917\n",
      "Epoch 43: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0192 - r_square: 0.9917 - val_loss: 0.0200 - val_r_square: 0.9916\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0201 - r_square: 0.9914\n",
      "Epoch 44: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0201 - r_square: 0.9914 - val_loss: 0.0194 - val_r_square: 0.9923\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0192 - r_square: 0.9922\n",
      "Epoch 45: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0192 - r_square: 0.9922 - val_loss: 0.0189 - val_r_square: 0.9916\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0184 - r_square: 0.9916\n",
      "Epoch 46: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0184 - r_square: 0.9916 - val_loss: 0.0187 - val_r_square: 0.9912\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0181 - r_square: 0.9911\n",
      "Epoch 47: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0181 - r_square: 0.9911 - val_loss: 0.0204 - val_r_square: 0.9912\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0203 - r_square: 0.9910\n",
      "Epoch 48: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0203 - r_square: 0.9910 - val_loss: 0.0210 - val_r_square: 0.9908\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0211 - r_square: 0.9905\n",
      "Epoch 49: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0211 - r_square: 0.9905 - val_loss: 0.0193 - val_r_square: 0.9916\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0193 - r_square: 0.9915\n",
      "Epoch 50: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0193 - r_square: 0.9915 - val_loss: 0.0162 - val_r_square: 0.9928\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0158 - r_square: 0.9928\n",
      "Epoch 51: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0158 - r_square: 0.9928 - val_loss: 0.0190 - val_r_square: 0.9923\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0187 - r_square: 0.9924\n",
      "Epoch 52: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0187 - r_square: 0.9924 - val_loss: 0.0174 - val_r_square: 0.9935\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0171 - r_square: 0.9936\n",
      "Epoch 53: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0171 - r_square: 0.9936 - val_loss: 0.0143 - val_r_square: 0.9944\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0140 - r_square: 0.9944\n",
      "Epoch 54: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0140 - r_square: 0.9944 - val_loss: 0.0151 - val_r_square: 0.9941\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0148 - r_square: 0.9941\n",
      "Epoch 55: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0148 - r_square: 0.9941 - val_loss: 0.0141 - val_r_square: 0.9949\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0137 - r_square: 0.9949\n",
      "Epoch 56: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0137 - r_square: 0.9949 - val_loss: 0.0137 - val_r_square: 0.9950\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0132 - r_square: 0.9950\n",
      "Epoch 57: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0132 - r_square: 0.9950 - val_loss: 0.0151 - val_r_square: 0.9942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0149 - r_square: 0.9941\n",
      "Epoch 58: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0149 - r_square: 0.9941 - val_loss: 0.0132 - val_r_square: 0.9953\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0128 - r_square: 0.9953\n",
      "Epoch 59: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0128 - r_square: 0.9953 - val_loss: 0.0156 - val_r_square: 0.9957\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0152 - r_square: 0.9958\n",
      "Epoch 60: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0152 - r_square: 0.9958 - val_loss: 0.0160 - val_r_square: 0.9957\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0155 - r_square: 0.9958\n",
      "Epoch 61: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0155 - r_square: 0.9958 - val_loss: 0.0121 - val_r_square: 0.9969\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - r_square: 0.9970\n",
      "Epoch 62: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0115 - r_square: 0.9970 - val_loss: 0.0152 - val_r_square: 0.9957\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0153 - r_square: 0.9957\n",
      "Epoch 63: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0153 - r_square: 0.9957 - val_loss: 0.0147 - val_r_square: 0.9961\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0148 - r_square: 0.9961\n",
      "Epoch 64: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0148 - r_square: 0.9961 - val_loss: 0.0101 - val_r_square: 0.9980\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9981\n",
      "Epoch 65: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0098 - r_square: 0.9981 - val_loss: 0.0161 - val_r_square: 0.9956\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0156 - r_square: 0.9958\n",
      "Epoch 66: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0156 - r_square: 0.9958 - val_loss: 0.0144 - val_r_square: 0.9963\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0140 - r_square: 0.9964\n",
      "Epoch 67: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0140 - r_square: 0.9964 - val_loss: 0.0101 - val_r_square: 0.9980\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9979\n",
      "Epoch 68: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0102 - r_square: 0.9979 - val_loss: 0.0144 - val_r_square: 0.9961\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0148 - r_square: 0.9959\n",
      "Epoch 69: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0148 - r_square: 0.9959 - val_loss: 0.0112 - val_r_square: 0.9973\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - r_square: 0.9972\n",
      "Epoch 70: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0115 - r_square: 0.9972 - val_loss: 0.0087 - val_r_square: 0.9980\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0084 - r_square: 0.9980\n",
      "Epoch 71: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0084 - r_square: 0.9980 - val_loss: 0.0089 - val_r_square: 0.9981\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9981\n",
      "Epoch 72: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0086 - r_square: 0.9981 - val_loss: 0.0088 - val_r_square: 0.9982\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9982\n",
      "Epoch 73: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0090 - r_square: 0.9982 - val_loss: 0.0101 - val_r_square: 0.9978\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - r_square: 0.9977\n",
      "Epoch 74: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0104 - r_square: 0.9977 - val_loss: 0.0063 - val_r_square: 0.9989\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9988\n",
      "Epoch 75: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - r_square: 0.9988 - val_loss: 0.0141 - val_r_square: 0.9971\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0138 - r_square: 0.9971\n",
      "Epoch 76: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0138 - r_square: 0.9971 - val_loss: 0.0112 - val_r_square: 0.9980\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9980\n",
      "Epoch 77: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0110 - r_square: 0.9980 - val_loss: 0.0079 - val_r_square: 0.9985\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9985\n",
      "Epoch 78: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0080 - r_square: 0.9985 - val_loss: 0.0102 - val_r_square: 0.9978\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9977\n",
      "Epoch 79: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0103 - r_square: 0.9977 - val_loss: 0.0072 - val_r_square: 0.9989\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9989\n",
      "Epoch 80: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0071 - r_square: 0.9989 - val_loss: 0.0082 - val_r_square: 0.9988\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9988\n",
      "Epoch 81: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0081 - r_square: 0.9988 - val_loss: 0.0056 - val_r_square: 0.9990\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9990\n",
      "Epoch 82: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - r_square: 0.9990 - val_loss: 0.0047 - val_r_square: 0.9992\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9992\n",
      "Epoch 83: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0047 - r_square: 0.9992 - val_loss: 0.0045 - val_r_square: 0.9992\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9992\n",
      "Epoch 84: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0045 - r_square: 0.9992 - val_loss: 0.0060 - val_r_square: 0.9991\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9991\n",
      "Epoch 85: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - r_square: 0.9991 - val_loss: 0.0049 - val_r_square: 0.9991\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9991\n",
      "Epoch 86: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - r_square: 0.9991 - val_loss: 0.0042 - val_r_square: 0.9992\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0042 - r_square: 0.9992\n",
      "Epoch 87: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - r_square: 0.9992 - val_loss: 0.0051 - val_r_square: 0.9993\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9993\n",
      "Epoch 88: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9993 - val_loss: 0.0082 - val_r_square: 0.9988\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9988\n",
      "Epoch 89: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0083 - r_square: 0.9988 - val_loss: 0.0044 - val_r_square: 0.9995\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9995\n",
      "Epoch 90: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - r_square: 0.9995 - val_loss: 0.0113 - val_r_square: 0.9982\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0112 - r_square: 0.9982\n",
      "Epoch 91: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0112 - r_square: 0.9982 - val_loss: 0.0092 - val_r_square: 0.9987\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9987\n",
      "Epoch 92: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0092 - r_square: 0.9987 - val_loss: 0.0072 - val_r_square: 0.9990\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9990\n",
      "Epoch 93: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0072 - r_square: 0.9990 - val_loss: 0.0094 - val_r_square: 0.9985\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9985\n",
      "Epoch 94: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0094 - r_square: 0.9985 - val_loss: 0.0049 - val_r_square: 0.9995\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9995\n",
      "Epoch 95: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - r_square: 0.9995 - val_loss: 0.0093 - val_r_square: 0.9988\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9987\n",
      "Epoch 96: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0092 - r_square: 0.9987 - val_loss: 0.0038 - val_r_square: 0.9997\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9997\n",
      "Epoch 97: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - r_square: 0.9997 - val_loss: 0.0141 - val_r_square: 0.9973\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0141 - r_square: 0.9973\n",
      "Epoch 98: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0141 - r_square: 0.9973 - val_loss: 0.0142 - val_r_square: 0.9973\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0143 - r_square: 0.9972\n",
      "Epoch 99: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0143 - r_square: 0.9972 - val_loss: 0.0030 - val_r_square: 0.9998\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9997\n",
      "Epoch 100: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - r_square: 0.9997 - val_loss: 0.0156 - val_r_square: 0.9968\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0154 - r_square: 0.9967\n",
      "Epoch 101: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0154 - r_square: 0.9967 - val_loss: 0.0165 - val_r_square: 0.9964\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0164 - r_square: 0.9963\n",
      "Epoch 102: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0164 - r_square: 0.9963 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9995\n",
      "Epoch 103: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - r_square: 0.9995 - val_loss: 0.0187 - val_r_square: 0.9955\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0187 - r_square: 0.9954\n",
      "Epoch 104: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0187 - r_square: 0.9954 - val_loss: 0.0257 - val_r_square: 0.9917\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0258 - r_square: 0.9914\n",
      "Epoch 105: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0258 - r_square: 0.9914 - val_loss: 0.0189 - val_r_square: 0.9954\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0190 - r_square: 0.9953\n",
      "Epoch 106: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0190 - r_square: 0.9953 - val_loss: 0.0031 - val_r_square: 0.9998\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 107: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0168 - val_r_square: 0.9963\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0167 - r_square: 0.9963\n",
      "Epoch 108: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - r_square: 0.9963 - val_loss: 0.0188 - val_r_square: 0.9955\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0187 - r_square: 0.9954\n",
      "Epoch 109: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0187 - r_square: 0.9954 - val_loss: 0.0081 - val_r_square: 0.9991\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9991\n",
      "Epoch 110: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0080 - r_square: 0.9991 - val_loss: 0.0140 - val_r_square: 0.9974\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0140 - r_square: 0.9974\n",
      "Epoch 111: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0140 - r_square: 0.9974 - val_loss: 0.0207 - val_r_square: 0.9945\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0207 - r_square: 0.9943\n",
      "Epoch 112: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0207 - r_square: 0.9943 - val_loss: 0.0143 - val_r_square: 0.9972\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0142 - r_square: 0.9972\n",
      "Epoch 113: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0142 - r_square: 0.9972 - val_loss: 0.0048 - val_r_square: 0.9996\n",
      "Epoch 114/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9996\n",
      "Epoch 114: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0048 - r_square: 0.9996 - val_loss: 0.0106 - val_r_square: 0.9984\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9984\n",
      "Epoch 115: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0106 - r_square: 0.9984 - val_loss: 0.0050 - val_r_square: 0.9995\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9995\n",
      "Epoch 116: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9995 - val_loss: 0.0090 - val_r_square: 0.9987\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9987\n",
      "Epoch 117: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0090 - r_square: 0.9987 - val_loss: 0.0088 - val_r_square: 0.9988\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0089 - r_square: 0.9988\n",
      "Epoch 118: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0089 - r_square: 0.9988 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9997\n",
      "Epoch 119: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - r_square: 0.9997 - val_loss: 0.0069 - val_r_square: 0.9992\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9992\n",
      "Epoch 120: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9992 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9998\n",
      "Epoch 121: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - r_square: 0.9998 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 122: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0030 - val_r_square: 0.9998\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9998\n",
      "Epoch 123: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - r_square: 0.9998 - val_loss: 0.0029 - val_r_square: 0.9998\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9998\n",
      "Epoch 124: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - r_square: 0.9998 - val_loss: 0.0025 - val_r_square: 0.9998\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - r_square: 0.9998\n",
      "Epoch 125: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - r_square: 0.9998 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9997\n",
      "Epoch 126: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - r_square: 0.9997 - val_loss: 0.0029 - val_r_square: 0.9998\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9998\n",
      "Epoch 127: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - r_square: 0.9998 - val_loss: 0.0033 - val_r_square: 0.9998\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - r_square: 0.9998\n",
      "Epoch 128: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - r_square: 0.9998 - val_loss: 0.0024 - val_r_square: 0.9998\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0023 - r_square: 0.9998\n",
      "Epoch 129: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - r_square: 0.9998 - val_loss: 0.0051 - val_r_square: 0.9996\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 130: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0041 - val_r_square: 0.9997\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 131: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0022 - val_r_square: 0.9999\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 132: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0064 - val_r_square: 0.9994\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9994\n",
      "Epoch 133: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0064 - r_square: 0.9994 - val_loss: 0.0027 - val_r_square: 0.9999\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9998\n",
      "Epoch 134: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - r_square: 0.9998 - val_loss: 0.0084 - val_r_square: 0.9990\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9990\n",
      "Epoch 135: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0083 - r_square: 0.9990 - val_loss: 0.0053 - val_r_square: 0.9996\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9996\n",
      "Epoch 136: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0053 - r_square: 0.9996 - val_loss: 0.0087 - val_r_square: 0.9990\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0087 - r_square: 0.9990\n",
      "Epoch 137: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0087 - r_square: 0.9990 - val_loss: 0.0095 - val_r_square: 0.9988\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9988\n",
      "Epoch 138: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0096 - r_square: 0.9988 - val_loss: 0.0022 - val_r_square: 0.9999\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 139: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0033 - val_r_square: 0.9998\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 140: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0055 - val_r_square: 0.9995\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 141: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0028 - val_r_square: 0.9999\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9999\n",
      "Epoch 142: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - r_square: 0.9999 - val_loss: 0.0090 - val_r_square: 0.9989\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9989\n",
      "Epoch 143: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0090 - r_square: 0.9989 - val_loss: 0.0069 - val_r_square: 0.9993\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9993\n",
      "Epoch 144: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0069 - r_square: 0.9993 - val_loss: 0.0062 - val_r_square: 0.9994\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9994\n",
      "Epoch 145: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - r_square: 0.9994 - val_loss: 0.0067 - val_r_square: 0.9993\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9993\n",
      "Epoch 146: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0067 - r_square: 0.9993 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 147: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0050 - val_r_square: 0.9996\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9996\n",
      "Epoch 148: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - r_square: 0.9996 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 149: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0034 - val_r_square: 0.9998\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 150: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0066 - val_r_square: 0.9994\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 151: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0046 - val_r_square: 0.9996\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9996\n",
      "Epoch 152: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - r_square: 0.9996 - val_loss: 0.0072 - val_r_square: 0.9993\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9992\n",
      "Epoch 153: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - r_square: 0.9992 - val_loss: 0.0064 - val_r_square: 0.9994\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 154: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0055 - val_r_square: 0.9995\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 155: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0063 - val_r_square: 0.9994\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9994\n",
      "Epoch 156: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - r_square: 0.9994 - val_loss: 0.0034 - val_r_square: 0.9998\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - r_square: 0.9998\n",
      "Epoch 157: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - r_square: 0.9998 - val_loss: 0.0037 - val_r_square: 0.9997\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 158: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0050 - val_r_square: 0.9996\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9996\n",
      "Epoch 159: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - r_square: 0.9996 - val_loss: 0.0028 - val_r_square: 0.9999\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9999\n",
      "Epoch 160: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - r_square: 0.9999 - val_loss: 0.0082 - val_r_square: 0.9991\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9991\n",
      "Epoch 161: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0082 - r_square: 0.9991 - val_loss: 0.0066 - val_r_square: 0.9993\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9993\n",
      "Epoch 162: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0066 - r_square: 0.9993 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 163: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 164: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0061 - val_r_square: 0.9995\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9994\n",
      "Epoch 165: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0060 - r_square: 0.9994 - val_loss: 0.0069 - val_r_square: 0.9993\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9993\n",
      "Epoch 166: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - r_square: 0.9993 - val_loss: 0.0020 - val_r_square: 0.9999\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0020 - r_square: 0.9999\n",
      "Epoch 167: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - r_square: 0.9999 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9998\n",
      "Epoch 168: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - r_square: 0.9998 - val_loss: 0.0047 - val_r_square: 0.9997\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9997\n",
      "Epoch 169: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - r_square: 0.9997 - val_loss: 0.0022 - val_r_square: 0.9999\n",
      "Epoch 170/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - r_square: 0.9999\n",
      "Epoch 170: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - r_square: 0.9999 - val_loss: 0.0064 - val_r_square: 0.9994\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9994\n",
      "Epoch 171: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0064 - r_square: 0.9994 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9998\n",
      "Epoch 172: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - r_square: 0.9998 - val_loss: 0.0083 - val_r_square: 0.9991\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9991\n",
      "Epoch 173: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0083 - r_square: 0.9991 - val_loss: 0.0077 - val_r_square: 0.9992\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9992\n",
      "Epoch 174: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - r_square: 0.9992 - val_loss: 0.0040 - val_r_square: 0.9998\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9998\n",
      "Epoch 175: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - r_square: 0.9998 - val_loss: 0.0053 - val_r_square: 0.9996\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9996\n",
      "Epoch 176: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - r_square: 0.9996 - val_loss: 0.0030 - val_r_square: 0.9998\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9998\n",
      "Epoch 177: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - r_square: 0.9998 - val_loss: 0.0020 - val_r_square: 0.9999\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - r_square: 0.9999\n",
      "Epoch 178: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0019 - r_square: 0.9999 - val_loss: 0.0056 - val_r_square: 0.9996\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9995\n",
      "Epoch 179: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - r_square: 0.9995 - val_loss: 0.0026 - val_r_square: 0.9999\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - r_square: 0.9999\n",
      "Epoch 180: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - r_square: 0.9999 - val_loss: 0.0085 - val_r_square: 0.9990\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9990\n",
      "Epoch 181: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0085 - r_square: 0.9990 - val_loss: 0.0072 - val_r_square: 0.9993\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9993\n",
      "Epoch 182: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0071 - r_square: 0.9993 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 183: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0048 - val_r_square: 0.9996\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9996\n",
      "Epoch 184: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0048 - r_square: 0.9996 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 185: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0054 - val_r_square: 0.9995\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 186: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0038 - val_r_square: 0.9997\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9997\n",
      "Epoch 187: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - r_square: 0.9997 - val_loss: 0.0023 - val_r_square: 0.9999\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - r_square: 0.9999\n",
      "Epoch 188: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - r_square: 0.9999 - val_loss: 0.0059 - val_r_square: 0.9995\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 189: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0030 - val_r_square: 0.9998\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9998\n",
      "Epoch 190: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - r_square: 0.9998 - val_loss: 0.0069 - val_r_square: 0.9993\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9993\n",
      "Epoch 191: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0069 - r_square: 0.9993 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 192: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9995\n",
      "Epoch 193: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - r_square: 0.9995 - val_loss: 0.0060 - val_r_square: 0.9995\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9995\n",
      "Epoch 194: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0060 - r_square: 0.9995 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9996\n",
      "Epoch 195: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - r_square: 0.9996 - val_loss: 0.0056 - val_r_square: 0.9995\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9995\n",
      "Epoch 196: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - r_square: 0.9995 - val_loss: 0.0031 - val_r_square: 0.9998\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9998\n",
      "Epoch 197: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - r_square: 0.9998 - val_loss: 0.0020 - val_r_square: 0.9999\n",
      "Epoch 198/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - r_square: 0.9999\n",
      "Epoch 198: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - r_square: 0.9999 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 199: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 200: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0088 - val_r_square: 0.9990\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0088 - r_square: 0.9990\n",
      "Epoch 201: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0088 - r_square: 0.9990 - val_loss: 0.0068 - val_r_square: 0.9993\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9993\n",
      "Epoch 202: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9993 - val_loss: 0.0052 - val_r_square: 0.9995\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 203: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0058 - val_r_square: 0.9994\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9994\n",
      "Epoch 204: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0058 - r_square: 0.9994 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9997\n",
      "Epoch 205: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - r_square: 0.9997 - val_loss: 0.0055 - val_r_square: 0.9995\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 206: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0028 - val_r_square: 0.9999\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9999\n",
      "Epoch 207: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - r_square: 0.9999 - val_loss: 0.0064 - val_r_square: 0.9994\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 208: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0034 - val_r_square: 0.9998\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 209: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0083 - val_r_square: 0.9991\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9990\n",
      "Epoch 210: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0082 - r_square: 0.9990 - val_loss: 0.0080 - val_r_square: 0.9990\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9990\n",
      "Epoch 211: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0079 - r_square: 0.9990 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 212: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0094 - val_r_square: 0.9987\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9987\n",
      "Epoch 213: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0095 - r_square: 0.9987 - val_loss: 0.0065 - val_r_square: 0.9993\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9993\n",
      "Epoch 214: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0066 - r_square: 0.9993 - val_loss: 0.0052 - val_r_square: 0.9995\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9995\n",
      "Epoch 215: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - r_square: 0.9995 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9995\n",
      "Epoch 216: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - r_square: 0.9995 - val_loss: 0.0053 - val_r_square: 0.9996\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9996\n",
      "Epoch 217: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - r_square: 0.9996 - val_loss: 0.0058 - val_r_square: 0.9995\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 218: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0034 - val_r_square: 0.9998\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - r_square: 0.9998\n",
      "Epoch 219: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - r_square: 0.9998 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0020 - r_square: 0.9999\n",
      "Epoch 220: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - r_square: 0.9999 - val_loss: 0.0071 - val_r_square: 0.9993\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9993\n",
      "Epoch 221: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0071 - r_square: 0.9993 - val_loss: 0.0047 - val_r_square: 0.9997\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 222: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0073 - val_r_square: 0.9993\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9993\n",
      "Epoch 223: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - r_square: 0.9993 - val_loss: 0.0080 - val_r_square: 0.9991\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9991\n",
      "Epoch 224: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0080 - r_square: 0.9991 - val_loss: 0.0018 - val_r_square: 0.9999\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 0.9999\n",
      "Epoch 225: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0018 - r_square: 0.9999 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9997\n",
      "Epoch 226: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0049 - r_square: 0.9997 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 227: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0010 - val_r_square: 1.0000\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.8846e-04 - r_square: 1.0000\n",
      "Epoch 228: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.8846e-04 - r_square: 1.0000 - val_loss: 0.0028 - val_r_square: 0.9999\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9999\n",
      "Epoch 229: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - r_square: 0.9999 - val_loss: 0.0033 - val_r_square: 0.9998\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 230: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0027 - val_r_square: 0.9999\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9999\n",
      "Epoch 231: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - r_square: 0.9999 - val_loss: 0.0022 - val_r_square: 0.9999\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - r_square: 0.9999\n",
      "Epoch 232: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - r_square: 0.9999 - val_loss: 0.0039 - val_r_square: 0.9998\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9998\n",
      "Epoch 233: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0038 - r_square: 0.9998 - val_loss: 0.0024 - val_r_square: 0.9999\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - r_square: 0.9999\n",
      "Epoch 234: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - r_square: 0.9999 - val_loss: 0.0012 - val_r_square: 1.0000\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 235: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0034 - val_r_square: 0.9998\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 236: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0025 - val_r_square: 0.9998\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - r_square: 0.9998\n",
      "Epoch 237: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - r_square: 0.9998 - val_loss: 0.0031 - val_r_square: 0.9998\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 238: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0028 - val_r_square: 0.9999\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9999\n",
      "Epoch 239: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0028 - r_square: 0.9999 - val_loss: 0.0032 - val_r_square: 0.9998\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 240: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0025 - val_r_square: 0.9999\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - r_square: 0.9999\n",
      "Epoch 241: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - r_square: 0.9999 - val_loss: 0.0013 - val_r_square: 1.0000\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 242: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0032 - val_r_square: 0.9998\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 243: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0030 - val_r_square: 0.9999\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9999\n",
      "Epoch 244: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - r_square: 0.9999 - val_loss: 0.0017 - val_r_square: 0.9999\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - r_square: 0.9999\n",
      "Epoch 245: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - r_square: 0.9999 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - r_square: 0.9998\n",
      "Epoch 246: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - r_square: 0.9998 - val_loss: 0.0033 - val_r_square: 0.9998\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - r_square: 0.9998\n",
      "Epoch 247: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - r_square: 0.9998 - val_loss: 0.0011 - val_r_square: 1.0000\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - r_square: 1.0000\n",
      "Epoch 248: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - r_square: 1.0000 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 249: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 250: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0013 - val_r_square: 1.0000\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 1.0000\n",
      "Epoch 251: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - r_square: 1.0000 - val_loss: 0.0093 - val_r_square: 0.9989\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 252: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0082 - val_r_square: 0.9991\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9991\n",
      "Epoch 253: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0081 - r_square: 0.9991 - val_loss: 0.0029 - val_r_square: 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 254: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0033 - val_r_square: 0.9998\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 255: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0060 - val_r_square: 0.9995\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 256: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 257: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0057 - val_r_square: 0.9995\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9995\n",
      "Epoch 258: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - r_square: 0.9995 - val_loss: 0.0047 - val_r_square: 0.9997\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9996\n",
      "Epoch 259: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - r_square: 0.9996 - val_loss: 0.0060 - val_r_square: 0.9995\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 260: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0057 - val_r_square: 0.9995\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9995\n",
      "Epoch 261: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - r_square: 0.9995 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 262: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0037 - val_r_square: 0.9998\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9998\n",
      "Epoch 263: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - r_square: 0.9998 - val_loss: 0.0051 - val_r_square: 0.9996\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9996\n",
      "Epoch 264: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9996 - val_loss: 0.0033 - val_r_square: 0.9998\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 265: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0063 - val_r_square: 0.9995\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9995\n",
      "Epoch 266: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0064 - r_square: 0.9995 - val_loss: 0.0050 - val_r_square: 0.9997\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9997\n",
      "Epoch 267: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9997 - val_loss: 0.0058 - val_r_square: 0.9995\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 268: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0058 - val_r_square: 0.9996\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9996\n",
      "Epoch 269: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0057 - r_square: 0.9996 - val_loss: 0.0042 - val_r_square: 0.9997\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9997\n",
      "Epoch 270: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - r_square: 0.9997 - val_loss: 0.0043 - val_r_square: 0.9997\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9997\n",
      "Epoch 271: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - r_square: 0.9997 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 272: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0026 - val_r_square: 0.9999\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - r_square: 0.9999\n",
      "Epoch 273: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - r_square: 0.9999 - val_loss: 0.0087 - val_r_square: 0.9990\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0087 - r_square: 0.9990\n",
      "Epoch 274: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0087 - r_square: 0.9990 - val_loss: 0.0092 - val_r_square: 0.9989\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9989\n",
      "Epoch 275: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0092 - r_square: 0.9989 - val_loss: 0.0013 - val_r_square: 1.0000\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 1.0000\n",
      "Epoch 276: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0013 - r_square: 1.0000 - val_loss: 0.0124 - val_r_square: 0.9981\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0124 - r_square: 0.9980\n",
      "Epoch 277: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0124 - r_square: 0.9980 - val_loss: 0.0140 - val_r_square: 0.9976\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0140 - r_square: 0.9975\n",
      "Epoch 278: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0140 - r_square: 0.9975 - val_loss: 0.0057 - val_r_square: 0.9996\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9996\n",
      "Epoch 279: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0057 - r_square: 0.9996 - val_loss: 0.0113 - val_r_square: 0.9984\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - r_square: 0.9983\n",
      "Epoch 280: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0113 - r_square: 0.9983 - val_loss: 0.0170 - val_r_square: 0.9964\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0170 - r_square: 0.9963\n",
      "Epoch 281: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0170 - r_square: 0.9963 - val_loss: 0.0125 - val_r_square: 0.9980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0125 - r_square: 0.9979\n",
      "Epoch 282: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0125 - r_square: 0.9979 - val_loss: 0.0029 - val_r_square: 0.9999\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 283: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0094 - val_r_square: 0.9988\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9988\n",
      "Epoch 284: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0094 - r_square: 0.9988 - val_loss: 0.0072 - val_r_square: 0.9993\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9993\n",
      "Epoch 285: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0072 - r_square: 0.9993 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 286: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 287: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9998\n",
      "Epoch 288: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - r_square: 0.9998 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 289: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0073 - val_r_square: 0.9993\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9993\n",
      "Epoch 290: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0073 - r_square: 0.9993 - val_loss: 0.0063 - val_r_square: 0.9995\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9995\n",
      "Epoch 291: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - r_square: 0.9995 - val_loss: 0.0040 - val_r_square: 0.9998\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9998\n",
      "Epoch 292: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0040 - r_square: 0.9998 - val_loss: 0.0037 - val_r_square: 0.9998\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9998\n",
      "Epoch 293: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - r_square: 0.9998 - val_loss: 0.0061 - val_r_square: 0.9995\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9995\n",
      "Epoch 294: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0061 - r_square: 0.9995 - val_loss: 0.0060 - val_r_square: 0.9995\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9995\n",
      "Epoch 295: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0060 - r_square: 0.9995 - val_loss: 0.0032 - val_r_square: 0.9998\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 296: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0047 - val_r_square: 0.9997\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 297: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9998\n",
      "Epoch 298: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - r_square: 0.9998 - val_loss: 0.0031 - val_r_square: 0.9999\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9999\n",
      "Epoch 299: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - r_square: 0.9999 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 300: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0031 - val_r_square: 0.9998\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9998\n",
      "Epoch 301: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - r_square: 0.9998 - val_loss: 0.0069 - val_r_square: 0.9994\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9993\n",
      "Epoch 302: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0070 - r_square: 0.9993 - val_loss: 0.0065 - val_r_square: 0.9994\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 303: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - r_square: 0.9998\n",
      "Epoch 304: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - r_square: 0.9998 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 305: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0029 - val_r_square: 0.9999\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 306: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0035 - val_r_square: 0.9998\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9998\n",
      "Epoch 307: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - r_square: 0.9998 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9997\n",
      "Epoch 308: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0047 - r_square: 0.9997 - val_loss: 0.0030 - val_r_square: 0.9999\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 309: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0078 - val_r_square: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9992\n",
      "Epoch 310: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0079 - r_square: 0.9992 - val_loss: 0.0082 - val_r_square: 0.9991\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9991\n",
      "Epoch 311: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0083 - r_square: 0.9991 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - r_square: 0.9999\n",
      "Epoch 312: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0015 - r_square: 0.9999 - val_loss: 0.0122 - val_r_square: 0.9981\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0122 - r_square: 0.9981\n",
      "Epoch 313: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0122 - r_square: 0.9981 - val_loss: 0.0133 - val_r_square: 0.9978\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0132 - r_square: 0.9978\n",
      "Epoch 314: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0132 - r_square: 0.9978 - val_loss: 0.0049 - val_r_square: 0.9997\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9997\n",
      "Epoch 315: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0049 - r_square: 0.9997 - val_loss: 0.0119 - val_r_square: 0.9982\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0120 - r_square: 0.9982\n",
      "Epoch 316: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0120 - r_square: 0.9982 - val_loss: 0.0178 - val_r_square: 0.9961\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0178 - r_square: 0.9960\n",
      "Epoch 317: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0178 - r_square: 0.9960 - val_loss: 0.0137 - val_r_square: 0.9976\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0138 - r_square: 0.9976\n",
      "Epoch 318: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0138 - r_square: 0.9976 - val_loss: 0.0018 - val_r_square: 0.9999\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 0.9999\n",
      "Epoch 319: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0018 - r_square: 0.9999 - val_loss: 0.0128 - val_r_square: 0.9979\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0128 - r_square: 0.9979\n",
      "Epoch 320: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0128 - r_square: 0.9979 - val_loss: 0.0159 - val_r_square: 0.9969\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0159 - r_square: 0.9968\n",
      "Epoch 321: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0159 - r_square: 0.9968 - val_loss: 0.0093 - val_r_square: 0.9989\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 322: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0058 - val_r_square: 0.9995\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 323: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0102 - val_r_square: 0.9986\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - r_square: 0.9986\n",
      "Epoch 324: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0101 - r_square: 0.9986 - val_loss: 0.0049 - val_r_square: 0.9996\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9996\n",
      "Epoch 325: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - r_square: 0.9996 - val_loss: 0.0086 - val_r_square: 0.9990\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9990\n",
      "Epoch 326: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0086 - r_square: 0.9990 - val_loss: 0.0115 - val_r_square: 0.9982\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0116 - r_square: 0.9982\n",
      "Epoch 327: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0116 - r_square: 0.9982 - val_loss: 0.0055 - val_r_square: 0.9995\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9995\n",
      "Epoch 328: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - r_square: 0.9995 - val_loss: 0.0065 - val_r_square: 0.9993\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9993\n",
      "Epoch 329: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - r_square: 0.9993 - val_loss: 0.0078 - val_r_square: 0.9991\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9991\n",
      "Epoch 330: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - r_square: 0.9991 - val_loss: 0.0025 - val_r_square: 0.9999\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - r_square: 0.9999\n",
      "Epoch 331: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - r_square: 0.9999 - val_loss: 0.0074 - val_r_square: 0.9993\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9993\n",
      "Epoch 332: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0074 - r_square: 0.9993 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 333: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0071 - val_r_square: 0.9993\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9993\n",
      "Epoch 334: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0071 - r_square: 0.9993 - val_loss: 0.0087 - val_r_square: 0.9990\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0087 - r_square: 0.9990\n",
      "Epoch 335: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0087 - r_square: 0.9990 - val_loss: 0.0029 - val_r_square: 0.9998\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9998\n",
      "Epoch 336: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - r_square: 0.9998 - val_loss: 0.0110 - val_r_square: 0.9983\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9983\n",
      "Epoch 337: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0110 - r_square: 0.9983 - val_loss: 0.0130 - val_r_square: 0.9978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0130 - r_square: 0.9977\n",
      "Epoch 338: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0130 - r_square: 0.9977 - val_loss: 0.0056 - val_r_square: 0.9995\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9995\n",
      "Epoch 339: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0056 - r_square: 0.9995 - val_loss: 0.0101 - val_r_square: 0.9987\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - r_square: 0.9987\n",
      "Epoch 340: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0101 - r_square: 0.9987 - val_loss: 0.0152 - val_r_square: 0.9971\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0152 - r_square: 0.9971\n",
      "Epoch 341: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0152 - r_square: 0.9971 - val_loss: 0.0106 - val_r_square: 0.9986\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9985\n",
      "Epoch 342: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0106 - r_square: 0.9985 - val_loss: 0.0031 - val_r_square: 0.9999\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9999\n",
      "Epoch 343: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - r_square: 0.9999 - val_loss: 0.0082 - val_r_square: 0.9991\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9991\n",
      "Epoch 344: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0082 - r_square: 0.9991 - val_loss: 0.0042 - val_r_square: 0.9998\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0042 - r_square: 0.9998\n",
      "Epoch 345: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - r_square: 0.9998 - val_loss: 0.0085 - val_r_square: 0.9991\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9991\n",
      "Epoch 346: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0085 - r_square: 0.9991 - val_loss: 0.0109 - val_r_square: 0.9985\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0109 - r_square: 0.9985\n",
      "Epoch 347: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0109 - r_square: 0.9985 - val_loss: 0.0041 - val_r_square: 0.9998\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9998\n",
      "Epoch 348: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9998 - val_loss: 0.0106 - val_r_square: 0.9986\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9986\n",
      "Epoch 349: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0106 - r_square: 0.9986 - val_loss: 0.0147 - val_r_square: 0.9973\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0147 - r_square: 0.9973\n",
      "Epoch 350: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0147 - r_square: 0.9973 - val_loss: 0.0094 - val_r_square: 0.9989\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 351: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 352: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0089 - val_r_square: 0.9989\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9989\n",
      "Epoch 353: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0090 - r_square: 0.9989 - val_loss: 0.0043 - val_r_square: 0.9997\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9997\n",
      "Epoch 354: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - r_square: 0.9997 - val_loss: 0.0079 - val_r_square: 0.9992\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9992\n",
      "Epoch 355: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0078 - r_square: 0.9992 - val_loss: 0.0097 - val_r_square: 0.9988\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9988\n",
      "Epoch 356: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - r_square: 0.9988 - val_loss: 0.0028 - val_r_square: 0.9999\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9999\n",
      "Epoch 357: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - r_square: 0.9999 - val_loss: 0.0107 - val_r_square: 0.9986\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9985\n",
      "Epoch 358: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0107 - r_square: 0.9985 - val_loss: 0.0135 - val_r_square: 0.9977\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0135 - r_square: 0.9977\n",
      "Epoch 359: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0135 - r_square: 0.9977 - val_loss: 0.0072 - val_r_square: 0.9993\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9993\n",
      "Epoch 360: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0072 - r_square: 0.9993 - val_loss: 0.0075 - val_r_square: 0.9993\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9993\n",
      "Epoch 361: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0074 - r_square: 0.9993 - val_loss: 0.0117 - val_r_square: 0.9982\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0117 - r_square: 0.9982\n",
      "Epoch 362: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0117 - r_square: 0.9982 - val_loss: 0.0066 - val_r_square: 0.9994\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9994\n",
      "Epoch 363: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0066 - r_square: 0.9994 - val_loss: 0.0069 - val_r_square: 0.9994\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9993\n",
      "Epoch 364: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0069 - r_square: 0.9993 - val_loss: 0.0101 - val_r_square: 0.9987\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9986\n",
      "Epoch 365: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0102 - r_square: 0.9986 - val_loss: 0.0047 - val_r_square: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9997\n",
      "Epoch 366: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9997 - val_loss: 0.0081 - val_r_square: 0.9990\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9990\n",
      "Epoch 367: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0081 - r_square: 0.9990 - val_loss: 0.0103 - val_r_square: 0.9986\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9986\n",
      "Epoch 368: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0102 - r_square: 0.9986 - val_loss: 0.0034 - val_r_square: 0.9998\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 369: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0102 - val_r_square: 0.9987\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9986\n",
      "Epoch 370: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0103 - r_square: 0.9986 - val_loss: 0.0135 - val_r_square: 0.9977\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0135 - r_square: 0.9977\n",
      "Epoch 371: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0135 - r_square: 0.9977 - val_loss: 0.0076 - val_r_square: 0.9993\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9992\n",
      "Epoch 372: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - r_square: 0.9992 - val_loss: 0.0065 - val_r_square: 0.9995\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 373: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0104 - val_r_square: 0.9986\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9986\n",
      "Epoch 374: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0103 - r_square: 0.9986 - val_loss: 0.0050 - val_r_square: 0.9997\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9997\n",
      "Epoch 375: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0050 - r_square: 0.9997 - val_loss: 0.0085 - val_r_square: 0.9991\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9990\n",
      "Epoch 376: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0086 - r_square: 0.9990 - val_loss: 0.0119 - val_r_square: 0.9982\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0120 - r_square: 0.9981\n",
      "Epoch 377: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0120 - r_square: 0.9981 - val_loss: 0.0063 - val_r_square: 0.9995\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9994\n",
      "Epoch 378: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - r_square: 0.9994 - val_loss: 0.0075 - val_r_square: 0.9993\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9993\n",
      "Epoch 379: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - r_square: 0.9993 - val_loss: 0.0110 - val_r_square: 0.9985\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9984\n",
      "Epoch 380: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0110 - r_square: 0.9984 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 381: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0081 - val_r_square: 0.9991\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9991\n",
      "Epoch 382: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0081 - r_square: 0.9991 - val_loss: 0.0116 - val_r_square: 0.9982\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0116 - r_square: 0.9982\n",
      "Epoch 383: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0116 - r_square: 0.9982 - val_loss: 0.0061 - val_r_square: 0.9994\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9994\n",
      "Epoch 384: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - r_square: 0.9994 - val_loss: 0.0073 - val_r_square: 0.9993\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9993\n",
      "Epoch 385: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0072 - r_square: 0.9993 - val_loss: 0.0107 - val_r_square: 0.9985\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9985\n",
      "Epoch 386: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0106 - r_square: 0.9985 - val_loss: 0.0050 - val_r_square: 0.9996\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9996\n",
      "Epoch 387: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - r_square: 0.9996 - val_loss: 0.0085 - val_r_square: 0.9990\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9990\n",
      "Epoch 388: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0086 - r_square: 0.9990 - val_loss: 0.0121 - val_r_square: 0.9981\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0121 - r_square: 0.9980\n",
      "Epoch 389: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0121 - r_square: 0.9980 - val_loss: 0.0066 - val_r_square: 0.9994\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9994\n",
      "Epoch 390: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0066 - r_square: 0.9994 - val_loss: 0.0068 - val_r_square: 0.9994\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9994\n",
      "Epoch 391: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0068 - r_square: 0.9994 - val_loss: 0.0102 - val_r_square: 0.9987\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9986\n",
      "Epoch 392: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0102 - r_square: 0.9986 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 393: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0090 - val_r_square: 0.9989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9989\n",
      "Epoch 394: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0090 - r_square: 0.9989 - val_loss: 0.0125 - val_r_square: 0.9980\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0126 - r_square: 0.9979\n",
      "Epoch 395: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0126 - r_square: 0.9979 - val_loss: 0.0071 - val_r_square: 0.9993\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9993\n",
      "Epoch 396: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0072 - r_square: 0.9993 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9995\n",
      "Epoch 397: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - r_square: 0.9995 - val_loss: 0.0096 - val_r_square: 0.9988\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9988\n",
      "Epoch 398: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0096 - r_square: 0.9988 - val_loss: 0.0041 - val_r_square: 0.9997\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9997\n",
      "Epoch 399: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - r_square: 0.9997 - val_loss: 0.0095 - val_r_square: 0.9988\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 400: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0131 - val_r_square: 0.9978\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0131 - r_square: 0.9977\n",
      "Epoch 401: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0131 - r_square: 0.9977 - val_loss: 0.0077 - val_r_square: 0.9992\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9992\n",
      "Epoch 402: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0078 - r_square: 0.9992 - val_loss: 0.0056 - val_r_square: 0.9996\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9996\n",
      "Epoch 403: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - r_square: 0.9996 - val_loss: 0.0091 - val_r_square: 0.9990\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9989\n",
      "Epoch 404: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0090 - r_square: 0.9989 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - r_square: 0.9998\n",
      "Epoch 405: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - r_square: 0.9998 - val_loss: 0.0099 - val_r_square: 0.9987\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9987\n",
      "Epoch 406: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0100 - r_square: 0.9987 - val_loss: 0.0135 - val_r_square: 0.9977\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0135 - r_square: 0.9976\n",
      "Epoch 407: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0135 - r_square: 0.9976 - val_loss: 0.0082 - val_r_square: 0.9991\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9991\n",
      "Epoch 408: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0082 - r_square: 0.9991 - val_loss: 0.0051 - val_r_square: 0.9996\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 409: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0086 - val_r_square: 0.9990\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9990\n",
      "Epoch 410: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0086 - r_square: 0.9990 - val_loss: 0.0032 - val_r_square: 0.9998\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 411: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0092 - val_r_square: 0.9989\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9989\n",
      "Epoch 412: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0092 - r_square: 0.9989 - val_loss: 0.0117 - val_r_square: 0.9982\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0118 - r_square: 0.9982\n",
      "Epoch 413: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0118 - r_square: 0.9982 - val_loss: 0.0056 - val_r_square: 0.9996\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9996\n",
      "Epoch 414: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0056 - r_square: 0.9996 - val_loss: 0.0083 - val_r_square: 0.9991\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9991\n",
      "Epoch 415: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0083 - r_square: 0.9991 - val_loss: 0.0123 - val_r_square: 0.9981\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0123 - r_square: 0.9981\n",
      "Epoch 416: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0123 - r_square: 0.9981 - val_loss: 0.0074 - val_r_square: 0.9993\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9993\n",
      "Epoch 417: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - r_square: 0.9993 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 418: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0088 - val_r_square: 0.9990\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0088 - r_square: 0.9990\n",
      "Epoch 419: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0088 - r_square: 0.9990 - val_loss: 0.0033 - val_r_square: 0.9998\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - r_square: 0.9998\n",
      "Epoch 420: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - r_square: 0.9998 - val_loss: 0.0094 - val_r_square: 0.9989\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 421: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0122 - val_r_square: 0.9981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0122 - r_square: 0.9981\n",
      "Epoch 422: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0122 - r_square: 0.9981 - val_loss: 0.0063 - val_r_square: 0.9995\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9995\n",
      "Epoch 423: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - r_square: 0.9995 - val_loss: 0.0075 - val_r_square: 0.9993\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9993\n",
      "Epoch 424: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0075 - r_square: 0.9993 - val_loss: 0.0114 - val_r_square: 0.9984\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0114 - r_square: 0.9983\n",
      "Epoch 425: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0114 - r_square: 0.9983 - val_loss: 0.0065 - val_r_square: 0.9995\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 426: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0064 - val_r_square: 0.9995\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9995\n",
      "Epoch 427: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - r_square: 0.9995 - val_loss: 0.0095 - val_r_square: 0.9988\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 428: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0039 - val_r_square: 0.9998\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9998\n",
      "Epoch 429: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - r_square: 0.9998 - val_loss: 0.0096 - val_r_square: 0.9988\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9988\n",
      "Epoch 430: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0096 - r_square: 0.9988 - val_loss: 0.0133 - val_r_square: 0.9978\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0133 - r_square: 0.9977\n",
      "Epoch 431: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0133 - r_square: 0.9977 - val_loss: 0.0082 - val_r_square: 0.9991\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9991\n",
      "Epoch 432: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0083 - r_square: 0.9991 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9997\n",
      "Epoch 433: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9997 - val_loss: 0.0081 - val_r_square: 0.9992\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9991\n",
      "Epoch 434: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0080 - r_square: 0.9991 - val_loss: 0.0027 - val_r_square: 0.9999\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9999\n",
      "Epoch 435: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - r_square: 0.9999 - val_loss: 0.0089 - val_r_square: 0.9990\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9990\n",
      "Epoch 436: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0090 - r_square: 0.9990 - val_loss: 0.0109 - val_r_square: 0.9985\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0109 - r_square: 0.9985\n",
      "Epoch 437: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0109 - r_square: 0.9985 - val_loss: 0.0043 - val_r_square: 0.9998\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 438: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0099 - val_r_square: 0.9988\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9988\n",
      "Epoch 439: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0098 - r_square: 0.9988 - val_loss: 0.0143 - val_r_square: 0.9975\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0142 - r_square: 0.9974\n",
      "Epoch 440: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0142 - r_square: 0.9974 - val_loss: 0.0099 - val_r_square: 0.9988\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9988\n",
      "Epoch 441: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0098 - r_square: 0.9988 - val_loss: 0.0028 - val_r_square: 0.9999\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9999\n",
      "Epoch 442: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - r_square: 0.9999 - val_loss: 0.0069 - val_r_square: 0.9994\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9993\n",
      "Epoch 443: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0070 - r_square: 0.9993 - val_loss: 0.0028 - val_r_square: 0.9999\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 444: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0082 - val_r_square: 0.9992\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9992\n",
      "Epoch 445: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0081 - r_square: 0.9992 - val_loss: 0.0095 - val_r_square: 0.9989\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 446: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0024 - val_r_square: 0.9999\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0023 - r_square: 0.9999\n",
      "Epoch 447: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - r_square: 0.9999 - val_loss: 0.0121 - val_r_square: 0.9982\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0121 - r_square: 0.9981\n",
      "Epoch 448: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0121 - r_square: 0.9981 - val_loss: 0.0168 - val_r_square: 0.9965\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0168 - r_square: 0.9964\n",
      "Epoch 449: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0168 - r_square: 0.9964 - val_loss: 0.0127 - val_r_square: 0.9980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0127 - r_square: 0.9979\n",
      "Epoch 450: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0127 - r_square: 0.9979 - val_loss: 0.0014 - val_r_square: 1.0000\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - r_square: 1.0000\n",
      "Epoch 451: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0014 - r_square: 1.0000 - val_loss: 0.0126 - val_r_square: 0.9980\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0125 - r_square: 0.9980\n",
      "Epoch 452: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0125 - r_square: 0.9980 - val_loss: 0.0162 - val_r_square: 0.9968\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0161 - r_square: 0.9967\n",
      "Epoch 453: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0161 - r_square: 0.9967 - val_loss: 0.0110 - val_r_square: 0.9985\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9985\n",
      "Epoch 454: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0110 - r_square: 0.9985 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 455: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0068 - val_r_square: 0.9994\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9994\n",
      "Epoch 456: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0068 - r_square: 0.9994 - val_loss: 0.0030 - val_r_square: 0.9998\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9998\n",
      "Epoch 457: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - r_square: 0.9998 - val_loss: 0.0080 - val_r_square: 0.9992\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9992\n",
      "Epoch 458: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0079 - r_square: 0.9992 - val_loss: 0.0095 - val_r_square: 0.9989\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 459: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0026 - val_r_square: 0.9999\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9999\n",
      "Epoch 460: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - r_square: 0.9999 - val_loss: 0.0100 - val_r_square: 0.9987\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 461: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0129 - val_r_square: 0.9979\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0129 - r_square: 0.9978\n",
      "Epoch 462: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0129 - r_square: 0.9978 - val_loss: 0.0073 - val_r_square: 0.9993\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9993\n",
      "Epoch 463: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0073 - r_square: 0.9993 - val_loss: 0.0060 - val_r_square: 0.9995\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9995\n",
      "Epoch 464: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - r_square: 0.9995 - val_loss: 0.0097 - val_r_square: 0.9988\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9988\n",
      "Epoch 465: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0097 - r_square: 0.9988 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 466: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0079 - val_r_square: 0.9992\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9992\n",
      "Epoch 467: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0079 - r_square: 0.9992 - val_loss: 0.0111 - val_r_square: 0.9984\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0111 - r_square: 0.9984\n",
      "Epoch 468: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0111 - r_square: 0.9984 - val_loss: 0.0057 - val_r_square: 0.9996\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9996\n",
      "Epoch 469: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - r_square: 0.9996 - val_loss: 0.0074 - val_r_square: 0.9993\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9993\n",
      "Epoch 470: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - r_square: 0.9993 - val_loss: 0.0109 - val_r_square: 0.9985\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0109 - r_square: 0.9984\n",
      "Epoch 471: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0109 - r_square: 0.9984 - val_loss: 0.0059 - val_r_square: 0.9995\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 472: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0069 - val_r_square: 0.9994\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9994\n",
      "Epoch 473: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0069 - r_square: 0.9994 - val_loss: 0.0102 - val_r_square: 0.9987\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - r_square: 0.9987\n",
      "Epoch 474: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0101 - r_square: 0.9987 - val_loss: 0.0049 - val_r_square: 0.9997\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9997\n",
      "Epoch 475: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0049 - r_square: 0.9997 - val_loss: 0.0075 - val_r_square: 0.9992\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9992\n",
      "Epoch 476: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0075 - r_square: 0.9992 - val_loss: 0.0105 - val_r_square: 0.9986\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9986\n",
      "Epoch 477: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0105 - r_square: 0.9986 - val_loss: 0.0050 - val_r_square: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9996\n",
      "Epoch 478: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0050 - r_square: 0.9996 - val_loss: 0.0082 - val_r_square: 0.9991\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9991\n",
      "Epoch 479: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0082 - r_square: 0.9991 - val_loss: 0.0119 - val_r_square: 0.9982\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0119 - r_square: 0.9982\n",
      "Epoch 480: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0119 - r_square: 0.9982 - val_loss: 0.0070 - val_r_square: 0.9994\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9993\n",
      "Epoch 481: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0070 - r_square: 0.9993 - val_loss: 0.0056 - val_r_square: 0.9996\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9996\n",
      "Epoch 482: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - r_square: 0.9996 - val_loss: 0.0087 - val_r_square: 0.9990\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0087 - r_square: 0.9990\n",
      "Epoch 483: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0087 - r_square: 0.9990 - val_loss: 0.0034 - val_r_square: 0.9998\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 484: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0091 - val_r_square: 0.9989\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9989\n",
      "Epoch 485: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0091 - r_square: 0.9989 - val_loss: 0.0122 - val_r_square: 0.9981\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0122 - r_square: 0.9981\n",
      "Epoch 486: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0122 - r_square: 0.9981 - val_loss: 0.0068 - val_r_square: 0.9994\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9994\n",
      "Epoch 487: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9994 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9995\n",
      "Epoch 488: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - r_square: 0.9995 - val_loss: 0.0098 - val_r_square: 0.9988\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9988\n",
      "Epoch 489: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0098 - r_square: 0.9988 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 490: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0078 - val_r_square: 0.9992\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9992\n",
      "Epoch 491: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0078 - r_square: 0.9992 - val_loss: 0.0110 - val_r_square: 0.9985\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0109 - r_square: 0.9984\n",
      "Epoch 492: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0109 - r_square: 0.9984 - val_loss: 0.0057 - val_r_square: 0.9996\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9995\n",
      "Epoch 493: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - r_square: 0.9995 - val_loss: 0.0071 - val_r_square: 0.9993\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9993\n",
      "Epoch 494: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0071 - r_square: 0.9993 - val_loss: 0.0106 - val_r_square: 0.9986\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9986\n",
      "Epoch 495: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0106 - r_square: 0.9986 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9996\n",
      "Epoch 496: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - r_square: 0.9996 - val_loss: 0.0071 - val_r_square: 0.9993\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9993\n",
      "Epoch 497: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0071 - r_square: 0.9993 - val_loss: 0.0103 - val_r_square: 0.9986\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9986\n",
      "Epoch 498: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0103 - r_square: 0.9986 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 499: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0075 - val_r_square: 0.9993\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9993\n",
      "Epoch 500: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0075 - r_square: 0.9993 - val_loss: 0.0108 - val_r_square: 0.9985\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9985\n",
      "Epoch 501: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0108 - r_square: 0.9985 - val_loss: 0.0057 - val_r_square: 0.9996\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9996\n",
      "Epoch 502: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - r_square: 0.9996 - val_loss: 0.0069 - val_r_square: 0.9994\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9993\n",
      "Epoch 503: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - r_square: 0.9993 - val_loss: 0.0102 - val_r_square: 0.9986\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9986\n",
      "Epoch 504: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0102 - r_square: 0.9986 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 505: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0074 - val_r_square: 0.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 506/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9993\n",
      "Epoch 506: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0074 - r_square: 0.9993 - val_loss: 0.0107 - val_r_square: 0.9986\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9985\n",
      "Epoch 507: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0107 - r_square: 0.9985 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 508: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0072 - val_r_square: 0.9993\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9993\n",
      "Epoch 509: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0071 - r_square: 0.9993 - val_loss: 0.0105 - val_r_square: 0.9986\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9985\n",
      "Epoch 510: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0105 - r_square: 0.9985 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 511: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0070 - val_r_square: 0.9994\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9993\n",
      "Epoch 512: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0070 - r_square: 0.9993 - val_loss: 0.0102 - val_r_square: 0.9987\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9987\n",
      "Epoch 513: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0102 - r_square: 0.9987 - val_loss: 0.0051 - val_r_square: 0.9996\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 514: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0075 - val_r_square: 0.9992\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9992\n",
      "Epoch 515: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0075 - r_square: 0.9992 - val_loss: 0.0109 - val_r_square: 0.9984\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9984\n",
      "Epoch 516: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0108 - r_square: 0.9984 - val_loss: 0.0059 - val_r_square: 0.9995\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 517: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0066 - val_r_square: 0.9994\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9994\n",
      "Epoch 518: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - r_square: 0.9994 - val_loss: 0.0098 - val_r_square: 0.9988\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 519: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 520: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0077 - val_r_square: 0.9992\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9992\n",
      "Epoch 521: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - r_square: 0.9992 - val_loss: 0.0110 - val_r_square: 0.9984\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9984\n",
      "Epoch 522: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0110 - r_square: 0.9984 - val_loss: 0.0060 - val_r_square: 0.9995\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 523: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0065 - val_r_square: 0.9994\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 524: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0098 - val_r_square: 0.9988\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9987\n",
      "Epoch 525: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0098 - r_square: 0.9987 - val_loss: 0.0047 - val_r_square: 0.9997\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 526: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0077 - val_r_square: 0.9992\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9992\n",
      "Epoch 527: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0077 - r_square: 0.9992 - val_loss: 0.0109 - val_r_square: 0.9984\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0109 - r_square: 0.9984\n",
      "Epoch 528: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0109 - r_square: 0.9984 - val_loss: 0.0059 - val_r_square: 0.9995\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 529: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0066 - val_r_square: 0.9994\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9994\n",
      "Epoch 530: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - r_square: 0.9994 - val_loss: 0.0098 - val_r_square: 0.9988\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9987\n",
      "Epoch 531: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0098 - r_square: 0.9987 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9996\n",
      "Epoch 532: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - r_square: 0.9996 - val_loss: 0.0070 - val_r_square: 0.9993\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9993\n",
      "Epoch 533: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0070 - r_square: 0.9993 - val_loss: 0.0097 - val_r_square: 0.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 534/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9987\n",
      "Epoch 534: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - r_square: 0.9987 - val_loss: 0.0043 - val_r_square: 0.9997\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0042 - r_square: 0.9997\n",
      "Epoch 535: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - r_square: 0.9997 - val_loss: 0.0080 - val_r_square: 0.9992\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9992\n",
      "Epoch 536: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0080 - r_square: 0.9992 - val_loss: 0.0111 - val_r_square: 0.9985\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0111 - r_square: 0.9984\n",
      "Epoch 537: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0111 - r_square: 0.9984 - val_loss: 0.0059 - val_r_square: 0.9995\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 538: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0067 - val_r_square: 0.9994\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9994\n",
      "Epoch 539: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0067 - r_square: 0.9994 - val_loss: 0.0101 - val_r_square: 0.9987\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - r_square: 0.9987\n",
      "Epoch 540: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0101 - r_square: 0.9987 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 541: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0070 - val_r_square: 0.9994\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9994\n",
      "Epoch 542: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0070 - r_square: 0.9994 - val_loss: 0.0102 - val_r_square: 0.9987\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9987\n",
      "Epoch 543: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0102 - r_square: 0.9987 - val_loss: 0.0051 - val_r_square: 0.9997\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9997\n",
      "Epoch 544: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - r_square: 0.9997 - val_loss: 0.0074 - val_r_square: 0.9993\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9993\n",
      "Epoch 545: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - r_square: 0.9993 - val_loss: 0.0108 - val_r_square: 0.9985\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9985\n",
      "Epoch 546: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0107 - r_square: 0.9985 - val_loss: 0.0059 - val_r_square: 0.9995\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 547: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0064 - val_r_square: 0.9995\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9995\n",
      "Epoch 548: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0064 - r_square: 0.9995 - val_loss: 0.0096 - val_r_square: 0.9988\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9988\n",
      "Epoch 549: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0096 - r_square: 0.9988 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 550: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0078 - val_r_square: 0.9992\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9992\n",
      "Epoch 551: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0078 - r_square: 0.9992 - val_loss: 0.0111 - val_r_square: 0.9984\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0111 - r_square: 0.9984\n",
      "Epoch 552: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0111 - r_square: 0.9984 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9995\n",
      "Epoch 553: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - r_square: 0.9995 - val_loss: 0.0061 - val_r_square: 0.9995\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9995\n",
      "Epoch 554: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0061 - r_square: 0.9995 - val_loss: 0.0093 - val_r_square: 0.9989\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 555: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0043 - val_r_square: 0.9997\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9997\n",
      "Epoch 556: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - r_square: 0.9997 - val_loss: 0.0081 - val_r_square: 0.9991\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9991\n",
      "Epoch 557: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0081 - r_square: 0.9991 - val_loss: 0.0113 - val_r_square: 0.9984\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - r_square: 0.9983\n",
      "Epoch 558: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0113 - r_square: 0.9983 - val_loss: 0.0064 - val_r_square: 0.9994\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9994\n",
      "Epoch 559: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - r_square: 0.9994 - val_loss: 0.0059 - val_r_square: 0.9995\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 560: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0091 - val_r_square: 0.9990\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9989\n",
      "Epoch 561: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0091 - r_square: 0.9989 - val_loss: 0.0041 - val_r_square: 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 562/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9998\n",
      "Epoch 562: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9998 - val_loss: 0.0082 - val_r_square: 0.9991\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9991\n",
      "Epoch 563: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0082 - r_square: 0.9991 - val_loss: 0.0114 - val_r_square: 0.9983\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0114 - r_square: 0.9983\n",
      "Epoch 564: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0114 - r_square: 0.9983 - val_loss: 0.0065 - val_r_square: 0.9994\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 565: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0058 - val_r_square: 0.9996\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 566: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0090 - val_r_square: 0.9990\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9989\n",
      "Epoch 567: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0090 - r_square: 0.9989 - val_loss: 0.0041 - val_r_square: 0.9998\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9998\n",
      "Epoch 568: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9998 - val_loss: 0.0081 - val_r_square: 0.9991\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9991\n",
      "Epoch 569: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0081 - r_square: 0.9991 - val_loss: 0.0113 - val_r_square: 0.9983\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - r_square: 0.9983\n",
      "Epoch 570: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0113 - r_square: 0.9983 - val_loss: 0.0063 - val_r_square: 0.9994\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9994\n",
      "Epoch 571: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - r_square: 0.9994 - val_loss: 0.0059 - val_r_square: 0.9995\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 572: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0091 - val_r_square: 0.9989\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9989\n",
      "Epoch 573: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0091 - r_square: 0.9989 - val_loss: 0.0043 - val_r_square: 0.9997\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9997\n",
      "Epoch 574: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - r_square: 0.9997 - val_loss: 0.0079 - val_r_square: 0.9992\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9991\n",
      "Epoch 575: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0079 - r_square: 0.9991 - val_loss: 0.0111 - val_r_square: 0.9984\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9984\n",
      "Epoch 576: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0110 - r_square: 0.9984 - val_loss: 0.0061 - val_r_square: 0.9995\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9995\n",
      "Epoch 577: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0061 - r_square: 0.9995 - val_loss: 0.0061 - val_r_square: 0.9995\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9995\n",
      "Epoch 578: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - r_square: 0.9995 - val_loss: 0.0093 - val_r_square: 0.9989\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 579: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 580: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0077 - val_r_square: 0.9992\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9992\n",
      "Epoch 581: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - r_square: 0.9992 - val_loss: 0.0109 - val_r_square: 0.9984\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9984\n",
      "Epoch 582: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0108 - r_square: 0.9984 - val_loss: 0.0060 - val_r_square: 0.9995\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 583: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9995\n",
      "Epoch 584: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - r_square: 0.9995 - val_loss: 0.0093 - val_r_square: 0.9989\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9989\n",
      "Epoch 585: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0094 - r_square: 0.9989 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 586: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0069 - val_r_square: 0.9993\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9993\n",
      "Epoch 587: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0069 - r_square: 0.9993 - val_loss: 0.0094 - val_r_square: 0.9988\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9988\n",
      "Epoch 588: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0094 - r_square: 0.9988 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9997\n",
      "Epoch 589: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - r_square: 0.9997 - val_loss: 0.0081 - val_r_square: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 590/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9991\n",
      "Epoch 590: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0081 - r_square: 0.9991 - val_loss: 0.0111 - val_r_square: 0.9984\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0111 - r_square: 0.9984\n",
      "Epoch 591: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0111 - r_square: 0.9984 - val_loss: 0.0061 - val_r_square: 0.9995\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9995\n",
      "Epoch 592: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - r_square: 0.9995 - val_loss: 0.0061 - val_r_square: 0.9995\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9995\n",
      "Epoch 593: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0061 - r_square: 0.9995 - val_loss: 0.0093 - val_r_square: 0.9989\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9988\n",
      "Epoch 594: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0093 - r_square: 0.9988 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 595: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0074 - val_r_square: 0.9993\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9993\n",
      "Epoch 596: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - r_square: 0.9993 - val_loss: 0.0105 - val_r_square: 0.9986\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9986\n",
      "Epoch 597: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0105 - r_square: 0.9986 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 598: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0067 - val_r_square: 0.9994\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9994\n",
      "Epoch 599: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0067 - r_square: 0.9994 - val_loss: 0.0099 - val_r_square: 0.9987\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 600: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0051 - val_r_square: 0.9996\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 601: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0069 - val_r_square: 0.9994\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9994\n",
      "Epoch 602: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - r_square: 0.9994 - val_loss: 0.0100 - val_r_square: 0.9987\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9987\n",
      "Epoch 603: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0100 - r_square: 0.9987 - val_loss: 0.0051 - val_r_square: 0.9997\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9997\n",
      "Epoch 604: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - r_square: 0.9997 - val_loss: 0.0071 - val_r_square: 0.9994\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9993\n",
      "Epoch 605: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0071 - r_square: 0.9993 - val_loss: 0.0103 - val_r_square: 0.9987\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9986\n",
      "Epoch 606: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0103 - r_square: 0.9986 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 607: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0066 - val_r_square: 0.9994\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 608: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0097 - val_r_square: 0.9988\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9988\n",
      "Epoch 609: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0097 - r_square: 0.9988 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 610: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0073 - val_r_square: 0.9993\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9993\n",
      "Epoch 611: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0073 - r_square: 0.9993 - val_loss: 0.0105 - val_r_square: 0.9986\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9986\n",
      "Epoch 612: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0105 - r_square: 0.9986 - val_loss: 0.0056 - val_r_square: 0.9996\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9996\n",
      "Epoch 613: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - r_square: 0.9996 - val_loss: 0.0064 - val_r_square: 0.9995\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9995\n",
      "Epoch 614: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - r_square: 0.9995 - val_loss: 0.0095 - val_r_square: 0.9989\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 615: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 616: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0074 - val_r_square: 0.9993\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9993\n",
      "Epoch 617: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0074 - r_square: 0.9993 - val_loss: 0.0106 - val_r_square: 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 618/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9985\n",
      "Epoch 618: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0106 - r_square: 0.9985 - val_loss: 0.0058 - val_r_square: 0.9995\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 619: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9995\n",
      "Epoch 620: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - r_square: 0.9995 - val_loss: 0.0093 - val_r_square: 0.9989\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 621: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 622: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0075 - val_r_square: 0.9993\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9992\n",
      "Epoch 623: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0075 - r_square: 0.9992 - val_loss: 0.0106 - val_r_square: 0.9986\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9985\n",
      "Epoch 624: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0106 - r_square: 0.9985 - val_loss: 0.0057 - val_r_square: 0.9995\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9995\n",
      "Epoch 625: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - r_square: 0.9995 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9995\n",
      "Epoch 626: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - r_square: 0.9995 - val_loss: 0.0094 - val_r_square: 0.9989\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9989\n",
      "Epoch 627: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0094 - r_square: 0.9989 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 628: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0073 - val_r_square: 0.9993\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9993\n",
      "Epoch 629: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0073 - r_square: 0.9993 - val_loss: 0.0104 - val_r_square: 0.9986\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - r_square: 0.9986\n",
      "Epoch 630: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0104 - r_square: 0.9986 - val_loss: 0.0056 - val_r_square: 0.9996\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9996\n",
      "Epoch 631: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - r_square: 0.9996 - val_loss: 0.0064 - val_r_square: 0.9995\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9995\n",
      "Epoch 632: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - r_square: 0.9995 - val_loss: 0.0095 - val_r_square: 0.9988\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 633: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 634: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0071 - val_r_square: 0.9993\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9993\n",
      "Epoch 635: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0071 - r_square: 0.9993 - val_loss: 0.0102 - val_r_square: 0.9986\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9986\n",
      "Epoch 636: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0102 - r_square: 0.9986 - val_loss: 0.0054 - val_r_square: 0.9996\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9996\n",
      "Epoch 637: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0054 - r_square: 0.9996 - val_loss: 0.0065 - val_r_square: 0.9994\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 638: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0096 - val_r_square: 0.9988\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9988\n",
      "Epoch 639: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0096 - r_square: 0.9988 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 640: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0070 - val_r_square: 0.9993\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9993\n",
      "Epoch 641: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - r_square: 0.9993 - val_loss: 0.0101 - val_r_square: 0.9986\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - r_square: 0.9986\n",
      "Epoch 642: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0101 - r_square: 0.9986 - val_loss: 0.0054 - val_r_square: 0.9996\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9996\n",
      "Epoch 643: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - r_square: 0.9996 - val_loss: 0.0065 - val_r_square: 0.9994\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 644: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0095 - val_r_square: 0.9988\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 645: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0047 - val_r_square: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 646/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9997\n",
      "Epoch 646: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9997 - val_loss: 0.0072 - val_r_square: 0.9993\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9993\n",
      "Epoch 647: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0072 - r_square: 0.9993 - val_loss: 0.0103 - val_r_square: 0.9986\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9986\n",
      "Epoch 648: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0103 - r_square: 0.9986 - val_loss: 0.0055 - val_r_square: 0.9995\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 649: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0063 - val_r_square: 0.9995\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9995\n",
      "Epoch 650: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - r_square: 0.9995 - val_loss: 0.0093 - val_r_square: 0.9989\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 651: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 652: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9993\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9993\n",
      "Epoch 653: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9993 - val_loss: 0.0094 - val_r_square: 0.9988\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9988\n",
      "Epoch 654: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0094 - r_square: 0.9988 - val_loss: 0.0042 - val_r_square: 0.9997\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0042 - r_square: 0.9997\n",
      "Epoch 655: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - r_square: 0.9997 - val_loss: 0.0076 - val_r_square: 0.9992\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9992\n",
      "Epoch 656: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0076 - r_square: 0.9992 - val_loss: 0.0107 - val_r_square: 0.9986\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9985\n",
      "Epoch 657: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0107 - r_square: 0.9985 - val_loss: 0.0059 - val_r_square: 0.9995\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 658: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0060 - val_r_square: 0.9995\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9995\n",
      "Epoch 659: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0060 - r_square: 0.9995 - val_loss: 0.0091 - val_r_square: 0.9989\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9989\n",
      "Epoch 660: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0091 - r_square: 0.9989 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 661: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0073 - val_r_square: 0.9993\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9993\n",
      "Epoch 662: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0073 - r_square: 0.9993 - val_loss: 0.0103 - val_r_square: 0.9987\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9986\n",
      "Epoch 663: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0103 - r_square: 0.9986 - val_loss: 0.0054 - val_r_square: 0.9996\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9996\n",
      "Epoch 664: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - r_square: 0.9996 - val_loss: 0.0064 - val_r_square: 0.9994\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9994\n",
      "Epoch 665: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0064 - r_square: 0.9994 - val_loss: 0.0096 - val_r_square: 0.9988\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9988\n",
      "Epoch 666: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0096 - r_square: 0.9988 - val_loss: 0.0049 - val_r_square: 0.9997\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9997\n",
      "Epoch 667: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9994\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9994\n",
      "Epoch 668: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0068 - r_square: 0.9994 - val_loss: 0.0098 - val_r_square: 0.9988\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9988\n",
      "Epoch 669: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0098 - r_square: 0.9988 - val_loss: 0.0050 - val_r_square: 0.9997\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9997\n",
      "Epoch 670: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9994\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9994\n",
      "Epoch 671: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0068 - r_square: 0.9994 - val_loss: 0.0099 - val_r_square: 0.9987\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 672: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 673: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0065 - val_r_square: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 674/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 674: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0095 - val_r_square: 0.9989\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 675: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 676: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0070 - val_r_square: 0.9993\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9993\n",
      "Epoch 677: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0070 - r_square: 0.9993 - val_loss: 0.0101 - val_r_square: 0.9987\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - r_square: 0.9987\n",
      "Epoch 678: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0101 - r_square: 0.9987 - val_loss: 0.0054 - val_r_square: 0.9996\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9996\n",
      "Epoch 679: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - r_square: 0.9996 - val_loss: 0.0063 - val_r_square: 0.9995\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9995\n",
      "Epoch 680: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - r_square: 0.9995 - val_loss: 0.0094 - val_r_square: 0.9989\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 681: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 682: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0071 - val_r_square: 0.9993\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9993\n",
      "Epoch 683: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0071 - r_square: 0.9993 - val_loss: 0.0102 - val_r_square: 0.9986\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9986\n",
      "Epoch 684: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0102 - r_square: 0.9986 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 685: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9995\n",
      "Epoch 686: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - r_square: 0.9995 - val_loss: 0.0092 - val_r_square: 0.9989\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9989\n",
      "Epoch 687: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0092 - r_square: 0.9989 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 688: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0072 - val_r_square: 0.9993\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9993\n",
      "Epoch 689: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - r_square: 0.9993 - val_loss: 0.0102 - val_r_square: 0.9986\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9986\n",
      "Epoch 690: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0102 - r_square: 0.9986 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 691: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9995\n",
      "Epoch 692: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - r_square: 0.9995 - val_loss: 0.0093 - val_r_square: 0.9989\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 693: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 694: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0070 - val_r_square: 0.9993\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9993\n",
      "Epoch 695: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0070 - r_square: 0.9993 - val_loss: 0.0100 - val_r_square: 0.9987\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9987\n",
      "Epoch 696: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0100 - r_square: 0.9987 - val_loss: 0.0053 - val_r_square: 0.9996\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9996\n",
      "Epoch 697: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - r_square: 0.9996 - val_loss: 0.0064 - val_r_square: 0.9995\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9994\n",
      "Epoch 698: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0064 - r_square: 0.9994 - val_loss: 0.0094 - val_r_square: 0.9989\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9988\n",
      "Epoch 699: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0094 - r_square: 0.9988 - val_loss: 0.0047 - val_r_square: 0.9997\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9997\n",
      "Epoch 700: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9997 - val_loss: 0.0069 - val_r_square: 0.9993\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9993\n",
      "Epoch 701: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0069 - r_square: 0.9993 - val_loss: 0.0099 - val_r_square: 0.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 702/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 702: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 703: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0064 - val_r_square: 0.9995\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9994\n",
      "Epoch 704: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0064 - r_square: 0.9994 - val_loss: 0.0094 - val_r_square: 0.9989\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9989\n",
      "Epoch 705: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0094 - r_square: 0.9989 - val_loss: 0.0047 - val_r_square: 0.9997\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 706: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9993\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9993\n",
      "Epoch 707: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9993 - val_loss: 0.0096 - val_r_square: 0.9988\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9987\n",
      "Epoch 708: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0096 - r_square: 0.9987 - val_loss: 0.0048 - val_r_square: 0.9996\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9996\n",
      "Epoch 709: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - r_square: 0.9996 - val_loss: 0.0069 - val_r_square: 0.9994\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9994\n",
      "Epoch 710: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0068 - r_square: 0.9994 - val_loss: 0.0099 - val_r_square: 0.9987\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 711: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0053 - val_r_square: 0.9996\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9996\n",
      "Epoch 712: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - r_square: 0.9996 - val_loss: 0.0063 - val_r_square: 0.9994\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9994\n",
      "Epoch 713: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - r_square: 0.9994 - val_loss: 0.0093 - val_r_square: 0.9988\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9988\n",
      "Epoch 714: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0093 - r_square: 0.9988 - val_loss: 0.0047 - val_r_square: 0.9997\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 715: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9994\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9994\n",
      "Epoch 716: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9994 - val_loss: 0.0097 - val_r_square: 0.9988\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9988\n",
      "Epoch 717: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - r_square: 0.9988 - val_loss: 0.0049 - val_r_square: 0.9997\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9997\n",
      "Epoch 718: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9993\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9993\n",
      "Epoch 719: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0068 - r_square: 0.9993 - val_loss: 0.0100 - val_r_square: 0.9987\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9987\n",
      "Epoch 720: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0100 - r_square: 0.9987 - val_loss: 0.0054 - val_r_square: 0.9996\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9996\n",
      "Epoch 721: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - r_square: 0.9996 - val_loss: 0.0061 - val_r_square: 0.9995\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9995\n",
      "Epoch 722: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - r_square: 0.9995 - val_loss: 0.0090 - val_r_square: 0.9990\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9989\n",
      "Epoch 723: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0090 - r_square: 0.9989 - val_loss: 0.0043 - val_r_square: 0.9997\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9997\n",
      "Epoch 724: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - r_square: 0.9997 - val_loss: 0.0067 - val_r_square: 0.9994\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9994\n",
      "Epoch 725: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0067 - r_square: 0.9994 - val_loss: 0.0092 - val_r_square: 0.9989\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9989\n",
      "Epoch 726: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0092 - r_square: 0.9989 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9997\n",
      "Epoch 727: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0040 - r_square: 0.9997 - val_loss: 0.0076 - val_r_square: 0.9993\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9992\n",
      "Epoch 728: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0076 - r_square: 0.9992 - val_loss: 0.0107 - val_r_square: 0.9986\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9985\n",
      "Epoch 729: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0107 - r_square: 0.9985 - val_loss: 0.0061 - val_r_square: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 730/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9995\n",
      "Epoch 730: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - r_square: 0.9995 - val_loss: 0.0054 - val_r_square: 0.9996\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9996\n",
      "Epoch 731: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - r_square: 0.9996 - val_loss: 0.0083 - val_r_square: 0.9991\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9991\n",
      "Epoch 732: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0083 - r_square: 0.9991 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9998\n",
      "Epoch 733: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - r_square: 0.9998 - val_loss: 0.0077 - val_r_square: 0.9992\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9992\n",
      "Epoch 734: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - r_square: 0.9992 - val_loss: 0.0106 - val_r_square: 0.9986\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9986\n",
      "Epoch 735: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0106 - r_square: 0.9986 - val_loss: 0.0058 - val_r_square: 0.9996\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 736: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0059 - val_r_square: 0.9995\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9995\n",
      "Epoch 737: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - r_square: 0.9995 - val_loss: 0.0090 - val_r_square: 0.9990\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9989\n",
      "Epoch 738: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0090 - r_square: 0.9989 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 739: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0070 - val_r_square: 0.9994\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9994\n",
      "Epoch 740: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0069 - r_square: 0.9994 - val_loss: 0.0099 - val_r_square: 0.9988\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 741: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 742: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0064 - val_r_square: 0.9995\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9994\n",
      "Epoch 743: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0064 - r_square: 0.9994 - val_loss: 0.0095 - val_r_square: 0.9988\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 744: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0049 - val_r_square: 0.9997\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9997\n",
      "Epoch 745: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - r_square: 0.9997 - val_loss: 0.0065 - val_r_square: 0.9994\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9994\n",
      "Epoch 746: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - r_square: 0.9994 - val_loss: 0.0095 - val_r_square: 0.9989\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 747: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 748: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0067 - val_r_square: 0.9994\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9994\n",
      "Epoch 749: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0067 - r_square: 0.9994 - val_loss: 0.0098 - val_r_square: 0.9988\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9988\n",
      "Epoch 750: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0098 - r_square: 0.9988 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 751: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0063 - val_r_square: 0.9995\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9995\n",
      "Epoch 752: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - r_square: 0.9995 - val_loss: 0.0093 - val_r_square: 0.9989\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9989\n",
      "Epoch 753: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0092 - r_square: 0.9989 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 754: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0069 - val_r_square: 0.9994\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9994\n",
      "Epoch 755: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0069 - r_square: 0.9994 - val_loss: 0.0099 - val_r_square: 0.9987\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 756: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0053 - val_r_square: 0.9996\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9996\n",
      "Epoch 757: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - r_square: 0.9996 - val_loss: 0.0061 - val_r_square: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 758/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9995\n",
      "Epoch 758: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - r_square: 0.9995 - val_loss: 0.0091 - val_r_square: 0.9989\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9989\n",
      "Epoch 759: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0091 - r_square: 0.9989 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 760: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0070 - val_r_square: 0.9993\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9993\n",
      "Epoch 761: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0070 - r_square: 0.9993 - val_loss: 0.0100 - val_r_square: 0.9987\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9987\n",
      "Epoch 762: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0100 - r_square: 0.9987 - val_loss: 0.0054 - val_r_square: 0.9996\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9996\n",
      "Epoch 763: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - r_square: 0.9996 - val_loss: 0.0061 - val_r_square: 0.9995\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9995\n",
      "Epoch 764: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - r_square: 0.9995 - val_loss: 0.0090 - val_r_square: 0.9990\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9989\n",
      "Epoch 765: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0090 - r_square: 0.9989 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 766: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0069 - val_r_square: 0.9993\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9993\n",
      "Epoch 767: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0069 - r_square: 0.9993 - val_loss: 0.0099 - val_r_square: 0.9987\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 768: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0053 - val_r_square: 0.9996\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9996\n",
      "Epoch 769: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - r_square: 0.9996 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9995\n",
      "Epoch 770: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - r_square: 0.9995 - val_loss: 0.0092 - val_r_square: 0.9989\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9989\n",
      "Epoch 771: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0091 - r_square: 0.9989 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 772: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9994\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9994\n",
      "Epoch 773: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0068 - r_square: 0.9994 - val_loss: 0.0097 - val_r_square: 0.9988\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9987\n",
      "Epoch 774: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - r_square: 0.9987 - val_loss: 0.0051 - val_r_square: 0.9996\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 775: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0063 - val_r_square: 0.9995\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9995\n",
      "Epoch 776: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - r_square: 0.9995 - val_loss: 0.0093 - val_r_square: 0.9989\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 777: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9997\n",
      "Epoch 778: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9997 - val_loss: 0.0066 - val_r_square: 0.9994\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9994\n",
      "Epoch 779: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - r_square: 0.9994 - val_loss: 0.0095 - val_r_square: 0.9988\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 780: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0049 - val_r_square: 0.9996\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9996\n",
      "Epoch 781: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - r_square: 0.9996 - val_loss: 0.0064 - val_r_square: 0.9995\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9994\n",
      "Epoch 782: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0064 - r_square: 0.9994 - val_loss: 0.0094 - val_r_square: 0.9989\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9989\n",
      "Epoch 783: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0093 - r_square: 0.9989 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 784: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0066 - val_r_square: 0.9994\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9994\n",
      "Epoch 785: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0066 - r_square: 0.9994 - val_loss: 0.0095 - val_r_square: 0.9988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 786/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9988\n",
      "Epoch 786: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0095 - r_square: 0.9988 - val_loss: 0.0050 - val_r_square: 0.9996\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9996\n",
      "Epoch 787: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9996 - val_loss: 0.0063 - val_r_square: 0.9995\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9995\n",
      "Epoch 788: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - r_square: 0.9995 - val_loss: 0.0092 - val_r_square: 0.9989\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9989\n",
      "Epoch 789: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0092 - r_square: 0.9989 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 790: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0063 - val_r_square: 0.9994\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9994\n",
      "Epoch 791: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - r_square: 0.9994 - val_loss: 0.0089 - val_r_square: 0.9989\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0089 - r_square: 0.9989\n",
      "Epoch 792: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0089 - r_square: 0.9989 - val_loss: 0.0041 - val_r_square: 0.9997\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 793: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0071 - val_r_square: 0.9993\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9993\n",
      "Epoch 794: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0071 - r_square: 0.9993 - val_loss: 0.0099 - val_r_square: 0.9988\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 795: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 796: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0063 - val_r_square: 0.9994\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9994\n",
      "Epoch 797: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - r_square: 0.9994 - val_loss: 0.0094 - val_r_square: 0.9988\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9988\n",
      "Epoch 798: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0094 - r_square: 0.9988 - val_loss: 0.0050 - val_r_square: 0.9996\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9996\n",
      "Epoch 799: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9996 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9995\n",
      "Epoch 800: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - r_square: 0.9995 - val_loss: 0.0091 - val_r_square: 0.9990\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9989\n",
      "Epoch 801: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0090 - r_square: 0.9989 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 802: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0070 - val_r_square: 0.9993\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9993\n",
      "Epoch 803: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0070 - r_square: 0.9993 - val_loss: 0.0100 - val_r_square: 0.9987\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9987\n",
      "Epoch 804: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0100 - r_square: 0.9987 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 805: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0057 - val_r_square: 0.9996\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9996\n",
      "Epoch 806: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0057 - r_square: 0.9996 - val_loss: 0.0086 - val_r_square: 0.9991\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9990\n",
      "Epoch 807: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0086 - r_square: 0.9990 - val_loss: 0.0040 - val_r_square: 0.9998\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9998\n",
      "Epoch 808: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - r_square: 0.9998 - val_loss: 0.0073 - val_r_square: 0.9993\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9993\n",
      "Epoch 809: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0073 - r_square: 0.9993 - val_loss: 0.0103 - val_r_square: 0.9986\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9986\n",
      "Epoch 810: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0103 - r_square: 0.9986 - val_loss: 0.0058 - val_r_square: 0.9995\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 811: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 812: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0084 - val_r_square: 0.9991\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0084 - r_square: 0.9991\n",
      "Epoch 813: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0084 - r_square: 0.9991 - val_loss: 0.0039 - val_r_square: 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9998\n",
      "Epoch 814: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - r_square: 0.9998 - val_loss: 0.0074 - val_r_square: 0.9993\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9992\n",
      "Epoch 815: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - r_square: 0.9992 - val_loss: 0.0103 - val_r_square: 0.9986\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9986\n",
      "Epoch 816: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0103 - r_square: 0.9986 - val_loss: 0.0058 - val_r_square: 0.9995\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 817: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 818: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0085 - val_r_square: 0.9991\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9991\n",
      "Epoch 819: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0085 - r_square: 0.9991 - val_loss: 0.0040 - val_r_square: 0.9998\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9998\n",
      "Epoch 820: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - r_square: 0.9998 - val_loss: 0.0072 - val_r_square: 0.9993\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9993\n",
      "Epoch 821: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0073 - r_square: 0.9993 - val_loss: 0.0102 - val_r_square: 0.9986\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9986\n",
      "Epoch 822: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0102 - r_square: 0.9986 - val_loss: 0.0056 - val_r_square: 0.9995\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9995\n",
      "Epoch 823: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - r_square: 0.9995 - val_loss: 0.0056 - val_r_square: 0.9996\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9996\n",
      "Epoch 824: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - r_square: 0.9996 - val_loss: 0.0086 - val_r_square: 0.9991\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9990\n",
      "Epoch 825: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0086 - r_square: 0.9990 - val_loss: 0.0041 - val_r_square: 0.9997\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 826: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9994\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9994\n",
      "Epoch 827: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0068 - r_square: 0.9994 - val_loss: 0.0094 - val_r_square: 0.9988\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9988\n",
      "Epoch 828: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0094 - r_square: 0.9988 - val_loss: 0.0046 - val_r_square: 0.9997\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 829: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 0.0069 - val_r_square: 0.9994\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9994\n",
      "Epoch 830: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0068 - r_square: 0.9994 - val_loss: 0.0100 - val_r_square: 0.9987\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 831: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0056 - val_r_square: 0.9996\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9996\n",
      "Epoch 832: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - r_square: 0.9996 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 833: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0083 - val_r_square: 0.9991\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9991\n",
      "Epoch 834: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0083 - r_square: 0.9991 - val_loss: 0.0037 - val_r_square: 0.9998\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9998\n",
      "Epoch 835: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - r_square: 0.9998 - val_loss: 0.0072 - val_r_square: 0.9993\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9993\n",
      "Epoch 836: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0071 - r_square: 0.9993 - val_loss: 0.0098 - val_r_square: 0.9988\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9988\n",
      "Epoch 837: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0097 - r_square: 0.9988 - val_loss: 0.0049 - val_r_square: 0.9997\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9997\n",
      "Epoch 838: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0049 - r_square: 0.9997 - val_loss: 0.0065 - val_r_square: 0.9994\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9994\n",
      "Epoch 839: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0066 - r_square: 0.9994 - val_loss: 0.0097 - val_r_square: 0.9988\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9987\n",
      "Epoch 840: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - r_square: 0.9987 - val_loss: 0.0054 - val_r_square: 0.9996\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 841: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0055 - val_r_square: 0.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 842/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 842: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0083 - val_r_square: 0.9991\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9991\n",
      "Epoch 843: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0083 - r_square: 0.9991 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9998\n",
      "Epoch 844: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - r_square: 0.9998 - val_loss: 0.0077 - val_r_square: 0.9992\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9992\n",
      "Epoch 845: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - r_square: 0.9992 - val_loss: 0.0107 - val_r_square: 0.9985\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9985\n",
      "Epoch 846: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0107 - r_square: 0.9985 - val_loss: 0.0063 - val_r_square: 0.9995\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9994\n",
      "Epoch 847: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0063 - r_square: 0.9994 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 848: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0076 - val_r_square: 0.9992\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9992\n",
      "Epoch 849: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0076 - r_square: 0.9992 - val_loss: 0.0031 - val_r_square: 0.9998\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 850: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0074 - val_r_square: 0.9993\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9992\n",
      "Epoch 851: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0075 - r_square: 0.9992 - val_loss: 0.0098 - val_r_square: 0.9988\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9987\n",
      "Epoch 852: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0098 - r_square: 0.9987 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 853: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0069 - val_r_square: 0.9994\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9994\n",
      "Epoch 854: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0068 - r_square: 0.9994 - val_loss: 0.0102 - val_r_square: 0.9987\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9987\n",
      "Epoch 855: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0102 - r_square: 0.9987 - val_loss: 0.0061 - val_r_square: 0.9995\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9995\n",
      "Epoch 856: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - r_square: 0.9995 - val_loss: 0.0047 - val_r_square: 0.9997\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 857: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0074 - val_r_square: 0.9993\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9993\n",
      "Epoch 858: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0074 - r_square: 0.9993 - val_loss: 0.0027 - val_r_square: 0.9999\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9999\n",
      "Epoch 859: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - r_square: 0.9999 - val_loss: 0.0075 - val_r_square: 0.9993\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9993\n",
      "Epoch 860: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - r_square: 0.9993 - val_loss: 0.0094 - val_r_square: 0.9989\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9989\n",
      "Epoch 861: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0094 - r_square: 0.9989 - val_loss: 0.0041 - val_r_square: 0.9998\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9998\n",
      "Epoch 862: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - r_square: 0.9998 - val_loss: 0.0079 - val_r_square: 0.9992\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9992\n",
      "Epoch 863: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0079 - r_square: 0.9992 - val_loss: 0.0115 - val_r_square: 0.9983\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - r_square: 0.9983\n",
      "Epoch 864: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0115 - r_square: 0.9983 - val_loss: 0.0077 - val_r_square: 0.9992\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9992\n",
      "Epoch 865: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0077 - r_square: 0.9992 - val_loss: 0.0029 - val_r_square: 0.9999\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 866: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0053 - val_r_square: 0.9996\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9996\n",
      "Epoch 867: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - r_square: 0.9996 - val_loss: 9.9663e-04 - val_r_square: 1.0000\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.5068e-04 - r_square: 1.0000\n",
      "Epoch 868: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.5068e-04 - r_square: 1.0000 - val_loss: 0.0029 - val_r_square: 0.9999\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 869: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0013 - val_r_square: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 870: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0014 - val_r_square: 1.0000\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - r_square: 1.0000\n",
      "Epoch 871: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - r_square: 1.0000 - val_loss: 0.0030 - val_r_square: 0.9999\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9999\n",
      "Epoch 872: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - r_square: 0.9999 - val_loss: 0.0012 - val_r_square: 1.0000\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 873: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0040 - val_r_square: 0.9998\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9998\n",
      "Epoch 874: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - r_square: 0.9998 - val_loss: 0.0010 - val_r_square: 1.0000\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9411e-04 - r_square: 1.0000\n",
      "Epoch 875: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9411e-04 - r_square: 1.0000 - val_loss: 0.0026 - val_r_square: 0.9999\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - r_square: 0.9999\n",
      "Epoch 876: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - r_square: 0.9999 - val_loss: 0.0011 - val_r_square: 1.0000\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - r_square: 1.0000\n",
      "Epoch 877: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0011 - r_square: 1.0000 - val_loss: 0.0010 - val_r_square: 1.0000\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.7708e-04 - r_square: 1.0000\n",
      "Epoch 878: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.7708e-04 - r_square: 1.0000 - val_loss: 0.0030 - val_r_square: 0.9999\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 879: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0014 - val_r_square: 1.0000\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - r_square: 1.0000\n",
      "Epoch 880: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - r_square: 1.0000 - val_loss: 0.0013 - val_r_square: 1.0000\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 881: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0018 - val_r_square: 0.9999\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 0.9999\n",
      "Epoch 882: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - r_square: 0.9999 - val_loss: 0.0024 - val_r_square: 0.9999\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - r_square: 0.9999\n",
      "Epoch 883: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - r_square: 0.9999 - val_loss: 8.5421e-04 - val_r_square: 1.0000\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.1633e-04 - r_square: 1.0000\n",
      "Epoch 884: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.1633e-04 - r_square: 1.0000 - val_loss: 0.0018 - val_r_square: 1.0000\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 1.0000\n",
      "Epoch 885: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0018 - r_square: 1.0000 - val_loss: 0.0026 - val_r_square: 0.9999\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - r_square: 0.9999\n",
      "Epoch 886: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - r_square: 0.9999 - val_loss: 0.0015 - val_r_square: 0.9999\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - r_square: 1.0000\n",
      "Epoch 887: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0015 - r_square: 1.0000 - val_loss: 0.0016 - val_r_square: 1.0000\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 1.0000\n",
      "Epoch 888: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - r_square: 1.0000 - val_loss: 0.0010 - val_r_square: 1.0000\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0010 - r_square: 1.0000\n",
      "Epoch 889: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0010 - r_square: 1.0000 - val_loss: 0.0012 - val_r_square: 1.0000\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 890: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0031 - val_r_square: 0.9998\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9998\n",
      "Epoch 891: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - r_square: 0.9998 - val_loss: 0.0020 - val_r_square: 0.9999\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - r_square: 0.9999\n",
      "Epoch 892: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - r_square: 0.9999 - val_loss: 0.0049 - val_r_square: 0.9997\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9997\n",
      "Epoch 893: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0049 - r_square: 0.9997 - val_loss: 0.0028 - val_r_square: 0.9999\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9999\n",
      "Epoch 894: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - r_square: 0.9999 - val_loss: 0.0062 - val_r_square: 0.9995\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9995\n",
      "Epoch 895: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0061 - r_square: 0.9995 - val_loss: 0.0070 - val_r_square: 0.9993\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9993\n",
      "Epoch 896: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0069 - r_square: 0.9993 - val_loss: 0.0017 - val_r_square: 1.0000\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 1.0000\n",
      "Epoch 897: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - r_square: 1.0000 - val_loss: 0.0053 - val_r_square: 0.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 898/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9996\n",
      "Epoch 898: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - r_square: 0.9996 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9998\n",
      "Epoch 899: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - r_square: 0.9998 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9997\n",
      "Epoch 900: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0047 - r_square: 0.9997 - val_loss: 0.0051 - val_r_square: 0.9996\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9996\n",
      "Epoch 901: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0050 - r_square: 0.9996 - val_loss: 0.0023 - val_r_square: 0.9999\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0023 - r_square: 0.9999\n",
      "Epoch 902: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - r_square: 0.9999 - val_loss: 0.0034 - val_r_square: 0.9998\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 903: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0024 - val_r_square: 0.9999\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - r_square: 0.9999\n",
      "Epoch 904: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - r_square: 0.9999 - val_loss: 0.0014 - val_r_square: 1.0000\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 1.0000\n",
      "Epoch 905: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - r_square: 1.0000 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 906: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 907: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0063 - val_r_square: 0.9994\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9994\n",
      "Epoch 908: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - r_square: 0.9994 - val_loss: 0.0065 - val_r_square: 0.9993\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9993\n",
      "Epoch 909: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0065 - r_square: 0.9993 - val_loss: 0.0029 - val_r_square: 0.9999\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 910: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9996\n",
      "Epoch 911: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0053 - r_square: 0.9996 - val_loss: 0.0036 - val_r_square: 0.9998\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9998\n",
      "Epoch 912: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - r_square: 0.9998 - val_loss: 0.0038 - val_r_square: 0.9998\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9998\n",
      "Epoch 913: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - r_square: 0.9998 - val_loss: 0.0029 - val_r_square: 0.9999\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 914: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0051 - val_r_square: 0.9996\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 915: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 916: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0034 - val_r_square: 0.9998\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 917: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 918: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0028 - val_r_square: 0.9999\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 919: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 920: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0031 - val_r_square: 0.9999\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9999\n",
      "Epoch 921: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - r_square: 0.9999 - val_loss: 0.0054 - val_r_square: 0.9996\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9996\n",
      "Epoch 922: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - r_square: 0.9996 - val_loss: 0.0058 - val_r_square: 0.9995\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 923: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0030 - val_r_square: 0.9998\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9998\n",
      "Epoch 924: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - r_square: 0.9998 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 925: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0034 - val_r_square: 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 926/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 926: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0041 - val_r_square: 0.9997\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 927: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0032 - val_r_square: 0.9999\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 928: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 929: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9997\n",
      "Epoch 930: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - r_square: 0.9997 - val_loss: 0.0040 - val_r_square: 0.9998\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 931: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0054 - val_r_square: 0.9996\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9996\n",
      "Epoch 932: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9996 - val_loss: 0.0025 - val_r_square: 0.9999\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - r_square: 0.9999\n",
      "Epoch 933: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - r_square: 0.9999 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9996\n",
      "Epoch 934: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - r_square: 0.9996 - val_loss: 0.0038 - val_r_square: 0.9998\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9998\n",
      "Epoch 935: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - r_square: 0.9998 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 936: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0055 - val_r_square: 0.9996\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9996\n",
      "Epoch 937: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - r_square: 0.9996 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 938: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0035 - val_r_square: 0.9998\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - r_square: 0.9998\n",
      "Epoch 939: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - r_square: 0.9998 - val_loss: 0.0012 - val_r_square: 1.0000\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - r_square: 1.0000\n",
      "Epoch 940: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - r_square: 1.0000 - val_loss: 0.0041 - val_r_square: 0.9998\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9998\n",
      "Epoch 941: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9998 - val_loss: 0.0015 - val_r_square: 1.0000\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - r_square: 1.0000\n",
      "Epoch 942: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0015 - r_square: 1.0000 - val_loss: 0.0039 - val_r_square: 0.9997\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9997\n",
      "Epoch 943: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - r_square: 0.9997 - val_loss: 0.0018 - val_r_square: 0.9999\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 0.9999\n",
      "Epoch 944: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0018 - r_square: 0.9999 - val_loss: 0.0025 - val_r_square: 0.9999\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - r_square: 0.9999\n",
      "Epoch 945: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - r_square: 0.9999 - val_loss: 0.0015 - val_r_square: 1.0000\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - r_square: 1.0000\n",
      "Epoch 946: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0015 - r_square: 1.0000 - val_loss: 0.0016 - val_r_square: 1.0000\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - r_square: 1.0000\n",
      "Epoch 947: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - r_square: 1.0000 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 948: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0019 - val_r_square: 0.9999\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - r_square: 0.9999\n",
      "Epoch 949: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0019 - r_square: 0.9999 - val_loss: 0.0020 - val_r_square: 0.9999\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0020 - r_square: 0.9999\n",
      "Epoch 950: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - r_square: 0.9999 - val_loss: 0.0018 - val_r_square: 0.9999\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 0.9999\n",
      "Epoch 951: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - r_square: 0.9999 - val_loss: 0.0013 - val_r_square: 1.0000\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 952: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0013 - val_r_square: 1.0000\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 1.0000\n",
      "Epoch 953: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0013 - r_square: 1.0000 - val_loss: 0.0029 - val_r_square: 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 954/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 954: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 955: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0037 - val_r_square: 0.9998\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9998\n",
      "Epoch 956: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - r_square: 0.9998 - val_loss: 0.0013 - val_r_square: 1.0000\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 1.0000\n",
      "Epoch 957: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0013 - r_square: 1.0000 - val_loss: 0.0025 - val_r_square: 0.9999\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - r_square: 0.9999\n",
      "Epoch 958: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - r_square: 0.9999 - val_loss: 0.0017 - val_r_square: 0.9999\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - r_square: 0.9999\n",
      "Epoch 959: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - r_square: 0.9999 - val_loss: 0.0014 - val_r_square: 1.0000\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 1.0000\n",
      "Epoch 960: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0013 - r_square: 1.0000 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 961: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0014 - val_r_square: 1.0000\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - r_square: 1.0000\n",
      "Epoch 962: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0014 - r_square: 1.0000 - val_loss: 0.0029 - val_r_square: 0.9999\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9999\n",
      "Epoch 963: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - r_square: 0.9999 - val_loss: 0.0015 - val_r_square: 1.0000\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - r_square: 1.0000\n",
      "Epoch 964: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - r_square: 1.0000 - val_loss: 0.0048 - val_r_square: 0.9997\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9997\n",
      "Epoch 965: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - r_square: 0.9997 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0020 - r_square: 0.9999\n",
      "Epoch 966: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - r_square: 0.9999 - val_loss: 0.0076 - val_r_square: 0.9993\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9992\n",
      "Epoch 967: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0076 - r_square: 0.9992 - val_loss: 0.0091 - val_r_square: 0.9990\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9989\n",
      "Epoch 968: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0090 - r_square: 0.9989 - val_loss: 0.0031 - val_r_square: 0.9999\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9999\n",
      "Epoch 969: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - r_square: 0.9999 - val_loss: 0.0094 - val_r_square: 0.9989\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9989\n",
      "Epoch 970: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0094 - r_square: 0.9989 - val_loss: 0.0134 - val_r_square: 0.9977\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0134 - r_square: 0.9977\n",
      "Epoch 971: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0134 - r_square: 0.9977 - val_loss: 0.0098 - val_r_square: 0.9987\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9987\n",
      "Epoch 972: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0098 - r_square: 0.9987 - val_loss: 0.0017 - val_r_square: 0.9999\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 973: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0118 - val_r_square: 0.9982\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0118 - r_square: 0.9982\n",
      "Epoch 974: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0118 - r_square: 0.9982 - val_loss: 0.0146 - val_r_square: 0.9973\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0146 - r_square: 0.9973\n",
      "Epoch 975: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0146 - r_square: 0.9973 - val_loss: 0.0099 - val_r_square: 0.9988\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9987\n",
      "Epoch 976: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0099 - r_square: 0.9987 - val_loss: 0.0016 - val_r_square: 1.0000\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - r_square: 1.0000\n",
      "Epoch 977: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0015 - r_square: 1.0000 - val_loss: 0.0047 - val_r_square: 0.9997\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9997\n",
      "Epoch 978: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - r_square: 0.9997 - val_loss: 7.7404e-04 - val_r_square: 1.0000\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5331e-04 - r_square: 1.0000\n",
      "Epoch 979: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.5331e-04 - r_square: 1.0000 - val_loss: 0.0018 - val_r_square: 1.0000\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 1.0000\n",
      "Epoch 980: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0018 - r_square: 1.0000 - val_loss: 0.0027 - val_r_square: 0.9999\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9999\n",
      "Epoch 981: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - r_square: 0.9999 - val_loss: 9.0799e-04 - val_r_square: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.0850e-04 - r_square: 1.0000\n",
      "Epoch 982: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.0850e-04 - r_square: 1.0000 - val_loss: 8.6874e-04 - val_r_square: 1.0000\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.4055e-04 - r_square: 1.0000\n",
      "Epoch 983: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.4055e-04 - r_square: 1.0000 - val_loss: 0.0025 - val_r_square: 0.9999\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - r_square: 0.9999\n",
      "Epoch 984: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - r_square: 0.9999 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 985: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0013 - val_r_square: 1.0000\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 1.0000\n",
      "Epoch 986: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - r_square: 1.0000 - val_loss: 0.0010 - val_r_square: 1.0000\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9853e-04 - r_square: 1.0000\n",
      "Epoch 987: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9853e-04 - r_square: 1.0000 - val_loss: 0.0027 - val_r_square: 0.9999\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9999\n",
      "Epoch 988: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - r_square: 0.9999 - val_loss: 0.0011 - val_r_square: 1.0000\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - r_square: 1.0000\n",
      "Epoch 989: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0011 - r_square: 1.0000 - val_loss: 0.0012 - val_r_square: 1.0000\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 990: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0028 - val_r_square: 0.9999\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9999\n",
      "Epoch 991: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - r_square: 0.9999 - val_loss: 0.0013 - val_r_square: 1.0000\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 1.0000\n",
      "Epoch 992: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0013 - r_square: 1.0000 - val_loss: 0.0016 - val_r_square: 1.0000\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 1.0000\n",
      "Epoch 993: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - r_square: 1.0000 - val_loss: 0.0015 - val_r_square: 1.0000\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - r_square: 1.0000\n",
      "Epoch 994: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0015 - r_square: 1.0000 - val_loss: 0.0015 - val_r_square: 1.0000\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - r_square: 1.0000\n",
      "Epoch 995: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - r_square: 1.0000 - val_loss: 0.0014 - val_r_square: 1.0000\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - r_square: 1.0000\n",
      "Epoch 996: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - r_square: 1.0000 - val_loss: 0.0022 - val_r_square: 0.9999\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - r_square: 0.9999\n",
      "Epoch 997: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - r_square: 0.9999 - val_loss: 0.0023 - val_r_square: 0.9999\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0023 - r_square: 0.9999\n",
      "Epoch 998: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - r_square: 0.9999 - val_loss: 0.0012 - val_r_square: 1.0000\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 999: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0037 - val_r_square: 0.9998\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9998\n",
      "Epoch 1000: saving model to training_regressions_separated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - r_square: 0.9998 - val_loss: 6.7570e-04 - val_r_square: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Create a sequential model\n",
    "model_separated = tf.keras.Sequential()\n",
    "#Add the hidden layers\n",
    "model_separated.add(tf.keras.layers.Dense(250, input_dim = (np.shape(xtrain_separated)[1]), activation='sigmoid'))\n",
    "model_separated.add(tf.keras.layers.Dense(80 , activation = 'sigmoid'))\n",
    "#Add the output layer\n",
    "model_separated.add(tf.keras.layers.Dense(1, activation = 'linear'))\n",
    "\n",
    "#Setting the optimiser equal to the Adam optimiser with learning rate = 0.0001\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "\n",
    "#Compliling the model\n",
    "model_separated.compile(optimizer=opt, loss = 'mean_absolute_error', metrics=[r_square])\n",
    "\n",
    "#Training the model\n",
    "history_separated = model_separated.fit(xtrain_separated, Ytrain_separated, epochs = 1000, validation_data = (xval_separated, Yval_separated), batch_size = np.shape(xtrain_separated)[0], verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b981385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40/150 [=======>......................] - ETA: 0s - loss: 6.5066e-04 - r_square: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 15:11:37.983038: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 3ms/step - loss: 6.4926e-04 - r_square: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006492643733508885, 0.9999895095825195]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the model on the training set\n",
    "model_separated.evaluate(xtrain_separated, Ytrain_separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3629d786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 3ms/step - loss: 6.5066e-04 - r_square: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006506631034426391, 0.9999896287918091]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the model on the test set\n",
    "model_separated.evaluate(xtest_separated, Ytest_separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed1dda82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure font properties for the plots\n",
    "plt.rc('font',family='Times New Roman')\n",
    "plt.rcParams.update({'font.size':13})\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "plt.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "plt.rcParams['axes.linewidth'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a99775b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the training and validation loss values over epochs\n",
    "plt.plot(history_separated.history['loss'], label='Training')\n",
    "plt.plot(history_separated.history['val_loss'], label='Validation')\n",
    "plt.legend()\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8af9ef18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 15:11:42.141312: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#inverse transform the scaled outputs to get original values\n",
    "y_true_separated = scaler.inverse_transform(Ytest_separated)\n",
    "y_pred_separated = scaler.inverse_transform(model_separated.predict(xtest_separated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56426ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a scatter plot of predicted values for $s$ versus true values\n",
    "plt.plot(y_pred_separated, y_true_separated, 'bo', label='Predictions')\n",
    "plt.plot(y_true_separated, y_true_separated, color='orange', label='True')\n",
    "plt.xlabel(r\"$\\mathrm{s}$\")\n",
    "plt.ylabel(r\"$\\mathrm{\\hat{s}}$\")\n",
    "plt.legend()\n",
    "plt.savefig('predictedsvreal_separated.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a754a203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a scatter plot of the difference between the predicted and true values of $s$ versus true values\n",
    "plt.plot(y_true_separated[y_true_separated.flatten().argsort()], (y_pred_separated - y_true_separated)[y_true_separated.flatten().argsort()], 'bo')\n",
    "plt.xlabel(r\"$\\mathrm{s}$\")\n",
    "plt.ylabel(r\"$\\mathrm{\\hat{s} - s}$\")\n",
    "plt.savefig('errorvs_separated.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ffeeae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.007107688068703155\n",
      "0.01598012678008709\n"
     ]
    }
   ],
   "source": [
    "#Generate arrays for the error distribution containing only one Ohmic trajectory\n",
    "y_true_separated_distrib = np.concatenate((y_true_separated[y_true_separated != 1], y_true_separated[y_true_separated==1][[0]]))\n",
    "y_pred_separated_distrib = np.concatenate((y_pred_separated[y_true_separated != 1], y_pred_separated[y_true_separated==1][[0]]))\n",
    "\n",
    "#define an array where each element is the difference between the predicted value and true value for $s$ for a \n",
    "#given trajectory\n",
    "diffs1 = y_pred_separated_distrib - y_true_separated_distrib\n",
    "#print the minimum difference to find the smallest prediction error\n",
    "print(np.amin(diffs1))\n",
    "#print the maximum difference to find the largest prediction error\n",
    "print(np.amax(diffs1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f15a6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define intervals for analysing the differences between predicted and true values for $s$\n",
    "intervals1 = [-0.008, -0.0075, -0.007, -0.0065, -0.006, -0.0055, -0.005, -0.0045, -0.004, -0.0035, -0.003, -0.0025, -0.002, -0.0015, -0.001, -0.0005, 0, 0.0005, 0.001, 0.0015, 0.002, 0.0025, 0.003, 0.0035, 0.004, 0.0045, 0.005, 0.0055, 0.006, 0.0065, 0.007, 0.0075, 0.008, 0.0085, 0.009, 0.0095, 0.01, 0.0105, 0.011, 0.0115, 0.012, 0.0125, 0.013, 0.0135, 0.014, 0.0145, 0.015, 0.0155, 0.016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14c6c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise list to store the frequencies of differences in intervals for $s$\n",
    "freq1 = []\n",
    "\n",
    "#loop through each interval\n",
    "for i in range(len(intervals1)-1):\n",
    "    #create a mask to find differences within the current interval\n",
    "    mask1 = (diffs1 >= intervals1[i]) & (diffs1 < intervals1[i+1])\n",
    "    #append the count of differences within the current interval to the frequency list\n",
    "    freq1.append(len(diffs1[mask1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41c75067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calculate x positions for bars and heights\n",
    "x1 = intervals1[1:] \n",
    "heights1 = (np.array(freq1)/len(y_true_separated_distrib))*100\n",
    "\n",
    "#Create the bar chart\n",
    "plt.bar(x1, heights1, width=-0.0005, align='edge', alpha = 1, color = 'orange', edgecolor='black')  \n",
    "plt.xlabel(r\"$\\mathrm{\\hat{s} - s}$\")\n",
    "plt.ylabel('% of trajectories')\n",
    "plt.savefig('barchart_separated.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55a86ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data with $\\eta = 0.25$, $\\omega_c = 0.5$ with $s \\in (0, 1)$ if the spectral density is sub-Ohmic,\n",
    "#$s \\in (1, 4]$ is the spectral density is super-Ohmic and $s=1$ is the spectral density is Ohmic.\n",
    "X_notseparated = np.loadtxt('Data/Xtrainx_fixedηandω_notseparated.csv', delimiter=',')\n",
    "Y_notseparated = np.loadtxt('Data/Ytrain_fixedηandω_notseparated.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "598f9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_notseparateds[:,[4]] selects the column with the Ohmicity parameter, located at index 4\n",
    "Y_notseparateds = Y_notseparated[:,[4]]\n",
    "\n",
    "#Scale the labels using MinMaxScaler for normalisation\n",
    "scaler=MinMaxScaler()\n",
    "Y_notseparateds_scaled = scaler.fit_transform(Y_notseparateds)\n",
    "\n",
    "#Generating a training, validation and test set \n",
    "xtrain_notseparated, xval_notseparated, xtest_notseparated, Ytrain_notseparated, Yval_notseparated, Ytest_notseparated = fouriertrainvaltest(X_notseparated, Y_notseparateds_scaled, 4800, 2400, 2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81e84316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the path where the model's weights will be saved\n",
    "checkpoint_path = \"training_regressions_notseparated.weights.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "#Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b728e725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3543 - r_square: -1.3332"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 15:32:58.881883: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-10-17 15:32:59.042241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.3543 - r_square: -1.3332 - val_loss: 0.3153 - val_r_square: -0.8651\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3141 - r_square: -0.8256\n",
      "Epoch 2: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3141 - r_square: -0.8256 - val_loss: 0.2776 - val_r_square: -0.4796\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2773 - r_square: -0.4570\n",
      "Epoch 3: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2773 - r_square: -0.4570 - val_loss: 0.2430 - val_r_square: -0.2315\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2439 - r_square: -0.2228\n",
      "Epoch 4: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2439 - r_square: -0.2228 - val_loss: 0.2111 - val_r_square: -0.1129\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2136 - r_square: -0.1152\n",
      "Epoch 5: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2136 - r_square: -0.1152 - val_loss: 0.1825 - val_r_square: -0.1144\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1863 - r_square: -0.1245\n",
      "Epoch 6: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1863 - r_square: -0.1245 - val_loss: 0.1975 - val_r_square: -0.2248\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2022 - r_square: -0.2400\n",
      "Epoch 7: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2022 - r_square: -0.2400 - val_loss: 0.2084 - val_r_square: -0.2932\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2131 - r_square: -0.3095\n",
      "Epoch 8: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2131 - r_square: -0.3095 - val_loss: 0.2100 - val_r_square: -0.2809\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2142 - r_square: -0.2966\n",
      "Epoch 9: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2142 - r_square: -0.2966 - val_loss: 0.2026 - val_r_square: -0.1922\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2067 - r_square: -0.2067\n",
      "Epoch 10: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2067 - r_square: -0.2067 - val_loss: 0.1884 - val_r_square: -0.0510\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1923 - r_square: -0.0639\n",
      "Epoch 11: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1923 - r_square: -0.0639 - val_loss: 0.1695 - val_r_square: 0.1136\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1734 - r_square: 0.1026\n",
      "Epoch 12: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1734 - r_square: 0.1026 - val_loss: 0.1487 - val_r_square: 0.2745\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1523 - r_square: 0.2658\n",
      "Epoch 13: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1523 - r_square: 0.2658 - val_loss: 0.1286 - val_r_square: 0.4090\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1315 - r_square: 0.4032\n",
      "Epoch 14: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1315 - r_square: 0.4032 - val_loss: 0.1325 - val_r_square: 0.5016\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1345 - r_square: 0.4991\n",
      "Epoch 15: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1345 - r_square: 0.4991 - val_loss: 0.1363 - val_r_square: 0.5525\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1375 - r_square: 0.5527\n",
      "Epoch 16: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1375 - r_square: 0.5527 - val_loss: 0.1369 - val_r_square: 0.5877\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1375 - r_square: 0.5897\n",
      "Epoch 17: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1375 - r_square: 0.5897 - val_loss: 0.1336 - val_r_square: 0.6235\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1341 - r_square: 0.6263\n",
      "Epoch 18: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1341 - r_square: 0.6263 - val_loss: 0.1262 - val_r_square: 0.6668\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1267 - r_square: 0.6694\n",
      "Epoch 19: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1267 - r_square: 0.6694 - val_loss: 0.1147 - val_r_square: 0.7170\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1153 - r_square: 0.7189\n",
      "Epoch 20: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1153 - r_square: 0.7189 - val_loss: 0.0997 - val_r_square: 0.7682\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1004 - r_square: 0.7689\n",
      "Epoch 21: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1004 - r_square: 0.7689 - val_loss: 0.0818 - val_r_square: 0.8109\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0827 - r_square: 0.8105\n",
      "Epoch 22: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0827 - r_square: 0.8105 - val_loss: 0.0625 - val_r_square: 0.8350\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0639 - r_square: 0.8338\n",
      "Epoch 23: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0639 - r_square: 0.8338 - val_loss: 0.0693 - val_r_square: 0.8331\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0706 - r_square: 0.8318\n",
      "Epoch 24: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0706 - r_square: 0.8318 - val_loss: 0.0746 - val_r_square: 0.8387\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0759 - r_square: 0.8379\n",
      "Epoch 25: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0759 - r_square: 0.8379 - val_loss: 0.0697 - val_r_square: 0.8671\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0708 - r_square: 0.8668\n",
      "Epoch 26: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0708 - r_square: 0.8668 - val_loss: 0.0548 - val_r_square: 0.9116\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0556 - r_square: 0.9115\n",
      "Epoch 27: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0556 - r_square: 0.9115 - val_loss: 0.0339 - val_r_square: 0.9519\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0346 - r_square: 0.9517\n",
      "Epoch 28: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0346 - r_square: 0.9517 - val_loss: 0.0375 - val_r_square: 0.9633\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0376 - r_square: 0.9632\n",
      "Epoch 29: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0376 - r_square: 0.9632 - val_loss: 0.0459 - val_r_square: 0.9554\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0460 - r_square: 0.9553\n",
      "Epoch 30: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0460 - r_square: 0.9553 - val_loss: 0.0459 - val_r_square: 0.9533\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0464 - r_square: 0.9531\n",
      "Epoch 31: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0464 - r_square: 0.9531 - val_loss: 0.0369 - val_r_square: 0.9644\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0375 - r_square: 0.9640\n",
      "Epoch 32: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0375 - r_square: 0.9640 - val_loss: 0.0238 - val_r_square: 0.9806\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0245 - r_square: 0.9802\n",
      "Epoch 33: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0245 - r_square: 0.9802 - val_loss: 0.0259 - val_r_square: 0.9847\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0260 - r_square: 0.9847\n",
      "Epoch 34: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0260 - r_square: 0.9847 - val_loss: 0.0333 - val_r_square: 0.9776\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0330 - r_square: 0.9781\n",
      "Epoch 35: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0330 - r_square: 0.9781 - val_loss: 0.0366 - val_r_square: 0.9723\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0362 - r_square: 0.9731\n",
      "Epoch 36: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0362 - r_square: 0.9731 - val_loss: 0.0379 - val_r_square: 0.9716\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0376 - r_square: 0.9723\n",
      "Epoch 37: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0376 - r_square: 0.9723 - val_loss: 0.0376 - val_r_square: 0.9735\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0375 - r_square: 0.9740\n",
      "Epoch 38: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0375 - r_square: 0.9740 - val_loss: 0.0353 - val_r_square: 0.9765\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0354 - r_square: 0.9767\n",
      "Epoch 39: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0354 - r_square: 0.9767 - val_loss: 0.0315 - val_r_square: 0.9786\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0319 - r_square: 0.9785\n",
      "Epoch 40: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0319 - r_square: 0.9785 - val_loss: 0.0269 - val_r_square: 0.9779\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0276 - r_square: 0.9774\n",
      "Epoch 41: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0276 - r_square: 0.9774 - val_loss: 0.0320 - val_r_square: 0.9732\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0329 - r_square: 0.9726\n",
      "Epoch 42: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0329 - r_square: 0.9726 - val_loss: 0.0309 - val_r_square: 0.9761\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0316 - r_square: 0.9756\n",
      "Epoch 43: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0316 - r_square: 0.9756 - val_loss: 0.0230 - val_r_square: 0.9858\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0235 - r_square: 0.9855\n",
      "Epoch 44: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0235 - r_square: 0.9855 - val_loss: 0.0166 - val_r_square: 0.9923\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0167 - r_square: 0.9922\n",
      "Epoch 45: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0167 - r_square: 0.9922 - val_loss: 0.0204 - val_r_square: 0.9908\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0205 - r_square: 0.9909\n",
      "Epoch 46: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0205 - r_square: 0.9909 - val_loss: 0.0202 - val_r_square: 0.9907\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0204 - r_square: 0.9906\n",
      "Epoch 47: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0204 - r_square: 0.9906 - val_loss: 0.0147 - val_r_square: 0.9925\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0150 - r_square: 0.9924\n",
      "Epoch 48: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0150 - r_square: 0.9924 - val_loss: 0.0194 - val_r_square: 0.9900\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0196 - r_square: 0.9898\n",
      "Epoch 49: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0196 - r_square: 0.9898 - val_loss: 0.0250 - val_r_square: 0.9856\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0251 - r_square: 0.9855\n",
      "Epoch 50: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0251 - r_square: 0.9855 - val_loss: 0.0234 - val_r_square: 0.9872\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0235 - r_square: 0.9870\n",
      "Epoch 51: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0235 - r_square: 0.9870 - val_loss: 0.0171 - val_r_square: 0.9915\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0176 - r_square: 0.9913\n",
      "Epoch 52: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0176 - r_square: 0.9913 - val_loss: 0.0163 - val_r_square: 0.9909\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0169 - r_square: 0.9906\n",
      "Epoch 53: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0169 - r_square: 0.9906 - val_loss: 0.0189 - val_r_square: 0.9899\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0194 - r_square: 0.9896\n",
      "Epoch 54: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0194 - r_square: 0.9896 - val_loss: 0.0144 - val_r_square: 0.9926\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0149 - r_square: 0.9923\n",
      "Epoch 55: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0149 - r_square: 0.9923 - val_loss: 0.0144 - val_r_square: 0.9937\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0149 - r_square: 0.9934\n",
      "Epoch 56: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0149 - r_square: 0.9934 - val_loss: 0.0177 - val_r_square: 0.9920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0180 - r_square: 0.9917\n",
      "Epoch 57: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0180 - r_square: 0.9917 - val_loss: 0.0148 - val_r_square: 0.9937\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0153 - r_square: 0.9934\n",
      "Epoch 58: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0153 - r_square: 0.9934 - val_loss: 0.0102 - val_r_square: 0.9958\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9955\n",
      "Epoch 59: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0107 - r_square: 0.9955 - val_loss: 0.0172 - val_r_square: 0.9935\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0175 - r_square: 0.9933\n",
      "Epoch 60: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0175 - r_square: 0.9933 - val_loss: 0.0178 - val_r_square: 0.9934\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0181 - r_square: 0.9933\n",
      "Epoch 61: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0181 - r_square: 0.9933 - val_loss: 0.0117 - val_r_square: 0.9962\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0122 - r_square: 0.9959\n",
      "Epoch 62: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0122 - r_square: 0.9959 - val_loss: 0.0138 - val_r_square: 0.9941\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0140 - r_square: 0.9939\n",
      "Epoch 63: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0140 - r_square: 0.9939 - val_loss: 0.0179 - val_r_square: 0.9916\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0181 - r_square: 0.9914\n",
      "Epoch 64: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0181 - r_square: 0.9914 - val_loss: 0.0127 - val_r_square: 0.9950\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0130 - r_square: 0.9948\n",
      "Epoch 65: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0130 - r_square: 0.9948 - val_loss: 0.0106 - val_r_square: 0.9970\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0109 - r_square: 0.9968\n",
      "Epoch 66: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0109 - r_square: 0.9968 - val_loss: 0.0137 - val_r_square: 0.9960\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0139 - r_square: 0.9959\n",
      "Epoch 67: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0139 - r_square: 0.9959 - val_loss: 0.0111 - val_r_square: 0.9970\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - r_square: 0.9969\n",
      "Epoch 68: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0115 - r_square: 0.9969 - val_loss: 0.0085 - val_r_square: 0.9976\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0089 - r_square: 0.9975\n",
      "Epoch 69: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0089 - r_square: 0.9975 - val_loss: 0.0106 - val_r_square: 0.9969\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9967\n",
      "Epoch 70: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0108 - r_square: 0.9967 - val_loss: 0.0087 - val_r_square: 0.9977\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9976\n",
      "Epoch 71: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0090 - r_square: 0.9976 - val_loss: 0.0078 - val_r_square: 0.9979\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9978\n",
      "Epoch 72: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0081 - r_square: 0.9978 - val_loss: 0.0076 - val_r_square: 0.9979\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9978\n",
      "Epoch 73: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0079 - r_square: 0.9978 - val_loss: 0.0077 - val_r_square: 0.9979\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9978\n",
      "Epoch 74: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0080 - r_square: 0.9978 - val_loss: 0.0083 - val_r_square: 0.9977\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9976\n",
      "Epoch 75: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0085 - r_square: 0.9976 - val_loss: 0.0055 - val_r_square: 0.9983\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9982\n",
      "Epoch 76: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0058 - r_square: 0.9982 - val_loss: 0.0111 - val_r_square: 0.9972\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - r_square: 0.9971\n",
      "Epoch 77: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0113 - r_square: 0.9971 - val_loss: 0.0074 - val_r_square: 0.9981\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9980\n",
      "Epoch 78: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0076 - r_square: 0.9980 - val_loss: 0.0109 - val_r_square: 0.9969\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9968\n",
      "Epoch 79: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0110 - r_square: 0.9968 - val_loss: 0.0110 - val_r_square: 0.9969\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0111 - r_square: 0.9968\n",
      "Epoch 80: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0111 - r_square: 0.9968 - val_loss: 0.0060 - val_r_square: 0.9985\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9985\n",
      "Epoch 81: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0061 - r_square: 0.9985 - val_loss: 0.0084 - val_r_square: 0.9981\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9981\n",
      "Epoch 82: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0086 - r_square: 0.9981 - val_loss: 0.0045 - val_r_square: 0.9987\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9987\n",
      "Epoch 83: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - r_square: 0.9987 - val_loss: 0.0111 - val_r_square: 0.9971\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0112 - r_square: 0.9971\n",
      "Epoch 84: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0112 - r_square: 0.9971 - val_loss: 0.0075 - val_r_square: 0.9982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9982\n",
      "Epoch 85: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0076 - r_square: 0.9982 - val_loss: 0.0097 - val_r_square: 0.9978\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9978\n",
      "Epoch 86: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0099 - r_square: 0.9978 - val_loss: 0.0109 - val_r_square: 0.9975\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9975\n",
      "Epoch 87: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0110 - r_square: 0.9975 - val_loss: 0.0040 - val_r_square: 0.9989\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9989\n",
      "Epoch 88: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9989 - val_loss: 0.0062 - val_r_square: 0.9987\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9987\n",
      "Epoch 89: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - r_square: 0.9987 - val_loss: 0.0039 - val_r_square: 0.9991\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9990\n",
      "Epoch 90: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - r_square: 0.9990 - val_loss: 0.0037 - val_r_square: 0.9992\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9991\n",
      "Epoch 91: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - r_square: 0.9991 - val_loss: 0.0039 - val_r_square: 0.9992\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9992\n",
      "Epoch 92: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - r_square: 0.9992 - val_loss: 0.0058 - val_r_square: 0.9989\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9989\n",
      "Epoch 93: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - r_square: 0.9989 - val_loss: 0.0029 - val_r_square: 0.9994\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9993\n",
      "Epoch 94: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - r_square: 0.9993 - val_loss: 0.0090 - val_r_square: 0.9984\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9984\n",
      "Epoch 95: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0091 - r_square: 0.9984 - val_loss: 0.0061 - val_r_square: 0.9991\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9991\n",
      "Epoch 96: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - r_square: 0.9991 - val_loss: 0.0087 - val_r_square: 0.9982\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0088 - r_square: 0.9982\n",
      "Epoch 97: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0088 - r_square: 0.9982 - val_loss: 0.0080 - val_r_square: 0.9985\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9984\n",
      "Epoch 98: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0081 - r_square: 0.9984 - val_loss: 0.0060 - val_r_square: 0.9992\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9992\n",
      "Epoch 99: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - r_square: 0.9992 - val_loss: 0.0071 - val_r_square: 0.9990\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9990\n",
      "Epoch 100: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0071 - r_square: 0.9990 - val_loss: 0.0040 - val_r_square: 0.9994\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9994\n",
      "Epoch 101: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - r_square: 0.9994 - val_loss: 0.0033 - val_r_square: 0.9995\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9995\n",
      "Epoch 102: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - r_square: 0.9995 - val_loss: 0.0078 - val_r_square: 0.9989\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9989\n",
      "Epoch 103: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0078 - r_square: 0.9989 - val_loss: 0.0048 - val_r_square: 0.9994\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9994\n",
      "Epoch 104: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - r_square: 0.9994 - val_loss: 0.0102 - val_r_square: 0.9980\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9980\n",
      "Epoch 105: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0103 - r_square: 0.9980 - val_loss: 0.0108 - val_r_square: 0.9978\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9978\n",
      "Epoch 106: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0108 - r_square: 0.9978 - val_loss: 0.0027 - val_r_square: 0.9996\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9996\n",
      "Epoch 107: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - r_square: 0.9996 - val_loss: 0.0128 - val_r_square: 0.9972\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0128 - r_square: 0.9972\n",
      "Epoch 108: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0128 - r_square: 0.9972 - val_loss: 0.0125 - val_r_square: 0.9973\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0126 - r_square: 0.9974\n",
      "Epoch 109: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0126 - r_square: 0.9974 - val_loss: 0.0028 - val_r_square: 0.9997\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9997\n",
      "Epoch 110: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0028 - r_square: 0.9997 - val_loss: 0.0143 - val_r_square: 0.9964\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0144 - r_square: 0.9964\n",
      "Epoch 111: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0144 - r_square: 0.9964 - val_loss: 0.0161 - val_r_square: 0.9955\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0162 - r_square: 0.9955\n",
      "Epoch 112: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0162 - r_square: 0.9955 - val_loss: 0.0065 - val_r_square: 0.9991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9991\n",
      "Epoch 113: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0065 - r_square: 0.9991 - val_loss: 0.0128 - val_r_square: 0.9972\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0128 - r_square: 0.9973\n",
      "Epoch 114: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0128 - r_square: 0.9973 - val_loss: 0.0184 - val_r_square: 0.9944\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0184 - r_square: 0.9945\n",
      "Epoch 115: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0184 - r_square: 0.9945 - val_loss: 0.0128 - val_r_square: 0.9972\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0128 - r_square: 0.9973\n",
      "Epoch 116: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0128 - r_square: 0.9973 - val_loss: 0.0043 - val_r_square: 0.9995\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9995\n",
      "Epoch 117: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - r_square: 0.9995 - val_loss: 0.0091 - val_r_square: 0.9984\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9984\n",
      "Epoch 118: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0092 - r_square: 0.9984 - val_loss: 0.0037 - val_r_square: 0.9996\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9996\n",
      "Epoch 119: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - r_square: 0.9996 - val_loss: 0.0108 - val_r_square: 0.9980\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9980\n",
      "Epoch 120: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0108 - r_square: 0.9980 - val_loss: 0.0122 - val_r_square: 0.9975\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0122 - r_square: 0.9975\n",
      "Epoch 121: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0122 - r_square: 0.9975 - val_loss: 0.0040 - val_r_square: 0.9996\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9996\n",
      "Epoch 122: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - r_square: 0.9996 - val_loss: 0.0134 - val_r_square: 0.9968\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0135 - r_square: 0.9969\n",
      "Epoch 123: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0135 - r_square: 0.9969 - val_loss: 0.0168 - val_r_square: 0.9952\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0169 - r_square: 0.9952\n",
      "Epoch 124: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0169 - r_square: 0.9952 - val_loss: 0.0090 - val_r_square: 0.9985\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9985\n",
      "Epoch 125: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0090 - r_square: 0.9985 - val_loss: 0.0094 - val_r_square: 0.9985\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9985\n",
      "Epoch 126: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0094 - r_square: 0.9985 - val_loss: 0.0149 - val_r_square: 0.9963\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0149 - r_square: 0.9963\n",
      "Epoch 127: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0149 - r_square: 0.9963 - val_loss: 0.0099 - val_r_square: 0.9983\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9983\n",
      "Epoch 128: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0099 - r_square: 0.9983 - val_loss: 0.0055 - val_r_square: 0.9993\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9993\n",
      "Epoch 129: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9993 - val_loss: 0.0096 - val_r_square: 0.9983\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9983\n",
      "Epoch 130: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0097 - r_square: 0.9983 - val_loss: 0.0039 - val_r_square: 0.9996\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9996\n",
      "Epoch 131: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - r_square: 0.9996 - val_loss: 0.0101 - val_r_square: 0.9982\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - r_square: 0.9983\n",
      "Epoch 132: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0101 - r_square: 0.9983 - val_loss: 0.0113 - val_r_square: 0.9978\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - r_square: 0.9979\n",
      "Epoch 133: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0113 - r_square: 0.9979 - val_loss: 0.0031 - val_r_square: 0.9997\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9997\n",
      "Epoch 134: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - r_square: 0.9997 - val_loss: 0.0127 - val_r_square: 0.9972\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0128 - r_square: 0.9972\n",
      "Epoch 135: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0128 - r_square: 0.9972 - val_loss: 0.0154 - val_r_square: 0.9960\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0155 - r_square: 0.9960\n",
      "Epoch 136: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0155 - r_square: 0.9960 - val_loss: 0.0074 - val_r_square: 0.9989\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9989\n",
      "Epoch 137: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - r_square: 0.9989 - val_loss: 0.0098 - val_r_square: 0.9983\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9984\n",
      "Epoch 138: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0098 - r_square: 0.9984 - val_loss: 0.0148 - val_r_square: 0.9964\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0147 - r_square: 0.9964\n",
      "Epoch 139: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0147 - r_square: 0.9964 - val_loss: 0.0093 - val_r_square: 0.9985\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9985\n",
      "Epoch 140: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0093 - r_square: 0.9985 - val_loss: 0.0062 - val_r_square: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9992\n",
      "Epoch 141: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - r_square: 0.9992 - val_loss: 0.0105 - val_r_square: 0.9980\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9980\n",
      "Epoch 142: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0106 - r_square: 0.9980 - val_loss: 0.0049 - val_r_square: 0.9995\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9995\n",
      "Epoch 143: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - r_square: 0.9995 - val_loss: 0.0097 - val_r_square: 0.9984\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9984\n",
      "Epoch 144: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - r_square: 0.9984 - val_loss: 0.0123 - val_r_square: 0.9975\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0123 - r_square: 0.9975\n",
      "Epoch 145: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0123 - r_square: 0.9975 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 146: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0114 - val_r_square: 0.9977\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - r_square: 0.9977\n",
      "Epoch 147: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0115 - r_square: 0.9977 - val_loss: 0.0156 - val_r_square: 0.9959\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0157 - r_square: 0.9959\n",
      "Epoch 148: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0157 - r_square: 0.9959 - val_loss: 0.0093 - val_r_square: 0.9984\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9984\n",
      "Epoch 149: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0093 - r_square: 0.9984 - val_loss: 0.0069 - val_r_square: 0.9991\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 150: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0113 - val_r_square: 0.9978\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - r_square: 0.9979\n",
      "Epoch 151: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0113 - r_square: 0.9979 - val_loss: 0.0061 - val_r_square: 0.9993\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9993\n",
      "Epoch 152: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0061 - r_square: 0.9993 - val_loss: 0.0087 - val_r_square: 0.9986\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0087 - r_square: 0.9986\n",
      "Epoch 153: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0087 - r_square: 0.9986 - val_loss: 0.0116 - val_r_square: 0.9977\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0117 - r_square: 0.9977\n",
      "Epoch 154: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0117 - r_square: 0.9977 - val_loss: 0.0047 - val_r_square: 0.9995\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9995\n",
      "Epoch 155: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - r_square: 0.9995 - val_loss: 0.0107 - val_r_square: 0.9980\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9981\n",
      "Epoch 156: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0107 - r_square: 0.9981 - val_loss: 0.0143 - val_r_square: 0.9965\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0144 - r_square: 0.9966\n",
      "Epoch 157: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0144 - r_square: 0.9966 - val_loss: 0.0082 - val_r_square: 0.9988\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9988\n",
      "Epoch 158: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0083 - r_square: 0.9988 - val_loss: 0.0071 - val_r_square: 0.9990\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9990\n",
      "Epoch 159: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0071 - r_square: 0.9990 - val_loss: 0.0113 - val_r_square: 0.9978\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - r_square: 0.9978\n",
      "Epoch 160: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0113 - r_square: 0.9978 - val_loss: 0.0055 - val_r_square: 0.9994\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9994\n",
      "Epoch 161: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - r_square: 0.9994 - val_loss: 0.0088 - val_r_square: 0.9986\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0089 - r_square: 0.9986\n",
      "Epoch 162: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0089 - r_square: 0.9986 - val_loss: 0.0118 - val_r_square: 0.9976\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0119 - r_square: 0.9976\n",
      "Epoch 163: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0119 - r_square: 0.9976 - val_loss: 0.0054 - val_r_square: 0.9994\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9994\n",
      "Epoch 164: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0055 - r_square: 0.9994 - val_loss: 0.0101 - val_r_square: 0.9982\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - r_square: 0.9982\n",
      "Epoch 165: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0101 - r_square: 0.9982 - val_loss: 0.0140 - val_r_square: 0.9967\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0141 - r_square: 0.9967\n",
      "Epoch 166: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0141 - r_square: 0.9967 - val_loss: 0.0079 - val_r_square: 0.9988\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9988\n",
      "Epoch 167: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0079 - r_square: 0.9988 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9990\n",
      "Epoch 168: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - r_square: 0.9990 - val_loss: 0.0115 - val_r_square: 0.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0116 - r_square: 0.9977\n",
      "Epoch 169: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0116 - r_square: 0.9977 - val_loss: 0.0062 - val_r_square: 0.9992\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9992\n",
      "Epoch 170: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - r_square: 0.9992 - val_loss: 0.0081 - val_r_square: 0.9988\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9988\n",
      "Epoch 171: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0081 - r_square: 0.9988 - val_loss: 0.0112 - val_r_square: 0.9978\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0112 - r_square: 0.9979\n",
      "Epoch 172: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0112 - r_square: 0.9979 - val_loss: 0.0049 - val_r_square: 0.9995\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9995\n",
      "Epoch 173: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0049 - r_square: 0.9995 - val_loss: 0.0096 - val_r_square: 0.9984\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9984\n",
      "Epoch 174: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0096 - r_square: 0.9984 - val_loss: 0.0128 - val_r_square: 0.9972\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0128 - r_square: 0.9972\n",
      "Epoch 175: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0128 - r_square: 0.9972 - val_loss: 0.0066 - val_r_square: 0.9991\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9992\n",
      "Epoch 176: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0066 - r_square: 0.9992 - val_loss: 0.0084 - val_r_square: 0.9987\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0084 - r_square: 0.9987\n",
      "Epoch 177: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0084 - r_square: 0.9987 - val_loss: 0.0123 - val_r_square: 0.9974\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0123 - r_square: 0.9975\n",
      "Epoch 178: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0123 - r_square: 0.9975 - val_loss: 0.0065 - val_r_square: 0.9992\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9992\n",
      "Epoch 179: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0065 - r_square: 0.9992 - val_loss: 0.0075 - val_r_square: 0.9989\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9989\n",
      "Epoch 180: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0075 - r_square: 0.9989 - val_loss: 0.0107 - val_r_square: 0.9980\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9980\n",
      "Epoch 181: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0107 - r_square: 0.9980 - val_loss: 0.0049 - val_r_square: 0.9995\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9995\n",
      "Epoch 182: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - r_square: 0.9995 - val_loss: 0.0085 - val_r_square: 0.9987\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9987\n",
      "Epoch 183: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0085 - r_square: 0.9987 - val_loss: 0.0108 - val_r_square: 0.9980\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9980\n",
      "Epoch 184: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0108 - r_square: 0.9980 - val_loss: 0.0042 - val_r_square: 0.9996\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0042 - r_square: 0.9996\n",
      "Epoch 185: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - r_square: 0.9996 - val_loss: 0.0094 - val_r_square: 0.9984\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9984\n",
      "Epoch 186: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0095 - r_square: 0.9984 - val_loss: 0.0119 - val_r_square: 0.9976\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0119 - r_square: 0.9976\n",
      "Epoch 187: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0119 - r_square: 0.9976 - val_loss: 0.0052 - val_r_square: 0.9994\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9994\n",
      "Epoch 188: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - r_square: 0.9994 - val_loss: 0.0095 - val_r_square: 0.9984\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9984\n",
      "Epoch 189: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0095 - r_square: 0.9984 - val_loss: 0.0132 - val_r_square: 0.9970\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0133 - r_square: 0.9971\n",
      "Epoch 190: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0133 - r_square: 0.9971 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9990\n",
      "Epoch 191: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0074 - r_square: 0.9990 - val_loss: 0.0067 - val_r_square: 0.9991\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9992\n",
      "Epoch 192: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0067 - r_square: 0.9992 - val_loss: 0.0102 - val_r_square: 0.9982\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9982\n",
      "Epoch 193: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0102 - r_square: 0.9982 - val_loss: 0.0046 - val_r_square: 0.9995\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9995\n",
      "Epoch 194: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - r_square: 0.9995 - val_loss: 0.0086 - val_r_square: 0.9987\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9987\n",
      "Epoch 195: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0086 - r_square: 0.9987 - val_loss: 0.0110 - val_r_square: 0.9979\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9979\n",
      "Epoch 196: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0110 - r_square: 0.9979 - val_loss: 0.0046 - val_r_square: 0.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9996\n",
      "Epoch 197: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0046 - r_square: 0.9996 - val_loss: 0.0097 - val_r_square: 0.9983\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9984\n",
      "Epoch 198: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0098 - r_square: 0.9984 - val_loss: 0.0131 - val_r_square: 0.9971\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0131 - r_square: 0.9972\n",
      "Epoch 199: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0131 - r_square: 0.9972 - val_loss: 0.0072 - val_r_square: 0.9990\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9991\n",
      "Epoch 200: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0072 - r_square: 0.9991 - val_loss: 0.0072 - val_r_square: 0.9990\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9990\n",
      "Epoch 201: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0072 - r_square: 0.9990 - val_loss: 0.0112 - val_r_square: 0.9978\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - r_square: 0.9979\n",
      "Epoch 202: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0113 - r_square: 0.9979 - val_loss: 0.0059 - val_r_square: 0.9993\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9993\n",
      "Epoch 203: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0059 - r_square: 0.9993 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9990\n",
      "Epoch 204: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0075 - r_square: 0.9990 - val_loss: 0.0104 - val_r_square: 0.9981\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - r_square: 0.9981\n",
      "Epoch 205: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0104 - r_square: 0.9981 - val_loss: 0.0047 - val_r_square: 0.9995\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9995\n",
      "Epoch 206: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0047 - r_square: 0.9995 - val_loss: 0.0082 - val_r_square: 0.9988\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9988\n",
      "Epoch 207: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0083 - r_square: 0.9988 - val_loss: 0.0105 - val_r_square: 0.9981\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9981\n",
      "Epoch 208: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0105 - r_square: 0.9981 - val_loss: 0.0038 - val_r_square: 0.9997\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 209: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0095 - val_r_square: 0.9984\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9984\n",
      "Epoch 210: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0095 - r_square: 0.9984 - val_loss: 0.0123 - val_r_square: 0.9974\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0123 - r_square: 0.9975\n",
      "Epoch 211: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0123 - r_square: 0.9975 - val_loss: 0.0062 - val_r_square: 0.9993\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9993\n",
      "Epoch 212: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - r_square: 0.9993 - val_loss: 0.0082 - val_r_square: 0.9988\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9988\n",
      "Epoch 213: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0082 - r_square: 0.9988 - val_loss: 0.0120 - val_r_square: 0.9976\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0120 - r_square: 0.9976\n",
      "Epoch 214: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0120 - r_square: 0.9976 - val_loss: 0.0065 - val_r_square: 0.9992\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9992\n",
      "Epoch 215: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0065 - r_square: 0.9992 - val_loss: 0.0075 - val_r_square: 0.9990\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9990\n",
      "Epoch 216: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0075 - r_square: 0.9990 - val_loss: 0.0112 - val_r_square: 0.9979\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0112 - r_square: 0.9979\n",
      "Epoch 217: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0112 - r_square: 0.9979 - val_loss: 0.0061 - val_r_square: 0.9993\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9993\n",
      "Epoch 218: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0061 - r_square: 0.9993 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9990\n",
      "Epoch 219: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0075 - r_square: 0.9990 - val_loss: 0.0105 - val_r_square: 0.9981\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9981\n",
      "Epoch 220: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0106 - r_square: 0.9981 - val_loss: 0.0048 - val_r_square: 0.9995\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9995\n",
      "Epoch 221: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - r_square: 0.9995 - val_loss: 0.0086 - val_r_square: 0.9987\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9987\n",
      "Epoch 222: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0086 - r_square: 0.9987 - val_loss: 0.0115 - val_r_square: 0.9978\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - r_square: 0.9978\n",
      "Epoch 223: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0115 - r_square: 0.9978 - val_loss: 0.0056 - val_r_square: 0.9994\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9994\n",
      "Epoch 224: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0056 - r_square: 0.9994 - val_loss: 0.0085 - val_r_square: 0.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9987\n",
      "Epoch 225: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0086 - r_square: 0.9987 - val_loss: 0.0123 - val_r_square: 0.9975\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0123 - r_square: 0.9975\n",
      "Epoch 226: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0123 - r_square: 0.9975 - val_loss: 0.0068 - val_r_square: 0.9991\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9991\n",
      "Epoch 227: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0069 - r_square: 0.9991 - val_loss: 0.0065 - val_r_square: 0.9992\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9992\n",
      "Epoch 228: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0065 - r_square: 0.9992 - val_loss: 0.0098 - val_r_square: 0.9983\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9984\n",
      "Epoch 229: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0098 - r_square: 0.9984 - val_loss: 0.0044 - val_r_square: 0.9996\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9996\n",
      "Epoch 230: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0044 - r_square: 0.9996 - val_loss: 0.0082 - val_r_square: 0.9988\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9988\n",
      "Epoch 231: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0083 - r_square: 0.9988 - val_loss: 0.0106 - val_r_square: 0.9981\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9981\n",
      "Epoch 232: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0107 - r_square: 0.9981 - val_loss: 0.0045 - val_r_square: 0.9996\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9996\n",
      "Epoch 233: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - r_square: 0.9996 - val_loss: 0.0092 - val_r_square: 0.9985\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9985\n",
      "Epoch 234: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0092 - r_square: 0.9985 - val_loss: 0.0125 - val_r_square: 0.9974\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0125 - r_square: 0.9974\n",
      "Epoch 235: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0125 - r_square: 0.9974 - val_loss: 0.0069 - val_r_square: 0.9991\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9991\n",
      "Epoch 236: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0069 - r_square: 0.9991 - val_loss: 0.0067 - val_r_square: 0.9991\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9991\n",
      "Epoch 237: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0068 - r_square: 0.9991 - val_loss: 0.0103 - val_r_square: 0.9982\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9982\n",
      "Epoch 238: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0103 - r_square: 0.9982 - val_loss: 0.0049 - val_r_square: 0.9995\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9995\n",
      "Epoch 239: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0049 - r_square: 0.9995 - val_loss: 0.0080 - val_r_square: 0.9988\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9989\n",
      "Epoch 240: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0081 - r_square: 0.9989 - val_loss: 0.0110 - val_r_square: 0.9979\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9980\n",
      "Epoch 241: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0110 - r_square: 0.9980 - val_loss: 0.0053 - val_r_square: 0.9994\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9994\n",
      "Epoch 242: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0053 - r_square: 0.9994 - val_loss: 0.0079 - val_r_square: 0.9989\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9989\n",
      "Epoch 243: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0079 - r_square: 0.9989 - val_loss: 0.0110 - val_r_square: 0.9979\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9980\n",
      "Epoch 244: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0110 - r_square: 0.9980 - val_loss: 0.0051 - val_r_square: 0.9994\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 245: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0086 - val_r_square: 0.9987\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9987\n",
      "Epoch 246: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0086 - r_square: 0.9987 - val_loss: 0.0124 - val_r_square: 0.9974\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0124 - r_square: 0.9974\n",
      "Epoch 247: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0124 - r_square: 0.9974 - val_loss: 0.0075 - val_r_square: 0.9990\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9990\n",
      "Epoch 248: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0075 - r_square: 0.9990 - val_loss: 0.0054 - val_r_square: 0.9994\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9994\n",
      "Epoch 249: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0054 - r_square: 0.9994 - val_loss: 0.0084 - val_r_square: 0.9988\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0084 - r_square: 0.9988\n",
      "Epoch 250: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0084 - r_square: 0.9988 - val_loss: 0.0031 - val_r_square: 0.9998\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9998\n",
      "Epoch 251: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0030 - r_square: 0.9998 - val_loss: 0.0081 - val_r_square: 0.9988\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9989\n",
      "Epoch 252: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0081 - r_square: 0.9989 - val_loss: 0.0091 - val_r_square: 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9986\n",
      "Epoch 253: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0091 - r_square: 0.9986 - val_loss: 0.0028 - val_r_square: 0.9998\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9998\n",
      "Epoch 254: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - r_square: 0.9998 - val_loss: 0.0094 - val_r_square: 0.9985\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9985\n",
      "Epoch 255: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0094 - r_square: 0.9985 - val_loss: 0.0108 - val_r_square: 0.9980\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9980\n",
      "Epoch 256: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0108 - r_square: 0.9980 - val_loss: 0.0038 - val_r_square: 0.9997\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 257: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0100 - val_r_square: 0.9983\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9983\n",
      "Epoch 258: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0100 - r_square: 0.9983 - val_loss: 0.0135 - val_r_square: 0.9969\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0135 - r_square: 0.9970\n",
      "Epoch 259: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0135 - r_square: 0.9970 - val_loss: 0.0083 - val_r_square: 0.9988\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9988\n",
      "Epoch 260: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0083 - r_square: 0.9988 - val_loss: 0.0050 - val_r_square: 0.9995\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9995\n",
      "Epoch 261: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - r_square: 0.9995 - val_loss: 0.0090 - val_r_square: 0.9986\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9986\n",
      "Epoch 262: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0091 - r_square: 0.9986 - val_loss: 0.0043 - val_r_square: 0.9996\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9996\n",
      "Epoch 263: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0044 - r_square: 0.9996 - val_loss: 0.0078 - val_r_square: 0.9989\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9989\n",
      "Epoch 264: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0078 - r_square: 0.9989 - val_loss: 0.0103 - val_r_square: 0.9982\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9982\n",
      "Epoch 265: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0103 - r_square: 0.9982 - val_loss: 0.0046 - val_r_square: 0.9996\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9996\n",
      "Epoch 266: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - r_square: 0.9996 - val_loss: 0.0080 - val_r_square: 0.9989\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9989\n",
      "Epoch 267: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0080 - r_square: 0.9989 - val_loss: 0.0104 - val_r_square: 0.9982\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - r_square: 0.9982\n",
      "Epoch 268: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0104 - r_square: 0.9982 - val_loss: 0.0041 - val_r_square: 0.9996\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9996\n",
      "Epoch 269: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - r_square: 0.9996 - val_loss: 0.0097 - val_r_square: 0.9984\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9984\n",
      "Epoch 270: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0097 - r_square: 0.9984 - val_loss: 0.0137 - val_r_square: 0.9969\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0137 - r_square: 0.9969\n",
      "Epoch 271: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0137 - r_square: 0.9969 - val_loss: 0.0090 - val_r_square: 0.9986\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9986\n",
      "Epoch 272: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0090 - r_square: 0.9986 - val_loss: 0.0037 - val_r_square: 0.9997\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9997\n",
      "Epoch 273: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - r_square: 0.9997 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9990\n",
      "Epoch 274: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0077 - r_square: 0.9990 - val_loss: 0.0031 - val_r_square: 0.9997\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9997\n",
      "Epoch 275: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - r_square: 0.9997 - val_loss: 0.0079 - val_r_square: 0.9989\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9989\n",
      "Epoch 276: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0079 - r_square: 0.9989 - val_loss: 0.0094 - val_r_square: 0.9985\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9985\n",
      "Epoch 277: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0094 - r_square: 0.9985 - val_loss: 0.0032 - val_r_square: 0.9998\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 278: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0094 - val_r_square: 0.9985\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9985\n",
      "Epoch 279: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0094 - r_square: 0.9985 - val_loss: 0.0116 - val_r_square: 0.9977\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0116 - r_square: 0.9978\n",
      "Epoch 280: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0116 - r_square: 0.9978 - val_loss: 0.0051 - val_r_square: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 281: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0088 - val_r_square: 0.9987\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0088 - r_square: 0.9987\n",
      "Epoch 282: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0088 - r_square: 0.9987 - val_loss: 0.0130 - val_r_square: 0.9972\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0130 - r_square: 0.9972\n",
      "Epoch 283: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0130 - r_square: 0.9972 - val_loss: 0.0085 - val_r_square: 0.9987\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9988\n",
      "Epoch 284: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0085 - r_square: 0.9988 - val_loss: 0.0041 - val_r_square: 0.9996\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9996\n",
      "Epoch 285: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - r_square: 0.9996 - val_loss: 0.0077 - val_r_square: 0.9989\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9989\n",
      "Epoch 286: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0077 - r_square: 0.9989 - val_loss: 0.0031 - val_r_square: 0.9998\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 287: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0083 - val_r_square: 0.9988\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9988\n",
      "Epoch 288: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0083 - r_square: 0.9988 - val_loss: 0.0100 - val_r_square: 0.9983\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9983\n",
      "Epoch 289: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0100 - r_square: 0.9983 - val_loss: 0.0037 - val_r_square: 0.9997\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9997\n",
      "Epoch 290: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - r_square: 0.9997 - val_loss: 0.0089 - val_r_square: 0.9986\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9986\n",
      "Epoch 291: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0090 - r_square: 0.9986 - val_loss: 0.0115 - val_r_square: 0.9978\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0116 - r_square: 0.9978\n",
      "Epoch 292: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0116 - r_square: 0.9978 - val_loss: 0.0056 - val_r_square: 0.9994\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9994\n",
      "Epoch 293: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0056 - r_square: 0.9994 - val_loss: 0.0083 - val_r_square: 0.9988\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9988\n",
      "Epoch 294: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0083 - r_square: 0.9988 - val_loss: 0.0124 - val_r_square: 0.9974\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0124 - r_square: 0.9975\n",
      "Epoch 295: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0124 - r_square: 0.9975 - val_loss: 0.0081 - val_r_square: 0.9989\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9989\n",
      "Epoch 296: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0081 - r_square: 0.9989 - val_loss: 0.0040 - val_r_square: 0.9996\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9996\n",
      "Epoch 297: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0040 - r_square: 0.9996 - val_loss: 0.0068 - val_r_square: 0.9991\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9991\n",
      "Epoch 298: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0069 - r_square: 0.9991 - val_loss: 0.0019 - val_r_square: 0.9999\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - r_square: 0.9999\n",
      "Epoch 299: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0019 - r_square: 0.9999 - val_loss: 0.0085 - val_r_square: 0.9988\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9988\n",
      "Epoch 300: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0085 - r_square: 0.9988 - val_loss: 0.0089 - val_r_square: 0.9986\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0089 - r_square: 0.9987\n",
      "Epoch 301: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0089 - r_square: 0.9987 - val_loss: 0.0025 - val_r_square: 0.9999\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - r_square: 0.9999\n",
      "Epoch 302: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - r_square: 0.9999 - val_loss: 0.0088 - val_r_square: 0.9986\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0089 - r_square: 0.9986\n",
      "Epoch 303: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0089 - r_square: 0.9986 - val_loss: 0.0095 - val_r_square: 0.9984\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9984\n",
      "Epoch 304: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0096 - r_square: 0.9984 - val_loss: 0.0022 - val_r_square: 0.9998\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - r_square: 0.9998\n",
      "Epoch 305: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0022 - r_square: 0.9998 - val_loss: 0.0113 - val_r_square: 0.9979\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - r_square: 0.9979\n",
      "Epoch 306: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0113 - r_square: 0.9979 - val_loss: 0.0149 - val_r_square: 0.9964\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0149 - r_square: 0.9964\n",
      "Epoch 307: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0149 - r_square: 0.9964 - val_loss: 0.0099 - val_r_square: 0.9984\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9984\n",
      "Epoch 308: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0099 - r_square: 0.9984 - val_loss: 0.0029 - val_r_square: 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9998\n",
      "Epoch 309: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - r_square: 0.9998 - val_loss: 0.0072 - val_r_square: 0.9991\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9991\n",
      "Epoch 310: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0072 - r_square: 0.9991 - val_loss: 0.0029 - val_r_square: 0.9998\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9998\n",
      "Epoch 311: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - r_square: 0.9998 - val_loss: 0.0080 - val_r_square: 0.9989\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9989\n",
      "Epoch 312: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0080 - r_square: 0.9989 - val_loss: 0.0097 - val_r_square: 0.9984\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9984\n",
      "Epoch 313: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0097 - r_square: 0.9984 - val_loss: 0.0036 - val_r_square: 0.9997\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9997\n",
      "Epoch 314: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - r_square: 0.9997 - val_loss: 0.0089 - val_r_square: 0.9986\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0089 - r_square: 0.9986\n",
      "Epoch 315: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0089 - r_square: 0.9986 - val_loss: 0.0115 - val_r_square: 0.9978\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - r_square: 0.9978\n",
      "Epoch 316: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0115 - r_square: 0.9978 - val_loss: 0.0056 - val_r_square: 0.9994\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9994\n",
      "Epoch 317: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0056 - r_square: 0.9994 - val_loss: 0.0081 - val_r_square: 0.9989\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9989\n",
      "Epoch 318: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0081 - r_square: 0.9989 - val_loss: 0.0122 - val_r_square: 0.9975\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0122 - r_square: 0.9976\n",
      "Epoch 319: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0122 - r_square: 0.9976 - val_loss: 0.0078 - val_r_square: 0.9990\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9990\n",
      "Epoch 320: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0078 - r_square: 0.9990 - val_loss: 0.0044 - val_r_square: 0.9996\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9996\n",
      "Epoch 321: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - r_square: 0.9996 - val_loss: 0.0078 - val_r_square: 0.9989\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9989\n",
      "Epoch 322: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0079 - r_square: 0.9989 - val_loss: 0.0031 - val_r_square: 0.9998\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 323: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0086 - val_r_square: 0.9987\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9988\n",
      "Epoch 324: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0086 - r_square: 0.9988 - val_loss: 0.0107 - val_r_square: 0.9981\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9981\n",
      "Epoch 325: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0107 - r_square: 0.9981 - val_loss: 0.0046 - val_r_square: 0.9996\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9996\n",
      "Epoch 326: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0046 - r_square: 0.9996 - val_loss: 0.0090 - val_r_square: 0.9986\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9986\n",
      "Epoch 327: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0090 - r_square: 0.9986 - val_loss: 0.0129 - val_r_square: 0.9973\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0129 - r_square: 0.9973\n",
      "Epoch 328: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0129 - r_square: 0.9973 - val_loss: 0.0082 - val_r_square: 0.9988\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9988\n",
      "Epoch 329: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0082 - r_square: 0.9988 - val_loss: 0.0044 - val_r_square: 0.9996\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9996\n",
      "Epoch 330: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - r_square: 0.9996 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9990\n",
      "Epoch 331: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0077 - r_square: 0.9990 - val_loss: 0.0030 - val_r_square: 0.9998\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 332: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0075 - val_r_square: 0.9990\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9990\n",
      "Epoch 333: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0075 - r_square: 0.9990 - val_loss: 0.0085 - val_r_square: 0.9988\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9988\n",
      "Epoch 334: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0085 - r_square: 0.9988 - val_loss: 0.0018 - val_r_square: 0.9999\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 0.9999\n",
      "Epoch 335: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - r_square: 0.9999 - val_loss: 0.0105 - val_r_square: 0.9982\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9982\n",
      "Epoch 336: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0105 - r_square: 0.9982 - val_loss: 0.0130 - val_r_square: 0.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0130 - r_square: 0.9973\n",
      "Epoch 337: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0130 - r_square: 0.9973 - val_loss: 0.0071 - val_r_square: 0.9991\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9992\n",
      "Epoch 338: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - r_square: 0.9992 - val_loss: 0.0063 - val_r_square: 0.9993\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9993\n",
      "Epoch 339: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0063 - r_square: 0.9993 - val_loss: 0.0101 - val_r_square: 0.9983\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - r_square: 0.9983\n",
      "Epoch 340: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0101 - r_square: 0.9983 - val_loss: 0.0054 - val_r_square: 0.9994\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9994\n",
      "Epoch 341: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0054 - r_square: 0.9994 - val_loss: 0.0070 - val_r_square: 0.9991\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9992\n",
      "Epoch 342: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0070 - r_square: 0.9992 - val_loss: 0.0102 - val_r_square: 0.9983\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9983\n",
      "Epoch 343: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0102 - r_square: 0.9983 - val_loss: 0.0052 - val_r_square: 0.9995\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 344: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9990\n",
      "Epoch 345: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0074 - r_square: 0.9990 - val_loss: 0.0105 - val_r_square: 0.9981\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9982\n",
      "Epoch 346: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0105 - r_square: 0.9982 - val_loss: 0.0052 - val_r_square: 0.9995\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 347: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0073 - val_r_square: 0.9991\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9991\n",
      "Epoch 348: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0073 - r_square: 0.9991 - val_loss: 0.0106 - val_r_square: 0.9981\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9982\n",
      "Epoch 349: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0105 - r_square: 0.9982 - val_loss: 0.0055 - val_r_square: 0.9994\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 350: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0071 - val_r_square: 0.9991\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9991\n",
      "Epoch 351: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0071 - r_square: 0.9991 - val_loss: 0.0102 - val_r_square: 0.9982\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9983\n",
      "Epoch 352: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0102 - r_square: 0.9983 - val_loss: 0.0050 - val_r_square: 0.9995\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9995\n",
      "Epoch 353: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9995 - val_loss: 0.0072 - val_r_square: 0.9991\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9991\n",
      "Epoch 354: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - r_square: 0.9991 - val_loss: 0.0102 - val_r_square: 0.9983\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9983\n",
      "Epoch 355: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0102 - r_square: 0.9983 - val_loss: 0.0050 - val_r_square: 0.9995\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9995\n",
      "Epoch 356: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9995 - val_loss: 0.0077 - val_r_square: 0.9990\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9990\n",
      "Epoch 357: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0078 - r_square: 0.9990 - val_loss: 0.0110 - val_r_square: 0.9980\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9980\n",
      "Epoch 358: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0110 - r_square: 0.9980 - val_loss: 0.0059 - val_r_square: 0.9994\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9994\n",
      "Epoch 359: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0060 - r_square: 0.9994 - val_loss: 0.0067 - val_r_square: 0.9992\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9992\n",
      "Epoch 360: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0067 - r_square: 0.9992 - val_loss: 0.0102 - val_r_square: 0.9983\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9983\n",
      "Epoch 361: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0102 - r_square: 0.9983 - val_loss: 0.0054 - val_r_square: 0.9995\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 362: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0069 - val_r_square: 0.9992\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 363: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0098 - val_r_square: 0.9984\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9984\n",
      "Epoch 364: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0099 - r_square: 0.9984 - val_loss: 0.0046 - val_r_square: 0.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9996\n",
      "Epoch 365: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - r_square: 0.9996 - val_loss: 0.0075 - val_r_square: 0.9990\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9990\n",
      "Epoch 366: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0075 - r_square: 0.9990 - val_loss: 0.0104 - val_r_square: 0.9982\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - r_square: 0.9982\n",
      "Epoch 367: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0104 - r_square: 0.9982 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9995\n",
      "Epoch 368: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - r_square: 0.9995 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9990\n",
      "Epoch 369: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0076 - r_square: 0.9990 - val_loss: 0.0109 - val_r_square: 0.9980\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0109 - r_square: 0.9980\n",
      "Epoch 370: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0109 - r_square: 0.9980 - val_loss: 0.0060 - val_r_square: 0.9993\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9994\n",
      "Epoch 371: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - r_square: 0.9994 - val_loss: 0.0065 - val_r_square: 0.9992\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9993\n",
      "Epoch 372: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - r_square: 0.9993 - val_loss: 0.0098 - val_r_square: 0.9984\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9984\n",
      "Epoch 373: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0098 - r_square: 0.9984 - val_loss: 0.0049 - val_r_square: 0.9995\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9995\n",
      "Epoch 374: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - r_square: 0.9995 - val_loss: 0.0073 - val_r_square: 0.9991\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9991\n",
      "Epoch 375: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0073 - r_square: 0.9991 - val_loss: 0.0102 - val_r_square: 0.9982\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9983\n",
      "Epoch 376: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0103 - r_square: 0.9983 - val_loss: 0.0050 - val_r_square: 0.9995\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9995\n",
      "Epoch 377: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0050 - r_square: 0.9995 - val_loss: 0.0072 - val_r_square: 0.9991\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9991\n",
      "Epoch 378: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - r_square: 0.9991 - val_loss: 0.0104 - val_r_square: 0.9982\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - r_square: 0.9982\n",
      "Epoch 379: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0104 - r_square: 0.9982 - val_loss: 0.0053 - val_r_square: 0.9994\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 380: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0070 - val_r_square: 0.9991\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9991\n",
      "Epoch 381: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0070 - r_square: 0.9991 - val_loss: 0.0102 - val_r_square: 0.9983\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9983\n",
      "Epoch 382: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0102 - r_square: 0.9983 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9995\n",
      "Epoch 383: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - r_square: 0.9995 - val_loss: 0.0072 - val_r_square: 0.9991\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9991\n",
      "Epoch 384: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0072 - r_square: 0.9991 - val_loss: 0.0104 - val_r_square: 0.9982\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - r_square: 0.9982\n",
      "Epoch 385: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0104 - r_square: 0.9982 - val_loss: 0.0054 - val_r_square: 0.9994\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9994\n",
      "Epoch 386: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - r_square: 0.9994 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9992\n",
      "Epoch 387: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0068 - r_square: 0.9992 - val_loss: 0.0099 - val_r_square: 0.9983\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9984\n",
      "Epoch 388: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0099 - r_square: 0.9984 - val_loss: 0.0048 - val_r_square: 0.9995\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9995\n",
      "Epoch 389: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - r_square: 0.9995 - val_loss: 0.0072 - val_r_square: 0.9991\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9991\n",
      "Epoch 390: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - r_square: 0.9991 - val_loss: 0.0102 - val_r_square: 0.9982\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9982\n",
      "Epoch 391: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0102 - r_square: 0.9982 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9995\n",
      "Epoch 392: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - r_square: 0.9995 - val_loss: 0.0067 - val_r_square: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9992\n",
      "Epoch 393: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0067 - r_square: 0.9992 - val_loss: 0.0094 - val_r_square: 0.9985\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9985\n",
      "Epoch 394: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0094 - r_square: 0.9985 - val_loss: 0.0041 - val_r_square: 0.9996\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 395: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0075 - val_r_square: 0.9990\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9990\n",
      "Epoch 396: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0076 - r_square: 0.9990 - val_loss: 0.0101 - val_r_square: 0.9982\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9983\n",
      "Epoch 397: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0102 - r_square: 0.9983 - val_loss: 0.0048 - val_r_square: 0.9995\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9996\n",
      "Epoch 398: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0048 - r_square: 0.9996 - val_loss: 0.0072 - val_r_square: 0.9991\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9991\n",
      "Epoch 399: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0072 - r_square: 0.9991 - val_loss: 0.0100 - val_r_square: 0.9983\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9984\n",
      "Epoch 400: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0100 - r_square: 0.9984 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 401: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9990\n",
      "Epoch 402: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0076 - r_square: 0.9990 - val_loss: 0.0108 - val_r_square: 0.9980\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9981\n",
      "Epoch 403: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0108 - r_square: 0.9981 - val_loss: 0.0060 - val_r_square: 0.9993\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9994\n",
      "Epoch 404: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - r_square: 0.9994 - val_loss: 0.0061 - val_r_square: 0.9993\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9993\n",
      "Epoch 405: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - r_square: 0.9993 - val_loss: 0.0092 - val_r_square: 0.9986\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9986\n",
      "Epoch 406: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0092 - r_square: 0.9986 - val_loss: 0.0041 - val_r_square: 0.9996\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 407: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0078 - val_r_square: 0.9989\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9990\n",
      "Epoch 408: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0078 - r_square: 0.9990 - val_loss: 0.0108 - val_r_square: 0.9981\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9981\n",
      "Epoch 409: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0108 - r_square: 0.9981 - val_loss: 0.0057 - val_r_square: 0.9994\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9994\n",
      "Epoch 410: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0057 - r_square: 0.9994 - val_loss: 0.0066 - val_r_square: 0.9992\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9992\n",
      "Epoch 411: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0066 - r_square: 0.9992 - val_loss: 0.0097 - val_r_square: 0.9984\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9984\n",
      "Epoch 412: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0098 - r_square: 0.9984 - val_loss: 0.0048 - val_r_square: 0.9995\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9995\n",
      "Epoch 413: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - r_square: 0.9995 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9990\n",
      "Epoch 414: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0075 - r_square: 0.9990 - val_loss: 0.0108 - val_r_square: 0.9980\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9981\n",
      "Epoch 415: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0108 - r_square: 0.9981 - val_loss: 0.0061 - val_r_square: 0.9993\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9993\n",
      "Epoch 416: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - r_square: 0.9993 - val_loss: 0.0058 - val_r_square: 0.9994\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9994\n",
      "Epoch 417: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0058 - r_square: 0.9994 - val_loss: 0.0087 - val_r_square: 0.9987\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0087 - r_square: 0.9987\n",
      "Epoch 418: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0087 - r_square: 0.9987 - val_loss: 0.0035 - val_r_square: 0.9997\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - r_square: 0.9997\n",
      "Epoch 419: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - r_square: 0.9997 - val_loss: 0.0084 - val_r_square: 0.9988\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0084 - r_square: 0.9988\n",
      "Epoch 420: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0084 - r_square: 0.9988 - val_loss: 0.0113 - val_r_square: 0.9978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0114 - r_square: 0.9979\n",
      "Epoch 421: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0114 - r_square: 0.9979 - val_loss: 0.0063 - val_r_square: 0.9993\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9993\n",
      "Epoch 422: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0064 - r_square: 0.9993 - val_loss: 0.0058 - val_r_square: 0.9994\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9994\n",
      "Epoch 423: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - r_square: 0.9994 - val_loss: 0.0090 - val_r_square: 0.9986\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9986\n",
      "Epoch 424: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0090 - r_square: 0.9986 - val_loss: 0.0041 - val_r_square: 0.9996\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9996\n",
      "Epoch 425: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9996 - val_loss: 0.0081 - val_r_square: 0.9989\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9989\n",
      "Epoch 426: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0081 - r_square: 0.9989 - val_loss: 0.0113 - val_r_square: 0.9978\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0114 - r_square: 0.9978\n",
      "Epoch 427: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0114 - r_square: 0.9978 - val_loss: 0.0066 - val_r_square: 0.9992\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9992\n",
      "Epoch 428: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0067 - r_square: 0.9992 - val_loss: 0.0052 - val_r_square: 0.9995\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 429: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0082 - val_r_square: 0.9989\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9989\n",
      "Epoch 430: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0082 - r_square: 0.9989 - val_loss: 0.0032 - val_r_square: 0.9998\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 431: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0075 - val_r_square: 0.9990\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9990\n",
      "Epoch 432: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0076 - r_square: 0.9990 - val_loss: 0.0095 - val_r_square: 0.9985\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9985\n",
      "Epoch 433: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0095 - r_square: 0.9985 - val_loss: 0.0039 - val_r_square: 0.9997\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9997\n",
      "Epoch 434: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - r_square: 0.9997 - val_loss: 0.0078 - val_r_square: 0.9990\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9990\n",
      "Epoch 435: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0078 - r_square: 0.9990 - val_loss: 0.0102 - val_r_square: 0.9982\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9983\n",
      "Epoch 436: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0103 - r_square: 0.9983 - val_loss: 0.0048 - val_r_square: 0.9995\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9995\n",
      "Epoch 437: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - r_square: 0.9995 - val_loss: 0.0075 - val_r_square: 0.9990\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9990\n",
      "Epoch 438: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0075 - r_square: 0.9990 - val_loss: 0.0108 - val_r_square: 0.9980\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9981\n",
      "Epoch 439: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0108 - r_square: 0.9981 - val_loss: 0.0062 - val_r_square: 0.9993\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9993\n",
      "Epoch 440: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - r_square: 0.9993 - val_loss: 0.0056 - val_r_square: 0.9994\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9994\n",
      "Epoch 441: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0056 - r_square: 0.9994 - val_loss: 0.0085 - val_r_square: 0.9987\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9987\n",
      "Epoch 442: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0085 - r_square: 0.9987 - val_loss: 0.0036 - val_r_square: 0.9997\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9997\n",
      "Epoch 443: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - r_square: 0.9997 - val_loss: 0.0078 - val_r_square: 0.9989\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9990\n",
      "Epoch 444: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0078 - r_square: 0.9990 - val_loss: 0.0103 - val_r_square: 0.9982\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9983\n",
      "Epoch 445: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0103 - r_square: 0.9983 - val_loss: 0.0049 - val_r_square: 0.9995\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9996\n",
      "Epoch 446: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - r_square: 0.9996 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9990\n",
      "Epoch 447: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0074 - r_square: 0.9990 - val_loss: 0.0106 - val_r_square: 0.9981\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9981\n",
      "Epoch 448: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0107 - r_square: 0.9981 - val_loss: 0.0059 - val_r_square: 0.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9993\n",
      "Epoch 449: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0059 - r_square: 0.9993 - val_loss: 0.0061 - val_r_square: 0.9993\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9993\n",
      "Epoch 450: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - r_square: 0.9993 - val_loss: 0.0093 - val_r_square: 0.9985\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9986\n",
      "Epoch 451: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0093 - r_square: 0.9986 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 452: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0070 - val_r_square: 0.9991\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9991\n",
      "Epoch 453: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0070 - r_square: 0.9991 - val_loss: 0.0098 - val_r_square: 0.9984\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9984\n",
      "Epoch 454: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0098 - r_square: 0.9984 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 455: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9990\n",
      "Epoch 456: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0076 - r_square: 0.9990 - val_loss: 0.0111 - val_r_square: 0.9980\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0111 - r_square: 0.9980\n",
      "Epoch 457: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0111 - r_square: 0.9980 - val_loss: 0.0066 - val_r_square: 0.9992\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9992\n",
      "Epoch 458: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0066 - r_square: 0.9992 - val_loss: 0.0049 - val_r_square: 0.9995\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9995\n",
      "Epoch 459: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - r_square: 0.9995 - val_loss: 0.0077 - val_r_square: 0.9990\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9990\n",
      "Epoch 460: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0077 - r_square: 0.9990 - val_loss: 0.0028 - val_r_square: 0.9998\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9998\n",
      "Epoch 461: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - r_square: 0.9998 - val_loss: 0.0081 - val_r_square: 0.9989\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9989\n",
      "Epoch 462: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0081 - r_square: 0.9989 - val_loss: 0.0102 - val_r_square: 0.9982\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9983\n",
      "Epoch 463: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0102 - r_square: 0.9983 - val_loss: 0.0046 - val_r_square: 0.9996\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9996\n",
      "Epoch 464: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - r_square: 0.9996 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9990\n",
      "Epoch 465: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - r_square: 0.9990 - val_loss: 0.0105 - val_r_square: 0.9982\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9982\n",
      "Epoch 466: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0105 - r_square: 0.9982 - val_loss: 0.0057 - val_r_square: 0.9994\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9994\n",
      "Epoch 467: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - r_square: 0.9994 - val_loss: 0.0063 - val_r_square: 0.9993\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9993\n",
      "Epoch 468: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - r_square: 0.9993 - val_loss: 0.0096 - val_r_square: 0.9984\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9985\n",
      "Epoch 469: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0096 - r_square: 0.9985 - val_loss: 0.0050 - val_r_square: 0.9995\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9995\n",
      "Epoch 470: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - r_square: 0.9995 - val_loss: 0.0065 - val_r_square: 0.9992\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9992\n",
      "Epoch 471: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - r_square: 0.9992 - val_loss: 0.0093 - val_r_square: 0.9985\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9985\n",
      "Epoch 472: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0093 - r_square: 0.9985 - val_loss: 0.0042 - val_r_square: 0.9996\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9996\n",
      "Epoch 473: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - r_square: 0.9996 - val_loss: 0.0079 - val_r_square: 0.9989\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9989\n",
      "Epoch 474: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0079 - r_square: 0.9989 - val_loss: 0.0113 - val_r_square: 0.9979\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - r_square: 0.9979\n",
      "Epoch 475: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0113 - r_square: 0.9979 - val_loss: 0.0067 - val_r_square: 0.9992\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9992\n",
      "Epoch 476: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0067 - r_square: 0.9992 - val_loss: 0.0048 - val_r_square: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9995\n",
      "Epoch 477: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0049 - r_square: 0.9995 - val_loss: 0.0077 - val_r_square: 0.9990\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9990\n",
      "Epoch 478: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0077 - r_square: 0.9990 - val_loss: 0.0029 - val_r_square: 0.9998\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9998\n",
      "Epoch 479: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - r_square: 0.9998 - val_loss: 0.0080 - val_r_square: 0.9989\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9989\n",
      "Epoch 480: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0080 - r_square: 0.9989 - val_loss: 0.0101 - val_r_square: 0.9983\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - r_square: 0.9983\n",
      "Epoch 481: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0101 - r_square: 0.9983 - val_loss: 0.0045 - val_r_square: 0.9996\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9996\n",
      "Epoch 482: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0045 - r_square: 0.9996 - val_loss: 0.0073 - val_r_square: 0.9991\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9991\n",
      "Epoch 483: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0073 - r_square: 0.9991 - val_loss: 0.0103 - val_r_square: 0.9982\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9982\n",
      "Epoch 484: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0103 - r_square: 0.9982 - val_loss: 0.0054 - val_r_square: 0.9994\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9994\n",
      "Epoch 485: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - r_square: 0.9994 - val_loss: 0.0065 - val_r_square: 0.9992\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9993\n",
      "Epoch 486: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0065 - r_square: 0.9993 - val_loss: 0.0098 - val_r_square: 0.9984\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9984\n",
      "Epoch 487: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0098 - r_square: 0.9984 - val_loss: 0.0053 - val_r_square: 0.9995\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 488: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0061 - val_r_square: 0.9993\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9993\n",
      "Epoch 489: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - r_square: 0.9993 - val_loss: 0.0089 - val_r_square: 0.9987\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0089 - r_square: 0.9987\n",
      "Epoch 490: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0089 - r_square: 0.9987 - val_loss: 0.0038 - val_r_square: 0.9997\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 491: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0080 - val_r_square: 0.9989\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9989\n",
      "Epoch 492: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0080 - r_square: 0.9989 - val_loss: 0.0111 - val_r_square: 0.9979\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0111 - r_square: 0.9980\n",
      "Epoch 493: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0111 - r_square: 0.9980 - val_loss: 0.0065 - val_r_square: 0.9992\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9993\n",
      "Epoch 494: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0065 - r_square: 0.9993 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 495: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0081 - val_r_square: 0.9989\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9989\n",
      "Epoch 496: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0081 - r_square: 0.9989 - val_loss: 0.0032 - val_r_square: 0.9998\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 497: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0082 - val_r_square: 0.9988\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9989\n",
      "Epoch 498: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0082 - r_square: 0.9989 - val_loss: 0.0109 - val_r_square: 0.9980\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0109 - r_square: 0.9980\n",
      "Epoch 499: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0109 - r_square: 0.9980 - val_loss: 0.0059 - val_r_square: 0.9994\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9994\n",
      "Epoch 500: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - r_square: 0.9994 - val_loss: 0.0060 - val_r_square: 0.9993\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9993\n",
      "Epoch 501: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - r_square: 0.9993 - val_loss: 0.0091 - val_r_square: 0.9986\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9986\n",
      "Epoch 502: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0092 - r_square: 0.9986 - val_loss: 0.0045 - val_r_square: 0.9996\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9996\n",
      "Epoch 503: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - r_square: 0.9996 - val_loss: 0.0072 - val_r_square: 0.9991\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9991\n",
      "Epoch 504: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - r_square: 0.9991 - val_loss: 0.0103 - val_r_square: 0.9982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9982\n",
      "Epoch 505: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0103 - r_square: 0.9982 - val_loss: 0.0058 - val_r_square: 0.9994\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9994\n",
      "Epoch 506: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0058 - r_square: 0.9994 - val_loss: 0.0057 - val_r_square: 0.9994\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9994\n",
      "Epoch 507: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - r_square: 0.9994 - val_loss: 0.0085 - val_r_square: 0.9987\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9988\n",
      "Epoch 508: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0085 - r_square: 0.9988 - val_loss: 0.0036 - val_r_square: 0.9997\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9997\n",
      "Epoch 509: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - r_square: 0.9997 - val_loss: 0.0080 - val_r_square: 0.9989\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9989\n",
      "Epoch 510: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0080 - r_square: 0.9989 - val_loss: 0.0110 - val_r_square: 0.9980\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9980\n",
      "Epoch 511: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0110 - r_square: 0.9980 - val_loss: 0.0063 - val_r_square: 0.9993\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9993\n",
      "Epoch 512: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - r_square: 0.9993 - val_loss: 0.0053 - val_r_square: 0.9995\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9995\n",
      "Epoch 513: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - r_square: 0.9995 - val_loss: 0.0083 - val_r_square: 0.9988\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9988\n",
      "Epoch 514: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0083 - r_square: 0.9988 - val_loss: 0.0035 - val_r_square: 0.9997\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - r_square: 0.9997\n",
      "Epoch 515: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - r_square: 0.9997 - val_loss: 0.0078 - val_r_square: 0.9989\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9989\n",
      "Epoch 516: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0078 - r_square: 0.9989 - val_loss: 0.0106 - val_r_square: 0.9981\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9981\n",
      "Epoch 517: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0106 - r_square: 0.9981 - val_loss: 0.0056 - val_r_square: 0.9994\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9994\n",
      "Epoch 518: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - r_square: 0.9994 - val_loss: 0.0062 - val_r_square: 0.9993\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9993\n",
      "Epoch 519: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - r_square: 0.9993 - val_loss: 0.0093 - val_r_square: 0.9985\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9986\n",
      "Epoch 520: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0093 - r_square: 0.9986 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 521: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0069 - val_r_square: 0.9991\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9991\n",
      "Epoch 522: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0069 - r_square: 0.9991 - val_loss: 0.0100 - val_r_square: 0.9983\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9983\n",
      "Epoch 523: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0100 - r_square: 0.9983 - val_loss: 0.0054 - val_r_square: 0.9994\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9994\n",
      "Epoch 524: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - r_square: 0.9994 - val_loss: 0.0061 - val_r_square: 0.9993\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9993\n",
      "Epoch 525: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - r_square: 0.9993 - val_loss: 0.0089 - val_r_square: 0.9986\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9987\n",
      "Epoch 526: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0090 - r_square: 0.9987 - val_loss: 0.0041 - val_r_square: 0.9996\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9996\n",
      "Epoch 527: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9996 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9990\n",
      "Epoch 528: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0076 - r_square: 0.9990 - val_loss: 0.0108 - val_r_square: 0.9980\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9981\n",
      "Epoch 529: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0108 - r_square: 0.9981 - val_loss: 0.0063 - val_r_square: 0.9993\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9993\n",
      "Epoch 530: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - r_square: 0.9993 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 531: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0080 - val_r_square: 0.9989\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9989\n",
      "Epoch 532: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0080 - r_square: 0.9989 - val_loss: 0.0033 - val_r_square: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - r_square: 0.9998\n",
      "Epoch 533: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - r_square: 0.9998 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9990\n",
      "Epoch 534: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - r_square: 0.9990 - val_loss: 0.0096 - val_r_square: 0.9984\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9984\n",
      "Epoch 535: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0096 - r_square: 0.9984 - val_loss: 0.0043 - val_r_square: 0.9996\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9996\n",
      "Epoch 536: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - r_square: 0.9996 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9992\n",
      "Epoch 537: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9992 - val_loss: 0.0092 - val_r_square: 0.9986\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9986\n",
      "Epoch 538: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0092 - r_square: 0.9986 - val_loss: 0.0039 - val_r_square: 0.9997\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9997\n",
      "Epoch 539: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - r_square: 0.9997 - val_loss: 0.0079 - val_r_square: 0.9989\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9989\n",
      "Epoch 540: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0079 - r_square: 0.9989 - val_loss: 0.0112 - val_r_square: 0.9979\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0112 - r_square: 0.9980\n",
      "Epoch 541: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0112 - r_square: 0.9980 - val_loss: 0.0067 - val_r_square: 0.9992\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9992\n",
      "Epoch 542: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0067 - r_square: 0.9992 - val_loss: 0.0046 - val_r_square: 0.9996\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9996\n",
      "Epoch 543: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - r_square: 0.9996 - val_loss: 0.0073 - val_r_square: 0.9990\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9991\n",
      "Epoch 544: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0074 - r_square: 0.9991 - val_loss: 0.0026 - val_r_square: 0.9998\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - r_square: 0.9998\n",
      "Epoch 545: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - r_square: 0.9998 - val_loss: 0.0079 - val_r_square: 0.9989\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9989\n",
      "Epoch 546: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0079 - r_square: 0.9989 - val_loss: 0.0100 - val_r_square: 0.9983\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9983\n",
      "Epoch 547: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0100 - r_square: 0.9983 - val_loss: 0.0045 - val_r_square: 0.9996\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9996\n",
      "Epoch 548: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - r_square: 0.9996 - val_loss: 0.0069 - val_r_square: 0.9991\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 549: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0097 - val_r_square: 0.9984\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9984\n",
      "Epoch 550: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0097 - r_square: 0.9984 - val_loss: 0.0049 - val_r_square: 0.9995\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9995\n",
      "Epoch 551: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0049 - r_square: 0.9995 - val_loss: 0.0069 - val_r_square: 0.9992\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 552: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0102 - val_r_square: 0.9983\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9983\n",
      "Epoch 553: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0102 - r_square: 0.9983 - val_loss: 0.0059 - val_r_square: 0.9994\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9994\n",
      "Epoch 554: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - r_square: 0.9994 - val_loss: 0.0053 - val_r_square: 0.9995\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9995\n",
      "Epoch 555: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - r_square: 0.9995 - val_loss: 0.0079 - val_r_square: 0.9989\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9989\n",
      "Epoch 556: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0080 - r_square: 0.9989 - val_loss: 0.0030 - val_r_square: 0.9998\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9998\n",
      "Epoch 557: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - r_square: 0.9998 - val_loss: 0.0080 - val_r_square: 0.9989\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9989\n",
      "Epoch 558: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0080 - r_square: 0.9989 - val_loss: 0.0106 - val_r_square: 0.9981\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9981\n",
      "Epoch 559: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0106 - r_square: 0.9981 - val_loss: 0.0057 - val_r_square: 0.9994\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9994\n",
      "Epoch 560: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0057 - r_square: 0.9994 - val_loss: 0.0060 - val_r_square: 0.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9993\n",
      "Epoch 561: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - r_square: 0.9993 - val_loss: 0.0092 - val_r_square: 0.9986\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9986\n",
      "Epoch 562: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0092 - r_square: 0.9986 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 563: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0067 - val_r_square: 0.9992\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9992\n",
      "Epoch 564: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0067 - r_square: 0.9992 - val_loss: 0.0097 - val_r_square: 0.9984\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9984\n",
      "Epoch 565: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - r_square: 0.9984 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9995\n",
      "Epoch 566: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - r_square: 0.9995 - val_loss: 0.0062 - val_r_square: 0.9993\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9993\n",
      "Epoch 567: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - r_square: 0.9993 - val_loss: 0.0090 - val_r_square: 0.9986\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9986\n",
      "Epoch 568: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0090 - r_square: 0.9986 - val_loss: 0.0043 - val_r_square: 0.9996\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9996\n",
      "Epoch 569: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - r_square: 0.9996 - val_loss: 0.0073 - val_r_square: 0.9990\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9991\n",
      "Epoch 570: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0073 - r_square: 0.9991 - val_loss: 0.0105 - val_r_square: 0.9981\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9982\n",
      "Epoch 571: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0105 - r_square: 0.9982 - val_loss: 0.0060 - val_r_square: 0.9993\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9993\n",
      "Epoch 572: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - r_square: 0.9993 - val_loss: 0.0052 - val_r_square: 0.9995\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 573: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0080 - val_r_square: 0.9989\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9989\n",
      "Epoch 574: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0080 - r_square: 0.9989 - val_loss: 0.0032 - val_r_square: 0.9997\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9997\n",
      "Epoch 575: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - r_square: 0.9997 - val_loss: 0.0078 - val_r_square: 0.9989\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9989\n",
      "Epoch 576: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0078 - r_square: 0.9989 - val_loss: 0.0104 - val_r_square: 0.9982\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - r_square: 0.9982\n",
      "Epoch 577: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0104 - r_square: 0.9982 - val_loss: 0.0054 - val_r_square: 0.9994\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9994\n",
      "Epoch 578: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - r_square: 0.9994 - val_loss: 0.0062 - val_r_square: 0.9993\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9993\n",
      "Epoch 579: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - r_square: 0.9993 - val_loss: 0.0094 - val_r_square: 0.9985\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9985\n",
      "Epoch 580: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0094 - r_square: 0.9985 - val_loss: 0.0049 - val_r_square: 0.9995\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9995\n",
      "Epoch 581: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0049 - r_square: 0.9995 - val_loss: 0.0063 - val_r_square: 0.9992\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9993\n",
      "Epoch 582: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0064 - r_square: 0.9993 - val_loss: 0.0093 - val_r_square: 0.9985\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9985\n",
      "Epoch 583: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0093 - r_square: 0.9985 - val_loss: 0.0048 - val_r_square: 0.9995\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9995\n",
      "Epoch 584: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - r_square: 0.9995 - val_loss: 0.0056 - val_r_square: 0.9994\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9994\n",
      "Epoch 585: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0056 - r_square: 0.9994 - val_loss: 0.0077 - val_r_square: 0.9990\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9990\n",
      "Epoch 586: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0077 - r_square: 0.9990 - val_loss: 0.0026 - val_r_square: 0.9998\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - r_square: 0.9998\n",
      "Epoch 587: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - r_square: 0.9998 - val_loss: 0.0073 - val_r_square: 0.9990\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9991\n",
      "Epoch 588: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0073 - r_square: 0.9991 - val_loss: 0.0087 - val_r_square: 0.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0087 - r_square: 0.9987\n",
      "Epoch 589: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0087 - r_square: 0.9987 - val_loss: 0.0032 - val_r_square: 0.9998\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 590: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0069 - val_r_square: 0.9991\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9991\n",
      "Epoch 591: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0070 - r_square: 0.9991 - val_loss: 0.0083 - val_r_square: 0.9988\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9988\n",
      "Epoch 592: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0083 - r_square: 0.9988 - val_loss: 0.0024 - val_r_square: 0.9998\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - r_square: 0.9998\n",
      "Epoch 593: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - r_square: 0.9998 - val_loss: 0.0090 - val_r_square: 0.9986\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9986\n",
      "Epoch 594: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0090 - r_square: 0.9986 - val_loss: 0.0118 - val_r_square: 0.9977\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0118 - r_square: 0.9977\n",
      "Epoch 595: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0118 - r_square: 0.9977 - val_loss: 0.0071 - val_r_square: 0.9991\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9991\n",
      "Epoch 596: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0071 - r_square: 0.9991 - val_loss: 0.0044 - val_r_square: 0.9996\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9996\n",
      "Epoch 597: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - r_square: 0.9996 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9990\n",
      "Epoch 598: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0075 - r_square: 0.9990 - val_loss: 0.0029 - val_r_square: 0.9998\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9998\n",
      "Epoch 599: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - r_square: 0.9998 - val_loss: 0.0079 - val_r_square: 0.9989\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9989\n",
      "Epoch 600: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0079 - r_square: 0.9989 - val_loss: 0.0105 - val_r_square: 0.9982\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9982\n",
      "Epoch 601: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0105 - r_square: 0.9982 - val_loss: 0.0055 - val_r_square: 0.9994\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9994\n",
      "Epoch 602: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - r_square: 0.9994 - val_loss: 0.0060 - val_r_square: 0.9993\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9993\n",
      "Epoch 603: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - r_square: 0.9993 - val_loss: 0.0091 - val_r_square: 0.9985\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9986\n",
      "Epoch 604: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0092 - r_square: 0.9986 - val_loss: 0.0047 - val_r_square: 0.9995\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9995\n",
      "Epoch 605: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - r_square: 0.9995 - val_loss: 0.0066 - val_r_square: 0.9992\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9992\n",
      "Epoch 606: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - r_square: 0.9992 - val_loss: 0.0096 - val_r_square: 0.9985\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9985\n",
      "Epoch 607: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0096 - r_square: 0.9985 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9995\n",
      "Epoch 608: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - r_square: 0.9995 - val_loss: 0.0061 - val_r_square: 0.9993\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9993\n",
      "Epoch 609: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - r_square: 0.9993 - val_loss: 0.0088 - val_r_square: 0.9986\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0089 - r_square: 0.9987\n",
      "Epoch 610: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0089 - r_square: 0.9987 - val_loss: 0.0041 - val_r_square: 0.9996\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9996\n",
      "Epoch 611: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9996 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9991\n",
      "Epoch 612: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0074 - r_square: 0.9991 - val_loss: 0.0106 - val_r_square: 0.9981\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9982\n",
      "Epoch 613: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0106 - r_square: 0.9982 - val_loss: 0.0062 - val_r_square: 0.9993\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9993\n",
      "Epoch 614: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - r_square: 0.9993 - val_loss: 0.0048 - val_r_square: 0.9995\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9995\n",
      "Epoch 615: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - r_square: 0.9995 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9990\n",
      "Epoch 616: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0076 - r_square: 0.9990 - val_loss: 0.0029 - val_r_square: 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9998\n",
      "Epoch 617: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - r_square: 0.9998 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9990\n",
      "Epoch 618: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0076 - r_square: 0.9990 - val_loss: 0.0098 - val_r_square: 0.9984\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9984\n",
      "Epoch 619: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0098 - r_square: 0.9984 - val_loss: 0.0046 - val_r_square: 0.9996\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 620: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0071 - val_r_square: 0.9991\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9991\n",
      "Epoch 621: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - r_square: 0.9991 - val_loss: 0.0105 - val_r_square: 0.9981\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9982\n",
      "Epoch 622: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0105 - r_square: 0.9982 - val_loss: 0.0063 - val_r_square: 0.9993\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9993\n",
      "Epoch 623: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - r_square: 0.9993 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 624: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0079 - val_r_square: 0.9989\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9989\n",
      "Epoch 625: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0079 - r_square: 0.9989 - val_loss: 0.0038 - val_r_square: 0.9997\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 626: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0060 - val_r_square: 0.9993\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - r_square: 0.9993\n",
      "Epoch 627: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - r_square: 0.9993 - val_loss: 0.0075 - val_r_square: 0.9990\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9990\n",
      "Epoch 628: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0075 - r_square: 0.9990 - val_loss: 0.0020 - val_r_square: 0.9999\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0020 - r_square: 0.9999\n",
      "Epoch 629: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - r_square: 0.9999 - val_loss: 0.0091 - val_r_square: 0.9986\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9986\n",
      "Epoch 630: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0091 - r_square: 0.9986 - val_loss: 0.0116 - val_r_square: 0.9978\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0116 - r_square: 0.9978\n",
      "Epoch 631: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0116 - r_square: 0.9978 - val_loss: 0.0066 - val_r_square: 0.9992\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9992\n",
      "Epoch 632: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0066 - r_square: 0.9992 - val_loss: 0.0050 - val_r_square: 0.9995\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9995\n",
      "Epoch 633: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0050 - r_square: 0.9995 - val_loss: 0.0083 - val_r_square: 0.9988\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9988\n",
      "Epoch 634: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0083 - r_square: 0.9988 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9997\n",
      "Epoch 635: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - r_square: 0.9997 - val_loss: 0.0070 - val_r_square: 0.9991\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9991\n",
      "Epoch 636: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - r_square: 0.9991 - val_loss: 0.0098 - val_r_square: 0.9984\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9984\n",
      "Epoch 637: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0098 - r_square: 0.9984 - val_loss: 0.0052 - val_r_square: 0.9995\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 638: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0060 - val_r_square: 0.9993\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9993\n",
      "Epoch 639: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - r_square: 0.9993 - val_loss: 0.0089 - val_r_square: 0.9986\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - r_square: 0.9987\n",
      "Epoch 640: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0090 - r_square: 0.9987 - val_loss: 0.0044 - val_r_square: 0.9996\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9996\n",
      "Epoch 641: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - r_square: 0.9996 - val_loss: 0.0069 - val_r_square: 0.9992\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 642: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0099 - val_r_square: 0.9983\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9984\n",
      "Epoch 643: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0099 - r_square: 0.9984 - val_loss: 0.0055 - val_r_square: 0.9994\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9994\n",
      "Epoch 644: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - r_square: 0.9994 - val_loss: 0.0055 - val_r_square: 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 645/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 645: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0082 - val_r_square: 0.9989\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9989\n",
      "Epoch 646: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0082 - r_square: 0.9989 - val_loss: 0.0035 - val_r_square: 0.9997\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - r_square: 0.9997\n",
      "Epoch 647: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - r_square: 0.9997 - val_loss: 0.0079 - val_r_square: 0.9989\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9989\n",
      "Epoch 648: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0079 - r_square: 0.9989 - val_loss: 0.0110 - val_r_square: 0.9980\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9980\n",
      "Epoch 649: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0110 - r_square: 0.9980 - val_loss: 0.0066 - val_r_square: 0.9992\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - r_square: 0.9992\n",
      "Epoch 650: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0066 - r_square: 0.9992 - val_loss: 0.0044 - val_r_square: 0.9996\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9996\n",
      "Epoch 651: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0045 - r_square: 0.9996 - val_loss: 0.0072 - val_r_square: 0.9991\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9991\n",
      "Epoch 652: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - r_square: 0.9991 - val_loss: 0.0027 - val_r_square: 0.9998\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9998\n",
      "Epoch 653: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - r_square: 0.9998 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9990\n",
      "Epoch 654: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0077 - r_square: 0.9990 - val_loss: 0.0097 - val_r_square: 0.9984\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9984\n",
      "Epoch 655: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0098 - r_square: 0.9984 - val_loss: 0.0045 - val_r_square: 0.9996\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9996\n",
      "Epoch 656: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0046 - r_square: 0.9996 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9992\n",
      "Epoch 657: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0068 - r_square: 0.9992 - val_loss: 0.0098 - val_r_square: 0.9984\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9984\n",
      "Epoch 658: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0098 - r_square: 0.9984 - val_loss: 0.0054 - val_r_square: 0.9995\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 659: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0058 - val_r_square: 0.9994\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9994\n",
      "Epoch 660: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - r_square: 0.9994 - val_loss: 0.0088 - val_r_square: 0.9987\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0088 - r_square: 0.9987\n",
      "Epoch 661: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0088 - r_square: 0.9987 - val_loss: 0.0044 - val_r_square: 0.9996\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9996\n",
      "Epoch 662: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - r_square: 0.9996 - val_loss: 0.0062 - val_r_square: 0.9993\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9993\n",
      "Epoch 663: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - r_square: 0.9993 - val_loss: 0.0085 - val_r_square: 0.9988\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9988\n",
      "Epoch 664: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0085 - r_square: 0.9988 - val_loss: 0.0035 - val_r_square: 0.9997\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - r_square: 0.9997\n",
      "Epoch 665: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - r_square: 0.9997 - val_loss: 0.0082 - val_r_square: 0.9989\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9989\n",
      "Epoch 666: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0082 - r_square: 0.9989 - val_loss: 0.0115 - val_r_square: 0.9978\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - r_square: 0.9978\n",
      "Epoch 667: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0115 - r_square: 0.9978 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9991\n",
      "Epoch 668: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0074 - r_square: 0.9991 - val_loss: 0.0034 - val_r_square: 0.9997\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9997\n",
      "Epoch 669: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - r_square: 0.9997 - val_loss: 0.0065 - val_r_square: 0.9992\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - r_square: 0.9992\n",
      "Epoch 670: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0065 - r_square: 0.9992 - val_loss: 0.0023 - val_r_square: 0.9998\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0023 - r_square: 0.9998\n",
      "Epoch 671: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0023 - r_square: 0.9998 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9990\n",
      "Epoch 672: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0076 - r_square: 0.9990 - val_loss: 0.0093 - val_r_square: 0.9985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9986\n",
      "Epoch 673: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0093 - r_square: 0.9986 - val_loss: 0.0039 - val_r_square: 0.9997\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9997\n",
      "Epoch 674: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - r_square: 0.9997 - val_loss: 0.0071 - val_r_square: 0.9991\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9991\n",
      "Epoch 675: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0071 - r_square: 0.9991 - val_loss: 0.0097 - val_r_square: 0.9984\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9984\n",
      "Epoch 676: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - r_square: 0.9984 - val_loss: 0.0050 - val_r_square: 0.9995\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9995\n",
      "Epoch 677: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9995 - val_loss: 0.0064 - val_r_square: 0.9993\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9993\n",
      "Epoch 678: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0064 - r_square: 0.9993 - val_loss: 0.0097 - val_r_square: 0.9984\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9984\n",
      "Epoch 679: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0097 - r_square: 0.9984 - val_loss: 0.0056 - val_r_square: 0.9994\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9994\n",
      "Epoch 680: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - r_square: 0.9994 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9995\n",
      "Epoch 681: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - r_square: 0.9995 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9990\n",
      "Epoch 682: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0076 - r_square: 0.9990 - val_loss: 0.0027 - val_r_square: 0.9998\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9998\n",
      "Epoch 683: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - r_square: 0.9998 - val_loss: 0.0085 - val_r_square: 0.9988\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9988\n",
      "Epoch 684: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0085 - r_square: 0.9988 - val_loss: 0.0115 - val_r_square: 0.9978\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - r_square: 0.9979\n",
      "Epoch 685: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0115 - r_square: 0.9979 - val_loss: 0.0071 - val_r_square: 0.9991\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9991\n",
      "Epoch 686: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0071 - r_square: 0.9991 - val_loss: 0.0039 - val_r_square: 0.9997\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9997\n",
      "Epoch 687: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - r_square: 0.9997 - val_loss: 0.0067 - val_r_square: 0.9992\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9992\n",
      "Epoch 688: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0067 - r_square: 0.9992 - val_loss: 0.0022 - val_r_square: 0.9998\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - r_square: 0.9998\n",
      "Epoch 689: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - r_square: 0.9998 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9990\n",
      "Epoch 690: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0076 - r_square: 0.9990 - val_loss: 0.0092 - val_r_square: 0.9986\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9986\n",
      "Epoch 691: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0092 - r_square: 0.9986 - val_loss: 0.0038 - val_r_square: 0.9997\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 692: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9992\n",
      "Epoch 693: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9992 - val_loss: 0.0091 - val_r_square: 0.9986\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9986\n",
      "Epoch 694: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0091 - r_square: 0.9986 - val_loss: 0.0041 - val_r_square: 0.9996\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0042 - r_square: 0.9996\n",
      "Epoch 695: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - r_square: 0.9996 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9991\n",
      "Epoch 696: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0074 - r_square: 0.9991 - val_loss: 0.0108 - val_r_square: 0.9981\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9981\n",
      "Epoch 697: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0108 - r_square: 0.9981 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9992\n",
      "Epoch 698: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0068 - r_square: 0.9992 - val_loss: 0.0038 - val_r_square: 0.9997\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 699: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0063 - val_r_square: 0.9993\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9993\n",
      "Epoch 700: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - r_square: 0.9993 - val_loss: 0.0019 - val_r_square: 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 701/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - r_square: 0.9999\n",
      "Epoch 701: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0019 - r_square: 0.9999 - val_loss: 0.0035 - val_r_square: 0.9997\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - r_square: 0.9997\n",
      "Epoch 702: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - r_square: 0.9997 - val_loss: 0.0029 - val_r_square: 0.9998\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9998\n",
      "Epoch 703: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - r_square: 0.9998 - val_loss: 0.0027 - val_r_square: 0.9998\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9998\n",
      "Epoch 704: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - r_square: 0.9998 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 705: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0017 - val_r_square: 0.9999\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 706: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0018 - val_r_square: 0.9999\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 0.9999\n",
      "Epoch 707: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0018 - r_square: 0.9999 - val_loss: 0.0022 - val_r_square: 0.9999\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - r_square: 0.9999\n",
      "Epoch 708: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - r_square: 0.9999 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 709: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0031 - val_r_square: 0.9998\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 710: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 711: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 712: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0023 - val_r_square: 0.9999\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0023 - r_square: 0.9999\n",
      "Epoch 713: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0023 - r_square: 0.9999 - val_loss: 0.0015 - val_r_square: 0.9999\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - r_square: 0.9999\n",
      "Epoch 714: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0015 - r_square: 0.9999 - val_loss: 0.0012 - val_r_square: 1.0000\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 715: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0027 - val_r_square: 0.9999\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - r_square: 0.9999\n",
      "Epoch 716: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - r_square: 0.9999 - val_loss: 0.0020 - val_r_square: 0.9999\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 717: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 0.9999\n",
      "Epoch 718: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - r_square: 0.9999 - val_loss: 0.0038 - val_r_square: 0.9997\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 719: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 1.0000\n",
      "Epoch 720: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0013 - r_square: 1.0000 - val_loss: 0.0057 - val_r_square: 0.9994\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9994\n",
      "Epoch 721: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - r_square: 0.9994 - val_loss: 0.0045 - val_r_square: 0.9996\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9997\n",
      "Epoch 722: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - r_square: 0.9997 - val_loss: 0.0037 - val_r_square: 0.9997\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9997\n",
      "Epoch 723: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - r_square: 0.9997 - val_loss: 0.0041 - val_r_square: 0.9996\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 724: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0032 - val_r_square: 0.9998\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 725: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0038 - val_r_square: 0.9997\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 726: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0017 - val_r_square: 0.9999\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - r_square: 0.9999\n",
      "Epoch 727: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - r_square: 0.9999 - val_loss: 0.0011 - val_r_square: 1.0000\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - r_square: 1.0000\n",
      "Epoch 728: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0011 - r_square: 1.0000 - val_loss: 0.0011 - val_r_square: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - r_square: 1.0000\n",
      "Epoch 729: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0011 - r_square: 1.0000 - val_loss: 0.0024 - val_r_square: 0.9999\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - r_square: 0.9999\n",
      "Epoch 730: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - r_square: 0.9999 - val_loss: 0.0022 - val_r_square: 0.9999\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - r_square: 0.9999\n",
      "Epoch 731: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - r_square: 0.9999 - val_loss: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 0.9999\n",
      "Epoch 732: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0013 - r_square: 0.9999 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9997\n",
      "Epoch 733: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - r_square: 0.9997 - val_loss: 0.0013 - val_r_square: 1.0000\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 1.0000\n",
      "Epoch 734: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0013 - r_square: 1.0000 - val_loss: 0.0060 - val_r_square: 0.9994\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9994\n",
      "Epoch 735: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - r_square: 0.9994 - val_loss: 0.0050 - val_r_square: 0.9996\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9996\n",
      "Epoch 736: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9996 - val_loss: 0.0032 - val_r_square: 0.9998\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 737: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0042 - val_r_square: 0.9996\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0042 - r_square: 0.9996\n",
      "Epoch 738: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - r_square: 0.9996 - val_loss: 0.0027 - val_r_square: 0.9998\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - r_square: 0.9999\n",
      "Epoch 739: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - r_square: 0.9999 - val_loss: 0.0033 - val_r_square: 0.9998\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - r_square: 0.9998\n",
      "Epoch 740: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - r_square: 0.9998 - val_loss: 0.0017 - val_r_square: 0.9999\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - r_square: 0.9999\n",
      "Epoch 741: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - r_square: 0.9999 - val_loss: 0.0015 - val_r_square: 0.9999\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - r_square: 0.9999\n",
      "Epoch 742: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0015 - r_square: 0.9999 - val_loss: 0.0017 - val_r_square: 0.9999\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 0.9999\n",
      "Epoch 743: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - r_square: 0.9999 - val_loss: 0.0019 - val_r_square: 0.9999\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0020 - r_square: 0.9999\n",
      "Epoch 744: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0020 - r_square: 0.9999 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 745: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0012 - val_r_square: 1.0000\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 746: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 747: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0027 - val_r_square: 0.9999\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9999\n",
      "Epoch 748: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - r_square: 0.9999 - val_loss: 0.0017 - val_r_square: 0.9999\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - r_square: 0.9999\n",
      "Epoch 749: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - r_square: 0.9999 - val_loss: 0.0037 - val_r_square: 0.9997\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 750: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 751: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0026 - val_r_square: 0.9999\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - r_square: 0.9999\n",
      "Epoch 752: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - r_square: 0.9999 - val_loss: 0.0028 - val_r_square: 0.9998\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9998\n",
      "Epoch 753: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - r_square: 0.9998 - val_loss: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - r_square: 0.9999\n",
      "Epoch 754: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0014 - r_square: 0.9999 - val_loss: 0.0045 - val_r_square: 0.9996\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9996\n",
      "Epoch 755: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - r_square: 0.9996 - val_loss: 0.0020 - val_r_square: 0.9999\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 756: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0059 - val_r_square: 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9994\n",
      "Epoch 757: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - r_square: 0.9994 - val_loss: 0.0055 - val_r_square: 0.9995\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 758: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0022 - val_r_square: 0.9999\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0023 - r_square: 0.9999\n",
      "Epoch 759: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - r_square: 0.9999 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - r_square: 0.9999\n",
      "Epoch 760: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - r_square: 0.9999 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 761: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0038 - val_r_square: 0.9997\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 762: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0036 - val_r_square: 0.9997\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0036 - r_square: 0.9998\n",
      "Epoch 763: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - r_square: 0.9998 - val_loss: 0.0030 - val_r_square: 0.9998\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 764: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0045 - val_r_square: 0.9996\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - r_square: 0.9996\n",
      "Epoch 765: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - r_square: 0.9996 - val_loss: 0.0048 - val_r_square: 0.9996\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - r_square: 0.9996\n",
      "Epoch 766: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - r_square: 0.9996 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 767: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 0.9999\n",
      "Epoch 768: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0013 - r_square: 0.9999 - val_loss: 0.0045 - val_r_square: 0.9997\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 769: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0025 - val_r_square: 0.9999\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - r_square: 0.9999\n",
      "Epoch 770: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - r_square: 0.9999 - val_loss: 0.0054 - val_r_square: 0.9995\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 771: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0052 - val_r_square: 0.9995\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9995\n",
      "Epoch 772: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - r_square: 0.9995 - val_loss: 0.0023 - val_r_square: 0.9999\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - r_square: 0.9999\n",
      "Epoch 773: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - r_square: 0.9999 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 774: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0012 - val_r_square: 1.0000\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 775: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0012 - val_r_square: 1.0000\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 776: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0037 - val_r_square: 0.9997\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 777: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 0.9999\n",
      "Epoch 778: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0013 - r_square: 0.9999 - val_loss: 0.0028 - val_r_square: 0.9998\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0028 - r_square: 0.9998\n",
      "Epoch 779: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - r_square: 0.9998 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 780: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0014 - val_r_square: 0.9999\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - r_square: 0.9999\n",
      "Epoch 781: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - r_square: 0.9999 - val_loss: 0.0019 - val_r_square: 0.9999\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 0.9999\n",
      "Epoch 782: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - r_square: 0.9999 - val_loss: 0.0018 - val_r_square: 0.9999\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - r_square: 0.9999\n",
      "Epoch 783: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - r_square: 0.9999 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - r_square: 0.9999\n",
      "Epoch 784: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - r_square: 0.9999 - val_loss: 0.0011 - val_r_square: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - r_square: 1.0000\n",
      "Epoch 785: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0011 - r_square: 1.0000 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 786: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0029 - val_r_square: 0.9999\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9999\n",
      "Epoch 787: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - r_square: 0.9999 - val_loss: 0.0011 - val_r_square: 1.0000\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - r_square: 1.0000\n",
      "Epoch 788: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0011 - r_square: 1.0000 - val_loss: 0.0044 - val_r_square: 0.9997\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - r_square: 0.9997\n",
      "Epoch 789: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0044 - r_square: 0.9997 - val_loss: 0.0016 - val_r_square: 0.9999\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - r_square: 0.9999\n",
      "Epoch 790: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - r_square: 0.9999 - val_loss: 0.0073 - val_r_square: 0.9991\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9992\n",
      "Epoch 791: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0073 - r_square: 0.9992 - val_loss: 0.0079 - val_r_square: 0.9990\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9990\n",
      "Epoch 792: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0079 - r_square: 0.9990 - val_loss: 0.0013 - val_r_square: 1.0000\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - r_square: 1.0000\n",
      "Epoch 793: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0013 - r_square: 1.0000 - val_loss: 0.0109 - val_r_square: 0.9981\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9981\n",
      "Epoch 794: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0110 - r_square: 0.9981 - val_loss: 0.0146 - val_r_square: 0.9966\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0146 - r_square: 0.9966\n",
      "Epoch 795: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0146 - r_square: 0.9966 - val_loss: 0.0106 - val_r_square: 0.9982\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0106 - r_square: 0.9982\n",
      "Epoch 796: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0106 - r_square: 0.9982 - val_loss: 8.1259e-04 - val_r_square: 1.0000\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.3804e-04 - r_square: 1.0000\n",
      "Epoch 797: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.3804e-04 - r_square: 1.0000 - val_loss: 0.0075 - val_r_square: 0.9991\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9991\n",
      "Epoch 798: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0075 - r_square: 0.9991 - val_loss: 0.0069 - val_r_square: 0.9992\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 799: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0012 - val_r_square: 1.0000\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - r_square: 1.0000\n",
      "Epoch 800: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0012 - r_square: 1.0000 - val_loss: 0.0029 - val_r_square: 0.9998\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - r_square: 0.9998\n",
      "Epoch 801: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - r_square: 0.9998 - val_loss: 0.0025 - val_r_square: 0.9999\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - r_square: 0.9999\n",
      "Epoch 802: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - r_square: 0.9999 - val_loss: 0.0010 - val_r_square: 1.0000\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - r_square: 1.0000\n",
      "Epoch 803: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0011 - r_square: 1.0000 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 804: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0020 - val_r_square: 0.9999\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0020 - r_square: 0.9999\n",
      "Epoch 805: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - r_square: 0.9999 - val_loss: 0.0072 - val_r_square: 0.9992\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9992\n",
      "Epoch 806: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - r_square: 0.9992 - val_loss: 0.0083 - val_r_square: 0.9989\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9989\n",
      "Epoch 807: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0083 - r_square: 0.9989 - val_loss: 0.0021 - val_r_square: 0.9999\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - r_square: 0.9999\n",
      "Epoch 808: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - r_square: 0.9999 - val_loss: 0.0103 - val_r_square: 0.9983\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - r_square: 0.9983\n",
      "Epoch 809: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0104 - r_square: 0.9983 - val_loss: 0.0142 - val_r_square: 0.9967\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0143 - r_square: 0.9968\n",
      "Epoch 810: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0143 - r_square: 0.9968 - val_loss: 0.0105 - val_r_square: 0.9982\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - r_square: 0.9982\n",
      "Epoch 811: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0105 - r_square: 0.9982 - val_loss: 6.3924e-04 - val_r_square: 1.0000\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.5158e-04 - r_square: 1.0000\n",
      "Epoch 812: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.5158e-04 - r_square: 1.0000 - val_loss: 0.0126 - val_r_square: 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 813/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0126 - r_square: 0.9975\n",
      "Epoch 813: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0126 - r_square: 0.9975 - val_loss: 0.0166 - val_r_square: 0.9956\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0166 - r_square: 0.9957\n",
      "Epoch 814: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0166 - r_square: 0.9957 - val_loss: 0.0130 - val_r_square: 0.9973\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0130 - r_square: 0.9973\n",
      "Epoch 815: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0130 - r_square: 0.9973 - val_loss: 0.0027 - val_r_square: 0.9999\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9999\n",
      "Epoch 816: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - r_square: 0.9999 - val_loss: 0.0134 - val_r_square: 0.9971\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0134 - r_square: 0.9971\n",
      "Epoch 817: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0134 - r_square: 0.9971 - val_loss: 0.0205 - val_r_square: 0.9932\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0206 - r_square: 0.9933\n",
      "Epoch 818: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0206 - r_square: 0.9933 - val_loss: 0.0197 - val_r_square: 0.9937\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0198 - r_square: 0.9938\n",
      "Epoch 819: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0198 - r_square: 0.9938 - val_loss: 0.0118 - val_r_square: 0.9977\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0118 - r_square: 0.9977\n",
      "Epoch 820: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0118 - r_square: 0.9977 - val_loss: 0.0027 - val_r_square: 0.9999\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - r_square: 0.9999\n",
      "Epoch 821: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - r_square: 0.9999 - val_loss: 0.0092 - val_r_square: 0.9986\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9987\n",
      "Epoch 822: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0092 - r_square: 0.9987 - val_loss: 0.0080 - val_r_square: 0.9990\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9990\n",
      "Epoch 823: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0080 - r_square: 0.9990 - val_loss: 0.0010 - val_r_square: 1.0000\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0010 - r_square: 1.0000\n",
      "Epoch 824: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0010 - r_square: 1.0000 - val_loss: 0.0080 - val_r_square: 0.9990\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9990\n",
      "Epoch 825: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0080 - r_square: 0.9990 - val_loss: 0.0077 - val_r_square: 0.9990\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9990\n",
      "Epoch 826: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0078 - r_square: 0.9990 - val_loss: 0.0010 - val_r_square: 1.0000\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0010 - r_square: 1.0000\n",
      "Epoch 827: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - r_square: 1.0000 - val_loss: 0.0097 - val_r_square: 0.9984\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9985\n",
      "Epoch 828: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0097 - r_square: 0.9985 - val_loss: 0.0116 - val_r_square: 0.9978\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0116 - r_square: 0.9978\n",
      "Epoch 829: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0116 - r_square: 0.9978 - val_loss: 0.0061 - val_r_square: 0.9994\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9994\n",
      "Epoch 830: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0062 - r_square: 0.9994 - val_loss: 0.0058 - val_r_square: 0.9994\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9994\n",
      "Epoch 831: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0058 - r_square: 0.9994 - val_loss: 0.0094 - val_r_square: 0.9986\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9986\n",
      "Epoch 832: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0094 - r_square: 0.9986 - val_loss: 0.0055 - val_r_square: 0.9995\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 833: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0053 - val_r_square: 0.9995\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9995\n",
      "Epoch 834: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - r_square: 0.9995 - val_loss: 0.0079 - val_r_square: 0.9990\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9990\n",
      "Epoch 835: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0079 - r_square: 0.9990 - val_loss: 0.0033 - val_r_square: 0.9998\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - r_square: 0.9998\n",
      "Epoch 836: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - r_square: 0.9998 - val_loss: 0.0079 - val_r_square: 0.9990\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9990\n",
      "Epoch 837: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0080 - r_square: 0.9990 - val_loss: 0.0108 - val_r_square: 0.9981\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0108 - r_square: 0.9981\n",
      "Epoch 838: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0108 - r_square: 0.9981 - val_loss: 0.0061 - val_r_square: 0.9994\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - r_square: 0.9994\n",
      "Epoch 839: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - r_square: 0.9994 - val_loss: 0.0052 - val_r_square: 0.9996\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 840: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0083 - val_r_square: 0.9989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9989\n",
      "Epoch 841: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0083 - r_square: 0.9989 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 842: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 843: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0095 - val_r_square: 0.9985\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9985\n",
      "Epoch 844: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0095 - r_square: 0.9985 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 845: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9993\n",
      "Epoch 846: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9993 - val_loss: 0.0099 - val_r_square: 0.9984\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9984\n",
      "Epoch 847: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0099 - r_square: 0.9984 - val_loss: 0.0056 - val_r_square: 0.9995\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9995\n",
      "Epoch 848: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - r_square: 0.9995 - val_loss: 0.0054 - val_r_square: 0.9995\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 849: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0081 - val_r_square: 0.9989\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9989\n",
      "Epoch 850: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0082 - r_square: 0.9989 - val_loss: 0.0035 - val_r_square: 0.9998\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - r_square: 0.9998\n",
      "Epoch 851: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - r_square: 0.9998 - val_loss: 0.0076 - val_r_square: 0.9991\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9991\n",
      "Epoch 852: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0076 - r_square: 0.9991 - val_loss: 0.0104 - val_r_square: 0.9983\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - r_square: 0.9983\n",
      "Epoch 853: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0104 - r_square: 0.9983 - val_loss: 0.0058 - val_r_square: 0.9994\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 854: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0055 - val_r_square: 0.9995\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 855: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0085 - val_r_square: 0.9988\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9988\n",
      "Epoch 856: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0085 - r_square: 0.9988 - val_loss: 0.0041 - val_r_square: 0.9997\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 857: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0070 - val_r_square: 0.9992\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9992\n",
      "Epoch 858: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0070 - r_square: 0.9992 - val_loss: 0.0099 - val_r_square: 0.9984\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9985\n",
      "Epoch 859: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0099 - r_square: 0.9985 - val_loss: 0.0053 - val_r_square: 0.9995\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9995\n",
      "Epoch 860: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - r_square: 0.9995 - val_loss: 0.0058 - val_r_square: 0.9994\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9994\n",
      "Epoch 861: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0058 - r_square: 0.9994 - val_loss: 0.0088 - val_r_square: 0.9987\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0088 - r_square: 0.9987\n",
      "Epoch 862: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0088 - r_square: 0.9987 - val_loss: 0.0043 - val_r_square: 0.9997\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9997\n",
      "Epoch 863: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9993\n",
      "Epoch 864: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9993 - val_loss: 0.0097 - val_r_square: 0.9985\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9985\n",
      "Epoch 865: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0097 - r_square: 0.9985 - val_loss: 0.0052 - val_r_square: 0.9995\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9996\n",
      "Epoch 866: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - r_square: 0.9996 - val_loss: 0.0059 - val_r_square: 0.9994\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9994\n",
      "Epoch 867: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - r_square: 0.9994 - val_loss: 0.0087 - val_r_square: 0.9987\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0087 - r_square: 0.9988\n",
      "Epoch 868: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0087 - r_square: 0.9988 - val_loss: 0.0042 - val_r_square: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 869/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0042 - r_square: 0.9997\n",
      "Epoch 869: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - r_square: 0.9997 - val_loss: 0.0069 - val_r_square: 0.9992\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 870: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0098 - val_r_square: 0.9984\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9985\n",
      "Epoch 871: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0099 - r_square: 0.9985 - val_loss: 0.0054 - val_r_square: 0.9995\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 872: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0056 - val_r_square: 0.9995\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9995\n",
      "Epoch 873: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - r_square: 0.9995 - val_loss: 0.0084 - val_r_square: 0.9988\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0084 - r_square: 0.9989\n",
      "Epoch 874: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0084 - r_square: 0.9989 - val_loss: 0.0039 - val_r_square: 0.9997\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9997\n",
      "Epoch 875: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - r_square: 0.9997 - val_loss: 0.0073 - val_r_square: 0.9991\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9991\n",
      "Epoch 876: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0073 - r_square: 0.9991 - val_loss: 0.0102 - val_r_square: 0.9983\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9983\n",
      "Epoch 877: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0103 - r_square: 0.9983 - val_loss: 0.0058 - val_r_square: 0.9994\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9994\n",
      "Epoch 878: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - r_square: 0.9994 - val_loss: 0.0051 - val_r_square: 0.9996\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 879: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0079 - val_r_square: 0.9990\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9990\n",
      "Epoch 880: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0079 - r_square: 0.9990 - val_loss: 0.0034 - val_r_square: 0.9998\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 881: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0077 - val_r_square: 0.9990\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - r_square: 0.9990\n",
      "Epoch 882: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0077 - r_square: 0.9990 - val_loss: 0.0107 - val_r_square: 0.9982\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - r_square: 0.9982\n",
      "Epoch 883: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0107 - r_square: 0.9982 - val_loss: 0.0063 - val_r_square: 0.9993\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - r_square: 0.9993\n",
      "Epoch 884: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - r_square: 0.9993 - val_loss: 0.0047 - val_r_square: 0.9996\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 885: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0075 - val_r_square: 0.9991\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9991\n",
      "Epoch 886: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0075 - r_square: 0.9991 - val_loss: 0.0030 - val_r_square: 0.9998\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - r_square: 0.9998\n",
      "Epoch 887: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - r_square: 0.9998 - val_loss: 0.0081 - val_r_square: 0.9989\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - r_square: 0.9989\n",
      "Epoch 888: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0081 - r_square: 0.9989 - val_loss: 0.0110 - val_r_square: 0.9980\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0110 - r_square: 0.9980\n",
      "Epoch 889: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0110 - r_square: 0.9980 - val_loss: 0.0066 - val_r_square: 0.9993\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9993\n",
      "Epoch 890: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0067 - r_square: 0.9993 - val_loss: 0.0043 - val_r_square: 0.9997\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9997\n",
      "Epoch 891: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - r_square: 0.9997 - val_loss: 0.0071 - val_r_square: 0.9992\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9992\n",
      "Epoch 892: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0071 - r_square: 0.9992 - val_loss: 0.0027 - val_r_square: 0.9999\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - r_square: 0.9999\n",
      "Epoch 893: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - r_square: 0.9999 - val_loss: 0.0084 - val_r_square: 0.9988\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0084 - r_square: 0.9988\n",
      "Epoch 894: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0084 - r_square: 0.9988 - val_loss: 0.0112 - val_r_square: 0.9979\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - r_square: 0.9979\n",
      "Epoch 895: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0113 - r_square: 0.9979 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 896: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0041 - val_r_square: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 897: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0069 - val_r_square: 0.9992\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 898: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0025 - val_r_square: 0.9999\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - r_square: 0.9999\n",
      "Epoch 899: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - r_square: 0.9999 - val_loss: 0.0085 - val_r_square: 0.9988\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9988\n",
      "Epoch 900: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0085 - r_square: 0.9988 - val_loss: 0.0113 - val_r_square: 0.9979\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0114 - r_square: 0.9979\n",
      "Epoch 901: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0114 - r_square: 0.9979 - val_loss: 0.0069 - val_r_square: 0.9992\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9992\n",
      "Epoch 902: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - r_square: 0.9992 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9997\n",
      "Epoch 903: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0040 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9992\n",
      "Epoch 904: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9992 - val_loss: 0.0024 - val_r_square: 0.9999\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - r_square: 0.9999\n",
      "Epoch 905: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - r_square: 0.9999 - val_loss: 0.0079 - val_r_square: 0.9990\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - r_square: 0.9990\n",
      "Epoch 906: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0079 - r_square: 0.9990 - val_loss: 0.0102 - val_r_square: 0.9983\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0102 - r_square: 0.9983\n",
      "Epoch 907: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0102 - r_square: 0.9983 - val_loss: 0.0053 - val_r_square: 0.9995\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9995\n",
      "Epoch 908: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - r_square: 0.9995 - val_loss: 0.0060 - val_r_square: 0.9994\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - r_square: 0.9994\n",
      "Epoch 909: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - r_square: 0.9994 - val_loss: 0.0091 - val_r_square: 0.9986\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - r_square: 0.9987\n",
      "Epoch 910: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0091 - r_square: 0.9987 - val_loss: 0.0050 - val_r_square: 0.9996\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9996\n",
      "Epoch 911: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9996 - val_loss: 0.0057 - val_r_square: 0.9995\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9995\n",
      "Epoch 912: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - r_square: 0.9995 - val_loss: 0.0084 - val_r_square: 0.9988\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - r_square: 0.9988\n",
      "Epoch 913: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0085 - r_square: 0.9988 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9997\n",
      "Epoch 914: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0040 - r_square: 0.9997 - val_loss: 0.0069 - val_r_square: 0.9992\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 915: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0097 - val_r_square: 0.9985\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9985\n",
      "Epoch 916: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - r_square: 0.9985 - val_loss: 0.0053 - val_r_square: 0.9995\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9995\n",
      "Epoch 917: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - r_square: 0.9995 - val_loss: 0.0057 - val_r_square: 0.9995\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9995\n",
      "Epoch 918: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - r_square: 0.9995 - val_loss: 0.0086 - val_r_square: 0.9988\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0087 - r_square: 0.9988\n",
      "Epoch 919: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0087 - r_square: 0.9988 - val_loss: 0.0043 - val_r_square: 0.9997\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - r_square: 0.9997\n",
      "Epoch 920: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - r_square: 0.9997 - val_loss: 0.0064 - val_r_square: 0.9993\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9993\n",
      "Epoch 921: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - r_square: 0.9993 - val_loss: 0.0092 - val_r_square: 0.9986\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - r_square: 0.9987\n",
      "Epoch 922: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0092 - r_square: 0.9987 - val_loss: 0.0046 - val_r_square: 0.9996\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9996\n",
      "Epoch 923: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - r_square: 0.9996 - val_loss: 0.0064 - val_r_square: 0.9993\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9993\n",
      "Epoch 924: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0064 - r_square: 0.9993 - val_loss: 0.0093 - val_r_square: 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 925/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9986\n",
      "Epoch 925: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0093 - r_square: 0.9986 - val_loss: 0.0050 - val_r_square: 0.9996\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9996\n",
      "Epoch 926: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - r_square: 0.9996 - val_loss: 0.0058 - val_r_square: 0.9994\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9995\n",
      "Epoch 927: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - r_square: 0.9995 - val_loss: 0.0085 - val_r_square: 0.9988\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - r_square: 0.9988\n",
      "Epoch 928: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0086 - r_square: 0.9988 - val_loss: 0.0041 - val_r_square: 0.9997\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 929: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9992\n",
      "Epoch 930: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0068 - r_square: 0.9992 - val_loss: 0.0097 - val_r_square: 0.9985\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9985\n",
      "Epoch 931: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - r_square: 0.9985 - val_loss: 0.0054 - val_r_square: 0.9995\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 932: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0054 - val_r_square: 0.9995\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 933: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0083 - val_r_square: 0.9989\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9989\n",
      "Epoch 934: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0083 - r_square: 0.9989 - val_loss: 0.0039 - val_r_square: 0.9997\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9997\n",
      "Epoch 935: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - r_square: 0.9997 - val_loss: 0.0070 - val_r_square: 0.9992\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9992\n",
      "Epoch 936: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0070 - r_square: 0.9992 - val_loss: 0.0098 - val_r_square: 0.9984\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - r_square: 0.9984\n",
      "Epoch 937: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0099 - r_square: 0.9984 - val_loss: 0.0055 - val_r_square: 0.9995\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 938: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0054 - val_r_square: 0.9995\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 939: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0082 - val_r_square: 0.9989\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - r_square: 0.9989\n",
      "Epoch 940: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0082 - r_square: 0.9989 - val_loss: 0.0039 - val_r_square: 0.9997\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9997\n",
      "Epoch 941: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - r_square: 0.9997 - val_loss: 0.0069 - val_r_square: 0.9992\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 942: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0097 - val_r_square: 0.9985\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - r_square: 0.9985\n",
      "Epoch 943: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0098 - r_square: 0.9985 - val_loss: 0.0053 - val_r_square: 0.9995\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 944: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0055 - val_r_square: 0.9995\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - r_square: 0.9995\n",
      "Epoch 945: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - r_square: 0.9995 - val_loss: 0.0083 - val_r_square: 0.9989\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9989\n",
      "Epoch 946: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0083 - r_square: 0.9989 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0040 - r_square: 0.9997\n",
      "Epoch 947: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0040 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9992\n",
      "Epoch 948: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9992 - val_loss: 0.0095 - val_r_square: 0.9985\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0096 - r_square: 0.9985\n",
      "Epoch 949: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0096 - r_square: 0.9985 - val_loss: 0.0052 - val_r_square: 0.9995\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 950: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0056 - val_r_square: 0.9995\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9995\n",
      "Epoch 951: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - r_square: 0.9995 - val_loss: 0.0084 - val_r_square: 0.9988\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0084 - r_square: 0.9989\n",
      "Epoch 952: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0084 - r_square: 0.9989 - val_loss: 0.0041 - val_r_square: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - r_square: 0.9997\n",
      "Epoch 953: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - r_square: 0.9997 - val_loss: 0.0067 - val_r_square: 0.9992\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - r_square: 0.9992\n",
      "Epoch 954: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0067 - r_square: 0.9992 - val_loss: 0.0095 - val_r_square: 0.9985\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9985\n",
      "Epoch 955: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0095 - r_square: 0.9985 - val_loss: 0.0051 - val_r_square: 0.9995\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - r_square: 0.9995\n",
      "Epoch 956: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - r_square: 0.9995 - val_loss: 0.0056 - val_r_square: 0.9995\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9995\n",
      "Epoch 957: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - r_square: 0.9995 - val_loss: 0.0083 - val_r_square: 0.9989\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - r_square: 0.9989\n",
      "Epoch 958: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0083 - r_square: 0.9989 - val_loss: 0.0040 - val_r_square: 0.9997\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - r_square: 0.9997\n",
      "Epoch 959: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0069 - r_square: 0.9992\n",
      "Epoch 960: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - r_square: 0.9992 - val_loss: 0.0097 - val_r_square: 0.9984\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - r_square: 0.9985\n",
      "Epoch 961: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - r_square: 0.9985 - val_loss: 0.0054 - val_r_square: 0.9995\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 962: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0053 - val_r_square: 0.9995\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - r_square: 0.9995\n",
      "Epoch 963: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - r_square: 0.9995 - val_loss: 0.0081 - val_r_square: 0.9989\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9990\n",
      "Epoch 964: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0080 - r_square: 0.9990 - val_loss: 0.0037 - val_r_square: 0.9998\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - r_square: 0.9998\n",
      "Epoch 965: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - r_square: 0.9998 - val_loss: 0.0071 - val_r_square: 0.9991\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - r_square: 0.9991\n",
      "Epoch 966: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0071 - r_square: 0.9991 - val_loss: 0.0099 - val_r_square: 0.9984\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9984\n",
      "Epoch 967: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0100 - r_square: 0.9984 - val_loss: 0.0056 - val_r_square: 0.9994\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - r_square: 0.9994\n",
      "Epoch 968: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - r_square: 0.9994 - val_loss: 0.0051 - val_r_square: 0.9996\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - r_square: 0.9996\n",
      "Epoch 969: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - r_square: 0.9996 - val_loss: 0.0078 - val_r_square: 0.9990\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9990\n",
      "Epoch 970: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0078 - r_square: 0.9990 - val_loss: 0.0035 - val_r_square: 0.9998\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 971: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0073 - val_r_square: 0.9991\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0073 - r_square: 0.9991\n",
      "Epoch 972: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0073 - r_square: 0.9991 - val_loss: 0.0101 - val_r_square: 0.9983\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - r_square: 0.9983\n",
      "Epoch 973: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0101 - r_square: 0.9983 - val_loss: 0.0058 - val_r_square: 0.9994\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - r_square: 0.9994\n",
      "Epoch 974: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0058 - r_square: 0.9994 - val_loss: 0.0049 - val_r_square: 0.9996\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - r_square: 0.9996\n",
      "Epoch 975: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0049 - r_square: 0.9996 - val_loss: 0.0076 - val_r_square: 0.9990\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - r_square: 0.9991\n",
      "Epoch 976: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0076 - r_square: 0.9991 - val_loss: 0.0033 - val_r_square: 0.9998\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - r_square: 0.9998\n",
      "Epoch 977: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - r_square: 0.9998 - val_loss: 0.0074 - val_r_square: 0.9990\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - r_square: 0.9990\n",
      "Epoch 978: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0074 - r_square: 0.9990 - val_loss: 0.0102 - val_r_square: 0.9982\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0103 - r_square: 0.9983\n",
      "Epoch 979: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0103 - r_square: 0.9983 - val_loss: 0.0059 - val_r_square: 0.9994\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - r_square: 0.9994\n",
      "Epoch 980: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0059 - r_square: 0.9994 - val_loss: 0.0047 - val_r_square: 0.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - r_square: 0.9996\n",
      "Epoch 981: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - r_square: 0.9996 - val_loss: 0.0075 - val_r_square: 0.9991\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - r_square: 0.9991\n",
      "Epoch 982: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0075 - r_square: 0.9991 - val_loss: 0.0032 - val_r_square: 0.9998\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - r_square: 0.9998\n",
      "Epoch 983: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - r_square: 0.9998 - val_loss: 0.0070 - val_r_square: 0.9992\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - r_square: 0.9991\n",
      "Epoch 984: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0070 - r_square: 0.9991 - val_loss: 0.0092 - val_r_square: 0.9986\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - r_square: 0.9986\n",
      "Epoch 985: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0093 - r_square: 0.9986 - val_loss: 0.0045 - val_r_square: 0.9996\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - r_square: 0.9996\n",
      "Epoch 986: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - r_square: 0.9996 - val_loss: 0.0065 - val_r_square: 0.9993\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - r_square: 0.9993\n",
      "Epoch 987: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0064 - r_square: 0.9993 - val_loss: 0.0095 - val_r_square: 0.9985\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - r_square: 0.9986\n",
      "Epoch 988: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0095 - r_square: 0.9986 - val_loss: 0.0054 - val_r_square: 0.9995\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - r_square: 0.9995\n",
      "Epoch 989: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - r_square: 0.9995 - val_loss: 0.0050 - val_r_square: 0.9995\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9995\n",
      "Epoch 990: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - r_square: 0.9995 - val_loss: 0.0077 - val_r_square: 0.9990\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - r_square: 0.9990\n",
      "Epoch 991: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0078 - r_square: 0.9990 - val_loss: 0.0034 - val_r_square: 0.9998\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - r_square: 0.9998\n",
      "Epoch 992: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - r_square: 0.9998 - val_loss: 0.0072 - val_r_square: 0.9991\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - r_square: 0.9992\n",
      "Epoch 993: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0072 - r_square: 0.9992 - val_loss: 0.0100 - val_r_square: 0.9984\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - r_square: 0.9984\n",
      "Epoch 994: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0100 - r_square: 0.9984 - val_loss: 0.0056 - val_r_square: 0.9995\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - r_square: 0.9995\n",
      "Epoch 995: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - r_square: 0.9995 - val_loss: 0.0051 - val_r_square: 0.9996\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - r_square: 0.9996\n",
      "Epoch 996: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - r_square: 0.9996 - val_loss: 0.0080 - val_r_square: 0.9989\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0080 - r_square: 0.9990\n",
      "Epoch 997: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0080 - r_square: 0.9990 - val_loss: 0.0037 - val_r_square: 0.9997\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - r_square: 0.9997\n",
      "Epoch 998: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - r_square: 0.9997 - val_loss: 0.0068 - val_r_square: 0.9992\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - r_square: 0.9993\n",
      "Epoch 999: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - r_square: 0.9993 - val_loss: 0.0094 - val_r_square: 0.9986\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - r_square: 0.9986\n",
      "Epoch 1000: saving model to training_regressions_notseparated.weights.h5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0094 - r_square: 0.9986 - val_loss: 0.0050 - val_r_square: 0.9996\n"
     ]
    }
   ],
   "source": [
    "#Create a sequential model\n",
    "model_notseparated = tf.keras.Sequential()\n",
    "#Add the hidden layers\n",
    "model_notseparated.add(tf.keras.layers.Dense(250, input_dim = (np.shape(xtrain_notseparated)[1]), activation='sigmoid'))\n",
    "model_notseparated.add(tf.keras.layers.Dense(80 , activation = 'sigmoid'))\n",
    "#Add the output layer\n",
    "model_notseparated.add(tf.keras.layers.Dense(1, activation = 'linear'))\n",
    "\n",
    "#Setting the optimiser equal to the Adam optimiser with learning rate = 0.0001\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "\n",
    "#Compliling the model\n",
    "model_notseparated.compile(optimizer=opt, loss = 'mean_absolute_error', metrics=[r_square])\n",
    "\n",
    "#Training the model\n",
    "history_notseparated = model_notseparated.fit(xtrain_notseparated, Ytrain_notseparated, epochs = 1000, validation_data = (xval_notseparated, Yval_notseparated), batch_size = np.shape(xtrain_notseparated)[0], verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95cb5f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36/150 [======>.......................] - ETA: 0s - loss: 0.0051 - r_square: 0.9995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 15:33:39.071537: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0050 - r_square: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005009652581065893, 0.9995163083076477]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model on the training set\n",
    "model_notseparated.evaluate(xtrain_notseparated, Ytrain_notseparated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b26f23aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0050 - r_square: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005008801352232695, 0.999495267868042]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model on the test set\n",
    "model_notseparated.evaluate(xtest_notseparated, Ytest_notseparated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1cd6f3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the training and validation loss values over epochs\n",
    "plt.plot(history_notseparated.history['loss'], label='Training')\n",
    "plt.plot(history_notseparated.history['val_loss'], label='Validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d6dfaa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 15:33:41.906014: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#inverse transform the scaled outputs to get original values\n",
    "y_true_notseparated = scaler.inverse_transform(Ytest_notseparated)\n",
    "y_pred_notseparated = scaler.inverse_transform(model_notseparated.predict(xtest_notseparated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c8adc276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a scatter plot of predicted values for $s$ versus true values\n",
    "plt.plot(y_pred_notseparated, y_true_notseparated, 'bo', label='Predictions')\n",
    "plt.plot(y_true_notseparated, y_true_notseparated, color='orange', label='True')\n",
    "plt.xlabel(r\"$\\mathrm{s}$\")\n",
    "plt.ylabel(r\"$\\mathrm{\\hat{s}}$\")\n",
    "plt.legend()\n",
    "plt.savefig('predictedsvreal_notseparated.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7cb1d9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a scatter plot of the difference between the predicted and true values of $s$ versus true values\n",
    "plt.plot(y_true_notseparated[y_true_notseparated.flatten().argsort()], (y_pred_notseparated - y_true_notseparated)[y_true_notseparated.flatten().argsort()], 'bo')\n",
    "plt.xlabel(r\"$\\mathrm{s}$\")\n",
    "plt.ylabel(r\"$\\mathrm{\\hat{s} - s}$\")\n",
    "plt.savefig('errorvs_notseparated.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c621665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008199982674535922\n",
      "0.04120591177345723\n"
     ]
    }
   ],
   "source": [
    "#Generate arrays for the error distribution containing only one Ohmic trajectory\n",
    "y_true_notseparated_distrib = np.concatenate((y_true_notseparated[y_true_notseparated != 1], y_true_notseparated[y_true_notseparated==1][[0]]))\n",
    "y_pred_notseparated_distrib = np.concatenate((y_pred_notseparated[y_true_notseparated != 1], y_pred_notseparated[y_true_notseparated == 1][[0]]))\n",
    "\n",
    "#define an array where each element is the difference between the predicted value and true value for $s$ for a \n",
    "#given trajectory\n",
    "diffs2 = y_pred_notseparated_distrib - y_true_notseparated_distrib\n",
    "#print the minimum difference to find the smallest prediction error\n",
    "print(np.amin(diffs2))\n",
    "#print the maximum difference to find the largest prediction error\n",
    "print(np.amax(diffs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "07576738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define intervals for analysing the differences between predicted and true values for $s$\n",
    "intervals2 = [0.008, 0.0085, 0.009, 0.0095, 0.01, 0.0105, 0.011, 0.0115, 0.012, 0.0125, 0.013, 0.0135, 0.014, 0.0145, 0.015, 0.0155, 0.016, 0.0165, 0.017, 0.0175, 0.018, 0.0185, 0.019, 0.0195, 0.02, 0.0205, 0.021, 0.0215, 0.022, 0.0225, 0.023, 0.0235, 0.024, 0.0245, 0.025, 0.0255, 0.026, 0.0265, 0.027, 0.0275, 0.028, 0.0285, 0.029, 0.0295, 0.03, 0.0305, 0.031, 0.0315, 0.032, 0.0325, 0.033, 0.0335, 0.034, 0.0345, 0.035, 0.0355, 0.036, 0.0365, 0.037, 0.0375, 0.038, 0.0385, 0.039, 0.0395, 0.04, 0.0405, 0.041, 0.0415]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5bba38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise list to store the frequencies of differences in intervals for $s$\n",
    "freq2 = []\n",
    "\n",
    "#loop through each interval\n",
    "for i in range(len(intervals2)-1):\n",
    "    #create a mask to find differences within the current interval\n",
    "    mask2 = (diffs2 >= intervals2[i]) & (diffs2 < intervals2[i+1])\n",
    "    #append the count of differences within the current interval to the frequency list\n",
    "    freq2.append(len(diffs2[mask2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "67f56dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#calculate x positions for bars and heights\n",
    "x2 = intervals2[1:] \n",
    "heights2 = (np.array(freq2)/len(y_true_notseparated_distrib))*100\n",
    "\n",
    "#create the bar chart\n",
    "plt.bar(x2, heights2, width=-0.0005, align='edge', alpha = 1, color = 'orange', edgecolor='black')  \n",
    "plt.xlabel(r\"$\\mathrm{\\hat{s} - s}$\")\n",
    "plt.ylabel('% of trajectories')\n",
    "plt.savefig('barchart_notseparated.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
